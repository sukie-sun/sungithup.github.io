<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta name="keywords" content="hexo,个人博客,blog">
  <meta name="description" content="Sukie的个人博客">
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://busuanzi.ibruce.info">
  
  <link rel="dns-prefetch" href="https://widget.daovoice.io">
  <link rel="dns-prefetch" href="https://widget-static-cdn.daovoice.io">
  <link rel="dns-prefetch" href="https://im.daovoice.io">
  
  
  <link rel="dns-prefetch" href="https://hm.baidu.com/">
  
  
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="https://api.github.com">
  <link rel="dns-prefetch" href="https://avatars3.githubusercontent.com">
  
  <link rel="stylesheet" type="text/css" href="/./style/main.d9e3dd.css">
	<link rel="shortcut icon" href="/favicon.ico" title="Favicon">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
	<title>Hadoop2.X</title>
  
  <script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?bc39ced90d9f89c71fda7b7d4ca8b638";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();
  </script>
  
  
    <script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/949e21d7.js","daovoice");daovoice('init',{app_id: "949e21d7"});daovoice('update');
  </script>
  
</head>
<body>
<canvas id="pattern-placeholder" height="230"></canvas>
<div class="navbar-header">
  <a class="blog-title" href="/">Sunrise山脉</a>
  <a class="face-img" href="/">
    <img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1545985146898&amp;di=2861af758f070858999b0a2a0e708388&amp;imgtype=0&amp;src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201610%2F11%2F20161011203442_eHhSV.jpeg">
  </a>
</div>
<main>
  <div class="article-title">
    
  
  <h1 class="title">
    Hadoop2.X
  </h1>
  


    <ul class="article-info">
      <li>
        发布
        <time datetime="2019-01-04T11:05:47.000Z" itemprop="datePublished">2019-01-04</time>
      </li>
      <li>
        
    更新 <time datetime="2019-01-24T01:25:19.144Z" itemprop="dateUpdated">2019-01-24</time>

      </li>
      <li id="busuanzi_container_page_pv">
        阅读 <span id="busuanzi_value_page_pv"></span>
      </li>
    </ul>
  </div>
  <div class="container">
    <div class="article">
      <div class="content">
        
        <p>[TOC]</p>
<h2 id="一、Hadoop-2-x产生背景"><a href="#一、Hadoop-2-x产生背景" class="headerlink" title="一、Hadoop 2.x产生背景"></a>一、Hadoop 2.x产生背景</h2><h3 id="1、Hadoop-1-0存在的问题"><a href="#1、Hadoop-1-0存在的问题" class="headerlink" title="1、Hadoop 1.0存在的问题"></a>1、Hadoop 1.0存在的问题</h3><h4 id="（1）HDFS存在的问题"><a href="#（1）HDFS存在的问题" class="headerlink" title="（1）HDFS存在的问题"></a>（1）HDFS存在的问题</h4><ul>
<li>NameNode单点故障，难以应用于在线场景</li>
<li>NameNode（一个）压力过大，内存受限，影响系统扩展性</li>
</ul>
<h4 id="（2）MapReduce存在的问题"><a href="#（2）MapReduce存在的问题" class="headerlink" title="（2）MapReduce存在的问题"></a>（2）MapReduce存在的问题</h4><ul>
<li>JobTracker访问压力大，影响系统扩展性</li>
<li>难以支持MapReduce以外的计算框架，比如Spark、Storm</li>
</ul>
<h3 id="2、Hadoop-2-0分支"><a href="#2、Hadoop-2-0分支" class="headerlink" title="2、Hadoop 2.0分支"></a>2、Hadoop 2.0分支</h3><p>HDFS：分布式文件存储系统<br>MapReduce：计算框架<br>YARN：资源管理系统</p>
<h3 id="3、特点"><a href="#3、特点" class="headerlink" title="3、特点"></a>3、特点</h3><p> 1）. 解决单点故障：HDFS HA（高可用）</p>
<blockquote>
<p>  通过主备NameNode解决，如果主NameNode发生故障，就切换到备NameNode上   |</p>
</blockquote>
<p> 2).解决内存受限问题：HDFS Federation（联邦制）、HA</p>
<blockquote>
<p> HA：两个NameNode<br> (3.0就实现了一组多从：水平扩展，支持多个NameNode；每个NameNode分管一部分目录；所有NameNode共享所有DataNode资源)</p>
</blockquote>
<p> 3).仅架构上发生变化使用方式不变</p>
<h2 id="二、HDFS-HA结构及功能"><a href="#二、HDFS-HA结构及功能" class="headerlink" title="二、HDFS HA结构及功能"></a>二、HDFS HA结构及功能</h2><h3 id="HA"><a href="#HA" class="headerlink" title="**HA"></a>**HA</h3><p>DN：DataNode（数据节点）</p>
<blockquote>
<p>存放数据block块；遵循心跳机制向NN Active和NN Standby汇报block块信息，但只执行active的命令         </p>
</blockquote>
<p>主备NN：NameNode Active 和 NameNode Standby （主备名称节点）</p>
<blockquote>
<p>主NN对外提供读写服务，备NN同步主NN元数据，以待切换，所有的DN同时向两个NN汇报数据块信息</p>
<p>元数据信息加载到主NN，并写入JN（至少写两台：过半原则）；</p>
<p>备NN可以从JN中同步元数据信息；</p>
<p>解决单点故障；</p>
<p>–两种切换方式：</p>
<p>手动：通过命令实现主备切换</p>
<p>自动：基于Zookeeper实现（详情见搭建步骤）</p>
</blockquote>
<p>JN：JournalNode（至少3台）</p>
<blockquote>
<p>存储主NN元数据信息，实现主备NN间数据共享；</p>
<p>（遵循过半原则：至少有过半的数量参与投票）</p>
</blockquote>
<p>ZKFC：FailoverController（竞争锁）</p>
<blockquote>
<p>谁拿到了这个所，谁就是active NN</p>
<p>心跳机制监控主备NN状态，一旦出现一台挂机，就会释放锁，另一个NN就会立即启动竞争锁，成为active NN</p>
</blockquote>
<p>ZK：Zookeeper（至少3台）</p>
<blockquote>
<p>（实现主备NN切换）</p>
</blockquote>
<h3 id="联邦"><a href="#联邦" class="headerlink" title="**联邦"></a>**联邦</h3><blockquote>
<p>通过多个namenode/namespace把元数据的存储和管理分散到多个节点中，使到namenode/namespace可以通过增加机器来进行水平扩展</p>
</blockquote>
<blockquote>
<p>通过多个namespace来隔离不同类型的应用，把不同类型应用的HDFS元数据的存储和管理分派到不同的namenode中。</p>
</blockquote>
<h2 id="三、YARN-资源管理"><a href="#三、YARN-资源管理" class="headerlink" title="三、YARN(资源管理)???????"></a>三、YARN(资源管理)???????</h2><p><code>详见Yarn学习.md</code></p>
<p>1、核心思想：SourceManager（资源管理）+ReplicationMaster（任务调度）</p>
<p>2.yarn的引入使得多个计算框架可以应用到一个集群中</p>
<h2 id="四、Zookeeper工作原理"><a href="#四、Zookeeper工作原理" class="headerlink" title="四、Zookeeper工作原理"></a>四、Zookeeper工作原理</h2><p><code>详见Zookeeper学习.md</code></p>
<h2 id="五、Hadoop2-X-集群搭建"><a href="#五、Hadoop2-X-集群搭建" class="headerlink" title="五、Hadoop2.X 集群搭建"></a>五、Hadoop2.X 集群搭建</h2><h3 id="1、linux环境下搭建"><a href="#1、linux环境下搭建" class="headerlink" title="1、linux环境下搭建"></a>1、linux环境下搭建</h3><table>
<thead>
<tr>
<th></th>
<th style="text-align:center">NN</th>
<th style="text-align:center">DN</th>
<th style="text-align:center">JN</th>
<th style="text-align:center">ZKFC</th>
<th style="text-align:center">ZK</th>
<th style="text-align:center">SM</th>
<th style="text-align:center">RM</th>
</tr>
</thead>
<tbody>
<tr>
<td>node00</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td>node01</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td>node02</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
</tr>
</tbody>
</table>
<p>0.在搭建环境之前的准备</p>
<p>三台虚拟机：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">关闭防火墙</span><br><span class="line">安装jdk</span><br><span class="line">编辑/etc/hosts/给各个节点服务器起别名</span><br><span class="line">时间服务器：ntpdate</span><br><span class="line">     安装：yum install ntpdate -y</span><br><span class="line">     生成：ntpdate cn.ntp.org.cn</span><br><span class="line">免密登录环境准备</span><br></pre></td></tr></table></figure>
<p>在hadoop安装目录下hadoop-2.6.5/etc/hadoop/</p>
<ol>
<li>编辑hadoop-env.sh</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/soft/jdk1.8.0_191</span><br></pre></td></tr></table></figure>
<p>   2.编辑core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://Sunrise<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!--配置集群的名字--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>node00:2181,node01:2181,node02:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--配置zookeeper：三个节点--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!--配置hadoop基础配置存放的路径--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>3.编辑hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>sxt<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.Sunrise<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.Sunrise.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node00:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.Sunrise.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.Sunrise.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node00:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.Sunrise.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 指定namenode元数据存储在journalnode中的路径 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://node00:8485;node01:8485;node02:8485/sxt<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定HDFS客户端连接active namenode的java类 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.Sunrise<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 配置隔离机制为ssh 防止脑裂：保证activeNN仅有一台--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定秘钥的位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/.ssh/id_dsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--免密登录是生成的文件，有的是id_rsa--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 指定journalnode日志文件存储的路径 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启自动故障转移 --&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>配置hadoop中的slaves（主从架构：datanode）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node00</span><br><span class="line">node01</span><br><span class="line">node02</span><br></pre></td></tr></table></figure>
<p>  5.准备zookeeper</p>
<ul>
<li><p>三台zookeeper：node00，node01，node02</p>
</li>
<li><p>编辑zookeeper-3.4.13/conf/zoo.cfg</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/usr/soft/zookeeper-3.4.13/data</span><br><span class="line">dataLogDir=/usr/soft/zookeeper-3.4.13/logs</span><br><span class="line">clientPort=2181</span><br><span class="line">server.1=node00:2888:3888</span><br><span class="line">server.2=node01:2888:3888</span><br><span class="line">server.3=node02:2888:3888</span><br></pre></td></tr></table></figure>
</li>
<li><p>在dataDir目录中创建文件myid，三台节点的文件内容分别为1，2，3</p>
</li>
</ul>
<p>6.配置环境变量   </p>
<blockquote>
<p>vim ~/.bash_profile</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/soft/jdk1.8.0_191</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">HADOOP_HOME=/usr/soft/hadoop-2.6.5</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">ZOOKEEPER_HOME=/usr/soft/zookeeper-3.4.13</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure>
<blockquote>
<p>source ~/.bash_profile</p>
<p>使其成为资源文件，发送到其他节点后，也需要此操作</p>
</blockquote>
<p>7.将以上配置文件远程发送至其他节点服务器</p>
<blockquote>
<p>scp -r filename nodename:<code>pwd</code></p>
</blockquote>
<p>8.命令操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1. 启动三个zookeeper：./zkServer.sh start</span><br><span class="line">2. 启动三个JournalNode：./hadoop-daemon.sh start journalnode</span><br><span class="line">3. （生成fsimage文件）在其中一个namenode上格式化：</span><br><span class="line">    hdfs namenode -format</span><br><span class="line">4. 把刚刚格式化之后的元数据拷贝到另外一个namenode上</span><br><span class="line"> a)	启动刚刚格式化的namenode :  hadoop-daemon.sh start namenode</span><br><span class="line"> b)	（同步fsimage文件）在另一个（没有格式化的）namenode上执行：</span><br><span class="line">    hdfs namenode -bootstrapStandby</span><br><span class="line"> c)	启动没格式化的namenode：    hadoop-daemon.sh start namenode</span><br><span class="line">5. （初始化竞争锁zookeeper）在其中一个namenode上初始化zkfc：</span><br><span class="line">    hdfs zkfc -formatZK</span><br><span class="line">6. 停止上面节点：stop-dfs.sh</span><br><span class="line">7. 全面启动（三个节点）：start-dfs.sh</span><br><span class="line">8. 启动yarn资源管理器</span><br><span class="line">   yarn-daemon.sh start resourcemanager </span><br><span class="line">   (yarn resourcemanager  )</span><br></pre></td></tr></table></figure>
<h3 id="2、使用"><a href="#2、使用" class="headerlink" title="2、使用"></a>2、使用</h3><p>（启动步骤）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(1)关闭防火墙：service iptables stop        （3台）</span><br><span class="line">(2)启动zookeeper:zkServer.sh start          （3台）</span><br><span class="line">(3)启动集群：start-dfs.sh |（start-all.sh   :  同时启动hdfs和yarn)</span><br><span class="line">(4)启动yarn：yarn-daemon.sh start resourcemanager （可3台）</span><br></pre></td></tr></table></figure>
<p>（关闭步骤）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(1)关闭yarn：yarn-daemon.sh stop resourcemanager  （开几台关几台）</span><br><span class="line">(2)关闭集群：stop-dfs.sh   |（stop-all.sh    :同时关闭hdfs和yarn） （3台）</span><br><span class="line">(3)关闭zookeeper：zkServer.sh stop                 （3台）</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">有可能会出错的地方</span><br><span class="line">1，	确认每台机器防火墙均关掉</span><br><span class="line">2，	确认每台机器的时间是一致的</span><br><span class="line">3，	确认配置文件无误，并且确认每台机器上面的配置文件一样</span><br><span class="line">4，	如果还有问题想重新格式化，那么先把所有节点的进程关掉</span><br><span class="line">5，	删除之前格式化的数据目录hadoop.tmp.dir属性对应的目录，所有节点同步都删掉，别单删掉之前的一个，删掉三台JN节点中dfs.journalnode.edits.dir属性所对应的目录</span><br><span class="line">6，	接上面的第6步又可以重新格式化已经启动了</span><br><span class="line">7，	最终Active Namenode停掉的时候，StandBy可以自动接管！</span><br></pre></td></tr></table></figure>

      </div>
        <div class="support-author">
          <p>感谢您的阅读。 🙏
          <a href="https://888.com/index.html" target="_blank">关于转载请看这里</a>
            <!--<a class="btn-pay"  href="#pay-modal">¥ 打赏支持</a>-->
          </p>
        </div>
        <!--
            <div class="like ">
              <div class="like-button">
                <a id="like-note" href="">
                  <i class="icon-heart"></i>喜欢
                </a>
              </div>
              <span id="likes-count">256</span>
            </div>
        -->
        <div class="otherLink">
          <div class="previous">
          </div>
          <div class="next">
          </div>
        </div>
        <div class="comments" id="comments">
          
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script type="text/javascript">
  const gitalk = new Gitalk({
    clientID: '6b3c35f853de938a9612',
    clientSecret: '70003661fc70b011a32d9d1b2197666021305201',
    repo: 'sungithup.github.io',
    owner: 'admin',
    admin: ['admin'],
    id: location.pathname,      // Ensure uniqueness and length less than 50
    distractionFreeMode: false
  })

  gitalk.render('comments');
</script>


        </div>
      </div>
    </div>
   
</main>
<div class="footer">
  <div class="info">
    <p>
    <a href="https://hexo.io"> Hexo </a> 强力驱动 |
      <a href="https://github.com/Youthink/hexo-themes-yearn"> Yearn </a>
      主题
    </p>
    <p>&copy;2013-2019 Sukie的个人博客 京ICP备xxxxxx号</p>
  </div>
</div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script>//console
  var consoleConfig = '\n欢迎访问 https://hufangyun.com ，围观小猿大圣的博客(づ｡◕‿‿◕｡)づ！\n,\n本博客使用 %cHexo%c 搭建，博客主题为小猿大圣开发的 %chexo-themes-yearn%c ~~~ 🎉🎉🎉 \n\n源码 https://github.com/Youthink/hexo-themes-yearn \n\n如果喜欢可以 star 支持一下 ❤️~\n,\n扫描下面的二维码，在手机上查看博客！\n,https://static.hufangyun.com/blog-url-qrcode-180-180.png,\n 想知道这个效果如何实现的？博客内搜索 console 彩蛋 🚀 ！\n'.split(',');
  var canConsole = true;
  var consoleInfo = (function(consoleConfig) {
  if (!canConsole || !consoleConfig || consoleConfig.length < 1) {
    return;
  }
  var consoleColor = '#6190e8';
  var _console;
  var backgroundTextStyle = 'padding: 1px 5px;color: #fff;background: ' + consoleColor + ';'
  var textStyle = 'color: ' + consoleColor + ';';

  consoleConfig.map(o => {
    var num = (o.match(/%c/g) || []).length;
    if(/^http(s)?:\/\//.test(o)) {
      console.log('%c     ', 'background: url(' + o + ') no-repeat left center;font-size: 180px;');
      return;
    }
    if (num > 0) {
      var logArguments = [];
      for (var i = 0; i < num; i++) {
        if (i % 2 === 0) {
          logArguments.push(backgroundTextStyle);
        } else {
          logArguments.push(textStyle);
        }
      }
      (_console = console).log.apply(_console, ['%c' + o, textStyle].concat(logArguments));
      return;
    }
    console.log('%c' + o, textStyle);
  });
}(consoleConfig));</script><script type="text/javascript" src="/./js/main.d9e3dd.js"></script>

</body>
</html>
