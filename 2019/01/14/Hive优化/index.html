<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta name="keywords" content="">
  <meta name="description" content="">
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://busuanzi.ibruce.info">
  
  
  <link rel="dns-prefetch" href="https://hm.baidu.com/">
  
  
  <link rel="stylesheet" type="text/css" href="/./style/main.d9e3dd.css">
	<link rel="shortcut icon" href="" title="Favicon">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
	<title>Hive优化</title>
  
  
</head>
<body>
<canvas id="pattern-placeholder" height="230"></canvas>
<div class="navbar-header">
  <a class="blog-title" href="/">Sunrise山脉</a>
  <a class="face-img" href="/">
    <img src="">
  </a>
</div>
<main>
  <div class="article-title">
    
    <ul class="article-info">
      <li>
        发布
        
      </li>
      <li>
        
      </li>
      <li id="busuanzi_container_page_pv">
        阅读 <span id="busuanzi_value_page_pv"></span>
      </li>
    </ul>
  </div>
  <div class="container">
    <div class="article">
      <div class="content">
        
        <p>[TOC]</p>
<h1 id="Hive优化"><a href="#Hive优化" class="headerlink" title="Hive优化"></a>Hive优化</h1><h2 id="一、核心思想："><a href="#一、核心思想：" class="headerlink" title="一、核心思想："></a>一、核心思想：</h2><blockquote>
<p>把Hive SQL 当做MapReduce程序进行优化</p>
</blockquote>
<p><code>注意：</code>以下不能HQL转化为Mapreduce任务运行</p>
<p>—select 仅查询本表字段</p>
<p>—where 仅对本表字段做条件过滤</p>
<h2 id="二、explain"><a href="#二、explain" class="headerlink" title="二、explain"></a>二、explain</h2><blockquote>
<p>用以显示任务执行计划</p>
<p>格式：</p>
<p>EXPLAIN [EXTENDED|DEPENDENCY|AUTHORIZATION] query</p>
</blockquote>
<p><code>语法解释</code></p>
<blockquote>
<p>从语法组成可以看出来是一个“explain ”+三个可选参数+查询语句。大家可以积极尝试一下，后面两个显示内容很简单的，我介绍一下第一个 extended 这个可以显示hql语句的语法树</p>
<p>其次，执行计划一共有三个部分：</p>
<ul>
<li>这个语句的抽象语法树</li>
<li><p>这个计划不同阶段之间的依赖关系</p>
</li>
<li><p>对于每个阶段的详细描述</p>
</li>
</ul>
</blockquote>
<p><code>例子：</code></p>
<blockquote>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; hive&gt; explain select * from log;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p><code>拓展</code>课下查询MySQl的执行计划。</p>
<h2 id="三、Hive运行方式"><a href="#三、Hive运行方式" class="headerlink" title="三、Hive运行方式"></a>三、Hive运行方式</h2><h3 id="集群模式："><a href="#集群模式：" class="headerlink" title="集群模式："></a>集群模式：</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">执行hql：</span><br><span class="line">hive&gt; select count(*) from log;</span><br></pre></td></tr></table></figure>
<p><code>结论：</code></p>
<blockquote>
<p>函数（如count）是在reduce阶段进行<br>默认提交到yarn所在的节点上运行，</p>
</blockquote>
<hr>
<h3 id="优化一"><a href="#优化一" class="headerlink" title="优化一:"></a>优化一:</h3><p>设置  本地模式（运行速度加快。但对加载文件有限制）</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;set hive.exec.mode.local.auto=true;</span><br><span class="line"></span><br><span class="line">查看：</span><br><span class="line">hive&gt;set hive.exec.mode.local.auto</span><br></pre></td></tr></table></figure>
<p><code>但是</code>如果加载文件的最大值大于配置（默认配置为100M），仍会使用集群模式运行（在yarn所在的节点）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">查看最大加载文件</span><br><span class="line">hive&gt; set hive.exec.mode.local.auto.inputbytes.max;</span><br><span class="line"></span><br><span class="line">显示：</span><br><span class="line">hive.exec.mode.local.auto.inputbytes.max=134217728</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="优化二："><a href="#优化二：" class="headerlink" title="优化二："></a>优化二：</h3><p>设置 严格模式</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">通过设置以下参数开启严格模式[防止误操作]：</span><br><span class="line">hive&gt; set hive.mapred.mode=strict;</span><br><span class="line">（默认为：nonstrict非严格模式）</span><br></pre></td></tr></table></figure>
<p><code>但是</code>存在查询限制</p>
<blockquote>
<p>1、对分区表查询时，必须添加where对于分区字段的条件过滤；</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; hive&gt; select * from day_table where dt='2019-01-13';</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>2、order by语句必须包含limit输出限制；</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; hive&gt; select * from log order by id limit 1;</span><br><span class="line">&gt; 这里的1， 表示显示前多少条记录，只能设一个数字</span><br><span class="line">&gt; 和Mysql（可以从0 开始）不同的是，它只能从1开始</span><br><span class="line">&gt; mysql可以有两个数字，表示从第几条开始，显示几条</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>3、限制执行笛卡尔积的查询</p>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1fzhry9ni0xj30m10cjdgp.jpg" alt="imit"><span class="img-alt">imit</span></p>
<h2 id="四、Hive排序"><a href="#四、Hive排序" class="headerlink" title="四、Hive排序"></a>四、Hive排序</h2><h3 id="1、Order-By"><a href="#1、Order-By" class="headerlink" title="1、Order By"></a>1、Order By</h3><p>— 对于查询结果做<code>全局</code>排序，只允许有<code>一个</code>reduce处理<br>（当数据量较大时，reduce数量有限，应慎用。</p>
<p>​     严格模式下，必须结合limit来使用）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from log order by id；</span><br></pre></td></tr></table></figure>
<h3 id="2、Sort-By"><a href="#2、Sort-By" class="headerlink" title="2、Sort By"></a>2、Sort By</h3><p>– 对于<code>单个</code>reduce的数据进行排序</p>
<p>–局部（单个reduce）有序，全局无序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可以通过设置mapred.reduce.tasks的值来控制reduce的数，然后对reduce输出的结果做二次排序</span><br></pre></td></tr></table></figure>
<p><code>案例</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> <span class="keyword">sort</span> <span class="keyword">by</span> <span class="keyword">id</span>;       (结果无序)</span><br></pre></td></tr></table></figure>
<p><code>显示</code></p>
<blockquote>
<p>Time taken: 147.077 seconds, Fetched: 7 row(s)</p>
</blockquote>
<h3 id="3、Distribute-By"><a href="#3、Distribute-By" class="headerlink" title="3、Distribute By"></a>3、Distribute By</h3><p>– 分区排序，经常和 Sort By 结合使用 全局有序，局部无序</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> <span class="keyword">distribute</span> <span class="keyword">by</span> <span class="keyword">id</span>;     （结果无序）</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Time taken: 144.708 seconds, Fetched: 7 row(s)</p>
</blockquote>
<p><code>注意：</code>hive要求DISTRIBUTE BY语句出现在SORT BY语句之前</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Distribute By可以将Map阶段输出的数据按指定的字段划分到不同的reduce文件中，然后，sort by 对reduce阶段的输出数据做排序。</span><br></pre></td></tr></table></figure>
<p><code>案例:</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> <span class="keyword">distribute</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">sort</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">asc</span>;   （结果无序）</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from (select * from log distribute by id) a sort by a.id ;s</span><br></pre></td></tr></table></figure>
<p><code>改良</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.* <span class="keyword">from</span> (<span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> cluster <span class="keyword">by</span> <span class="keyword">id</span> ) a <span class="keyword">order</span> <span class="keyword">by</span> a.id <span class="keyword">limit</span> <span class="number">9</span> ; (结果有序)</span><br><span class="line"></span><br><span class="line">9 在这里是表中数据记录的总条数</span><br></pre></td></tr></table></figure>
<p>显示：</p>
<blockquote>
<p> Time taken: 234.593 seconds, Fetched: 7 row(s)</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">limit</span> <span class="number">9</span>;    （结果有序）</span><br></pre></td></tr></table></figure>
<p>显示：</p>
<blockquote>
<p> Time taken: 102.065 seconds, Fetched: 7 row(s)</p>
</blockquote>
<h3 id="4、Cluster-By"><a href="#4、Cluster-By" class="headerlink" title="4、Cluster By"></a>4、Cluster By</h3><p>– 相当于 Sort By + Distribute By<br>（Cluster By不能通过asc、desc的方式指定排序规则；<br>可通过 distribute by column sort by column asc|desc 的方式）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> cluster <span class="keyword">by</span> <span class="keyword">id</span>；    （结果无序）</span><br></pre></td></tr></table></figure>
<h2 id="五、Hive-Join-（重难点）"><a href="#五、Hive-Join-（重难点）" class="headerlink" title="五、Hive Join  （重难点）"></a>五、Hive Join  （重难点）</h2><h3 id="1、Join-连接时，将小表（驱动表）放在join的左边"><a href="#1、Join-连接时，将小表（驱动表）放在join的左边" class="headerlink" title="1、Join 连接时，将小表（驱动表）放在join的左边"></a>1、Join 连接时，将小表（驱动表）放在join的左边</h3><h3 id="2、Map-Join-："><a href="#2、Map-Join-：" class="headerlink" title="2、Map Join ："></a>2、Map Join ：</h3><blockquote>
<p>因为Map Join 是在Map端且在内存中进行的，所以不需要启动Reduce任务，也没有shuffle阶段，从而在一定程度上节省资源，提高Join效率。</p>
</blockquote>
<h3 id="方式：（两种）"><a href="#方式：（两种）" class="headerlink" title="方式：（两种）"></a>方式：（两种）</h3><h4 id="1、SQL方式："><a href="#1、SQL方式：" class="headerlink" title="1、SQL方式："></a>1、SQL方式：</h4><p>​     在HQl语句中添加MapJoin标记（mapjoin）(将小表加入到内存，注意小表的大小)</p>
<p>​     语法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(smallTable) */</span>  smallTable.key,  bigTable.value </span><br><span class="line"><span class="keyword">FROM</span>  smallTable  <span class="keyword">JOIN</span>  bigTable  <span class="keyword">ON</span>  smallTable.key  = bigTable.key;</span><br></pre></td></tr></table></figure>
<p><code>案例：</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(log1) */</span>  log.id,log1.name </span><br><span class="line"><span class="keyword">FROM</span>  <span class="keyword">log</span>  <span class="keyword">JOIN</span>  log1  <span class="keyword">ON</span>  log.id  = log1.id;</span><br></pre></td></tr></table></figure>
<h4 id="2、自动的MapJoin"><a href="#2、自动的MapJoin" class="headerlink" title="2、自动的MapJoin"></a>2、自动的MapJoin</h4><p>​           通过修改以下配置启用自动的mapjoin：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.auto.convert.join = true;</span><br></pre></td></tr></table></figure>
<p>​    （  该参数为true时，Hive自动对左边的表统计数据量，如果是小表就加入内存，即对小表使用Map join）<br>其他相关配置参数：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.mapjoin.smalltable.filesize;</span><br></pre></td></tr></table></figure>
<p>（默认：大表小表判断的阈值25MB左右，如果表的大小小于该值则会被加载到内存中运行，可自定义）</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.ignore.mapjoin.hint;</span><br></pre></td></tr></table></figure>
<p>（默认值：true；是否忽略mapjoin hint 即mapjoin标记；如果为false，这则需要添加-MapJoin标记，mapjoin（smalltable））</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.auto.convert.join.noconditionaltask;</span><br></pre></td></tr></table></figure>
<p>（默认值：true；将普通的join转化为普通的mapjoin时，是否将多个mapjoin转化为一个mapjoin）</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.auto.convert.join.noconditionaltask.size;</span><br></pre></td></tr></table></figure>
<p>（默认：10M；将多个mapjoin转化为一个mapjoin时，其表的最大值为10M，可自定义）</p>
<h2 id="六、Map-Side聚合"><a href="#六、Map-Side聚合" class="headerlink" title="六、Map-Side聚合"></a>六、Map-Side聚合</h2><blockquote>
<p>相当于聚合函数：count（）</p>
</blockquote>
<p>设置参数，开启在Map端的聚合</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>
<p>相关配置参数：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.groupby.mapaggr.checkinterval；</span><br></pre></td></tr></table></figure>
<p>（默认为：100000，表示 map端group by执行聚合时处理的多少行数据）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr.hash.min.reduction；</span><br></pre></td></tr></table></figure>
<p>（默认为：0.5，进行聚合的最小比例，预先取100000条数据聚合,如果聚合后的条数/100000&gt;0.5，则不再聚合）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr.hash.percentmemory;</span><br></pre></td></tr></table></figure>
<p>（默认： 0.5 ，map端聚合使用的内存的最大值）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr.hash.force.flush.memory.threshold;</span><br></pre></td></tr></table></figure>
<p>（默认为：0.9，map端做聚合操作是hash表的最大可用内容，大于该值则会触发flush</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.groupby.skewindata；</span><br></pre></td></tr></table></figure>
<p>（默认为：false，是否对GroupBy产生的数据倾斜做优化）</p>
<p><code>附加：</code></p>
<blockquote>
<ul>
<li>数据倾斜问题解决：多种方式（使用MapJoin、使用MapSide）</li>
</ul>
</blockquote>
<p><code>参考</code></p>
<p><a href="http://www.sohu.com/a/224276626_543508" target="_blank" rel="noopener">http://www.sohu.com/a/224276626_543508</a></p>
<h2 id="七、控制Hive中Map和Reduce的数量"><a href="#七、控制Hive中Map和Reduce的数量" class="headerlink" title="七、控制Hive中Map和Reduce的数量"></a>七、控制Hive中Map和Reduce的数量</h2><h3 id="1、Map数量相关的参数"><a href="#1、Map数量相关的参数" class="headerlink" title="1、Map数量相关的参数"></a>1、Map数量相关的参数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.max.split.size;</span><br></pre></td></tr></table></figure>
<p>（默认为：256M，一个split的最大值，即每个map处理文件的最大值）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.min.split.size.per.node;</span><br></pre></td></tr></table></figure>
<p>(一个节点上最小split数：1个)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.min.split.size.per.rack;</span><br></pre></td></tr></table></figure>
<p>(一个机架上最小split数：1个)</p>
<h3 id="2、Reduce数量相关的参数"><a href="#2、Reduce数量相关的参数" class="headerlink" title="2、Reduce数量相关的参数"></a>2、Reduce数量相关的参数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.reduce.tasks;</span><br></pre></td></tr></table></figure>
<p>(默认为：-1，强制指定reduce任务的数量。-1，是未定义，不发挥作用。如果指定了，就会按指定的数量执行)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer;</span><br></pre></td></tr></table></figure>
<p>（默认为：256M ，每个reduce任务处理的数据量）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.reducers.max;</span><br></pre></td></tr></table></figure>
<p>（默认为：1009个，每个任务最大的reduce数 [Map数量 &gt;= Reduce数量 ]）</p>
<h2 id="八、Hive-JVM重用"><a href="#八、Hive-JVM重用" class="headerlink" title="八、Hive - JVM重用"></a>八、Hive - JVM重用</h2><p><code>适用场景：</code><br>1、小文件个数过多<br>2、task个数过多</p>
<p><code>原理：</code></p>
<p>hadoop默认配置是使用派生JVM来执行map和reduce任务的，JVM重用可以使得JVM实例在同一个JOB中重新使用N次</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.job.reuse.jvm.num.tasks;</span><br></pre></td></tr></table></figure>
<p>(默认是1，表示一个JVM上最多可以顺序执行的task数目（属于同一个Job）是1。也就是说一个task启一个JVM)</p>
<p><code>缺点：</code></p>
<p>设置开启之后，task插槽会一直占用资源，不论是否有task运行，<br>直到所有的task即整个job全部执行完成时，才会释放所有的task插槽资源！</p>

      </div>
        <div class="support-author">
          <p>感谢您的阅读。 🙏
          <a href="" target="_blank">关于转载请看这里</a>
            <!--<a class="btn-pay"  href="#pay-modal">¥ 打赏支持</a>-->
          </p>
        </div>
        <!--
            <div class="like ">
              <div class="like-button">
                <a id="like-note" href="">
                  <i class="icon-heart"></i>喜欢
                </a>
              </div>
              <span id="likes-count">256</span>
            </div>
        -->
        <div class="otherLink">
          <div class="previous">
          </div>
          <div class="next">
          </div>
        </div>
        <div class="comments" id="comments">
          
        </div>
      </div>
    </div>
   
</main>
<div class="footer">
  <div class="info">
    <p>
    <a href="https://hexo.io"> Hexo </a> 强力驱动 |
      <a href="https://github.com/Youthink/hexo-themes-yearn"> Yearn </a>
      主题
    </p>
    <p>&copy; </p>
  </div>
</div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script>//console
  var consoleConfig = ''.split(',');
  var canConsole = ;
  var consoleInfo = (function(consoleConfig) {
  if (!canConsole || !consoleConfig || consoleConfig.length < 1) {
    return;
  }
  var consoleColor = '#6190e8';
  var _console;
  var backgroundTextStyle = 'padding: 1px 5px;color: #fff;background: ' + consoleColor + ';'
  var textStyle = 'color: ' + consoleColor + ';';

  consoleConfig.map(o => {
    var num = (o.match(/%c/g) || []).length;
    if(/^http(s)?:\/\//.test(o)) {
      console.log('%c     ', 'background: url(' + o + ') no-repeat left center;font-size: 180px;');
      return;
    }
    if (num > 0) {
      var logArguments = [];
      for (var i = 0; i < num; i++) {
        if (i % 2 === 0) {
          logArguments.push(backgroundTextStyle);
        } else {
          logArguments.push(textStyle);
        }
      }
      (_console = console).log.apply(_console, ['%c' + o, textStyle].concat(logArguments));
      return;
    }
    console.log('%c' + o, textStyle);
  });
}(consoleConfig));</script><script type="text/javascript" src="/./js/main.d9e3dd.js"></script>

</body>
</html>
