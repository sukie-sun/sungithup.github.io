<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="Sukie">



<meta name="description" content="资源调优，并行度调优，代码调优，数据本地化级别，内存调优，sparkshuffle调优，调节excutor的堆外内存，解决数据倾斜，spark故障解决">
<meta name="keywords" content="资源,内存,数据倾斜">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark调优">
<meta property="og:url" content="http://sungithup.github.io/2019/02/23/Spark优化/index.html">
<meta property="og:site_name" content="Sukie山脉">
<meta property="og:description" content="资源调优，并行度调优，代码调优，数据本地化级别，内存调优，sparkshuffle调优，调节excutor的堆外内存，解决数据倾斜，spark故障解决">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21btcmi0aj309d06tt9e.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21bugz8otj30bp0cdwfu.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21bvbr619j309j07a3yr.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21bw26vmxj30910bcmxv.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21bwjhtyfj30ek08owf7.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21bxft53yj30d709iq33.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21c00ck9yj30ek078t9g.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21c0ylpoxj30ek06ijsi.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21c1yursmj30ek08fmyp.jpg">
<meta property="og:updated_time" content="2019-04-17T03:38:28.416Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark调优">
<meta name="twitter:description" content="资源调优，并行度调优，代码调优，数据本地化级别，内存调优，sparkshuffle调优，调节excutor的堆外内存，解决数据倾斜，spark故障解决">
<meta name="twitter:image" content="https://ws1.sinaimg.cn/large/005zftzDgy1g21btcmi0aj309d06tt9e.jpg">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Sukie山脉" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Spark调优 | Sukie山脉</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>





    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?bc39ced90d9f89c71fda7b7d4ca8b638";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script>


</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Sukie</a></h1>
        </hgroup>

        
        <p class="header-subtitle">肆意玩耍，肆意高歌</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false">
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class="no-result">No results found <i class="fa fa-spinner fa-pulse"></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/essays/">推荐</a></li>
                        
                            <li><a href="/books/">书籍</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:sunyaru216@163.com" title="Email"></a>
                            
                                <a class="fa 新浪微博" href="http://weibo.com/sunrise200 " title="新浪微博"></a>
                            
                                <a class="fa GitHub" href="https://github.com/sungithup" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa 博客园" href="/cnblogs" title="博客园"></a>
                            
                                <a class="fa CSDN" href="/" title="CSDN"></a>
                            
                                <a class="fa 网易云音乐" href="https://music.163.com/#/song?id=18949687" title="网易云音乐"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Array/">Array</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CDH/">CDH</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CentOS-6/">CentOS 6</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/">HBase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JVM/">JVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux命令/">Linux命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux系统环境/">Linux系统环境</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/List/">List</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Map/">Map</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/">Nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/">Redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL语句/">SQL语句</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Set/">Set</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark-shell/">Spark shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkCore/">SparkCore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkShuffle/">SparkShuffle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkSql/">SparkSql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkStreaming/">SparkStreaming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark框架/">Spark框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sqoop/">Sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Storm，流式处理框架/">Storm，流式处理框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/String/">String</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Zookeeper/">Zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maven/">maven</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shuffle调优/">shuffle调优</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sparkcore/">sparkcore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark内存管理/">spark内存管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web/">web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/yarn/">yarn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/内存/">内存</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式搜索和分析引擎/">分布式搜索和分析引擎</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式离线计算框架/">分布式离线计算框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分而治之/">分而治之</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/参数解释/">参数解释</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大型网站日志分析系统/">大型网站日志分析系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工作流调度引擎/">工作流调度引擎</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/广播/">广播</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据倾斜/">数据倾斜</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/流式处理框架/">流式处理框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/消息队列系统/">消息队列系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/源码分析/">源码分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/离线分析/">离线分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/累加/">累加</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编程语言/">编程语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算引擎/">计算引擎</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算框架/">计算框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/资源/">资源</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/静态/">静态</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">正宗小白</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Sukie</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Sukie</a></h1>
            </hgroup>
            
            <p class="header-subtitle">肆意玩耍，肆意高歌</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/essays/">推荐</a></li>
                
                    <li><a href="/books/">书籍</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:sunyaru216@163.com" title="Email"></a>
                            
                                <a class="fa 新浪微博" target="_blank" href="http://weibo.com/sunrise200 " title="新浪微博"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/sungithup" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa 博客园" target="_blank" href="/cnblogs" title="博客园"></a>
                            
                                <a class="fa CSDN" target="_blank" href="/" title="CSDN"></a>
                            
                                <a class="fa 网易云音乐" target="_blank" href="https://music.163.com/#/song?id=18949687" title="网易云音乐"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我">
</nav>
      <div class="body-wrap"><article id="post-Spark优化" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/23/Spark优化/" class="article-date">
      <time datetime="2019-02-22T16:00:00.000Z" itemprop="datePublished">2019-02-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark调优
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">7.6k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">28分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/内存/">内存</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据倾斜/">数据倾斜</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/资源/">资源</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>[TOC]</p>
<h1 id="1、资源调优"><a href="#1、资源调优" class="headerlink" title="1、资源调优"></a>1、资源调优</h1><h2 id="1）-在部署-spark-集群中"><a href="#1）-在部署-spark-集群中" class="headerlink" title="1）  在部署 spark 集群中"></a>1）  在部署 spark 集群中</h2><p>在部署 spark 集群中指定资源分配的默认参数 。</p>
<p>在 spark 安装包的 conf 下 spark-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_WORKER_CORES</span><br><span class="line">SPARK_WORKER_MEMORY</span><br><span class="line">SPARK_WORKER_INSTANCES  ##每台机器启动 worker 数</span><br></pre></td></tr></table></figure>
<h2 id="2）-在提交-Application-时"><a href="#2）-在提交-Application-时" class="headerlink" title="2）  在提交 Application 时"></a>2）  在提交 Application 时</h2><p>在提交 Application 的时候给当前的 Application 分配更多的资源</p>
<p>提交命令选项：（在提交 Application 的时候使用选项）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--executor-cores</span><br><span class="line">--executor-memory</span><br><span class="line">--total-executor-cores</span><br></pre></td></tr></table></figure>
<p>配置信息：（Application 的代码中设置或在 Spark-default.conf 中设置）</p>
<p>通过SparkConf  conf.set( ) 进行配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark.executor.cores</span><br><span class="line">spark. executor.memory</span><br><span class="line">spark.max.cores</span><br></pre></td></tr></table></figure>
<p>动态分配资源</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark.shuffle.service.enabled true ##启用 External shuffle Service 服务</span><br><span class="line">spark.shuffle.service.port 7337 ##Shuffle Service 服务端口，必须和yarn-site 中的一致</span><br><span class="line">spark.dynamicAllocation.enabled true ##开启动态资源分配</span><br><span class="line">spark.dynamicAllocation.minExecutors 1 ##每个 Application 最小分配的executor 数</span><br><span class="line">spark.dynamicAllocation.maxExecutors 30 ##每个 Application 最大并发分配的 executor 数</span><br><span class="line">spark.dynamicAllocation.schedulerBacklogTimeout 1s</span><br><span class="line">spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s</span><br></pre></td></tr></table></figure>
<h1 id="2、并行度调优"><a href="#2、并行度调优" class="headerlink" title="2、并行度调优"></a>2、并行度调优</h1><p>1）  如果读取的数据在 HDFS 中，降低 block 大小，相当于提高了 RDD中 partition 个数 </p>
<p>一般产生shuffle（数据放在磁盘，shuffle就是从磁盘拉取数据到内存就可以重新部署）的算子都可以设置分区数达到并行度调优。</p>
<p>​       sc.textFile(xx,numPartitions)</p>
<p>2）  sc.parallelize(xxx, numPartitions)</p>
<p>3）  sc.makeRDD(xxx, numPartitions)      //Scala代码，类似于parallelize</p>
<p>4）  sc.parallelizePairs(xxx, numPartitions)</p>
<p>5）  repartions/coalesce</p>
<p>6）  redecByKey/groupByKey/join —(xxx, numPartitions)</p>
<p>7）  spark.default.parallelism net set</p>
<p>8）  spark.sql.shuffle.partitions—200</p>
<p>9）  自定义分区器（作用在K,V 格式的RDD上）partitionBy，或者在reduceByKey算子中，把自定义分区器用匿名内部类的形式作为参数传入。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, String&gt; partitionByPairRDD = </span><br><span class="line">       javaPairRDD.partitionBy(<span class="keyword">new</span> Partitioner() &#123;</span><br><span class="line">        <span class="comment">//定义分区规则</span></span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">               Integer value = Integer.parseInt((String)key);</span><br><span class="line">               <span class="keyword">return</span> value % <span class="number">3</span>;</span><br><span class="line">           &#125;</span><br><span class="line">         <span class="comment">//定义分成几个区</span></span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numPartitions</span><span class="params">()</span> </span>&#123;</span><br><span class="line">               <span class="keyword">return</span> <span class="number">3</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;);</span><br></pre></td></tr></table></figure>
<p>10） 如果读取数据是在 SparkStreaming 中</p>
<p>Receiver模式 ;设置blockInterval:   spark.streaming.blockInterval—200ms</p>
<p>Direct:由读取的 topic 的分区数决定并行度</p>
<h1 id="3、代码调优"><a href="#3、代码调优" class="headerlink" title="3、代码调优"></a>3、代码调优</h1><h2 id="1、避免创建重复的-RDD"><a href="#1、避免创建重复的-RDD" class="headerlink" title="1、避免创建重复的 RDD"></a>1、避免创建重复的 RDD</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(path1)</span><br><span class="line"><span class="keyword">val</span> rdd2 = sc.textFile(path1)</span><br></pre></td></tr></table></figure>
<p>这就是创建了重复的 RDD<br>有什么问题？ 对于执行性能来说没有问题，但是呢，代码乱</p>
<h2 id="2、复用同一个-RDD"><a href="#2、复用同一个-RDD" class="headerlink" title="2、复用同一个 RDD"></a>2、复用同一个 RDD</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = <span class="type">RDD</span>&lt;<span class="type">String</span>,<span class="type">String</span>&gt;</span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.map(_._2)</span><br></pre></td></tr></table></figure>
<p>这样的话 rdd2 是 rdd1 的子集。 rdd2 执行了一个操作 filter</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd2.filter()= rdd1.map（(_._2)）.filter()</span><br></pre></td></tr></table></figure>
<p>复用同一个RDD时，对这个RDD做cache持久化 ，就可以避免对这个RDD的重复计算。</p>
<h2 id="3、对多次使用的-RDD-进行持久化"><a href="#3、对多次使用的-RDD-进行持久化" class="headerlink" title="3、对多次使用的 RDD 进行持久化"></a>3、对多次使用的 RDD 进行持久化</h2><h3 id="选择最合适的持久化策略？"><a href="#选择最合适的持久化策略？" class="headerlink" title="选择最合适的持久化策略？"></a>选择最合适的持久化策略？</h3><p>​        MEMORY_ONLY    (默认)</p>
<p>​         性能最高，但要求内存必须足够大，可存放下整个 RDD 的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个 RDD 的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种策略的场景还是有限的，如果 RDD 中数据比较多时（比如几十亿），<br>直接用这种持久化级别，会导致 JVM 的 OOM 内存溢出异常。</p>
<p>​         MEMORY_ONLY_SER   （建议）</p>
<p>​        该级别会将 RDD 数据序列化后再保存在内存中，此时每个 partition 仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别比 MEMORY_ONLY 多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。如果RDD 中的数据量过多的话，还是可能会导致 OOM 内存溢出的异常。</p>
<p>​      MEMORY_AND_DISK_SER   （建 议）</p>
<p>​    适用于纯内存的级别都无法使用 ,RDD 的数据量很大，内存无法完全放下时。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。</p>
<p>​      DISK_ONLY 和后缀为_2      （不建议）</p>
<p>​      因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，有时还不如重新计算一次所有RDD。后缀为_2 的级别，必须将所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建议使用。</p>
<h3 id="持久化算子："><a href="#持久化算子：" class="headerlink" title="持久化算子："></a>持久化算子：</h3><h4 id="（1）cache"><a href="#（1）cache" class="headerlink" title="（1）cache:"></a>（1）cache:</h4><p> MEMORY_ONLY</p>
<h4 id="（2）persist："><a href="#（2）persist：" class="headerlink" title="（2）persist："></a>（2）persist：</h4><p>MEMORY_ONLY<br>MEMORY_ONLY_SER<br>MEMORY_AND_DISK_SER<br>一般不要选择带有_2 的持久化级别。</p>
<h4 id="（3）checkpoint"><a href="#（3）checkpoint" class="headerlink" title="（3）checkpoint:"></a>（3）checkpoint:</h4><p>① 如果一个 RDD 的计算时间比较长或者计算起来比较复杂，一般将这个 RDD 的计算结果保存到 HDFS 上，这样数据会更加安全。优化方案：在需要checkpoint的地方调用cache或persist ，提高效率。<br>② 如果一个 RDD 的依赖关系非常长，也会使用 checkpoint,会切断依赖关系，提高容错的效率。</p>
<h2 id="4、尽量避免使用-shuffle-类的算子"><a href="#4、尽量避免使用-shuffle-类的算子" class="headerlink" title="4、尽量避免使用 shuffle 类的算子"></a>4、尽量避免使用 shuffle 类的算子</h2><p>使用广播变量来模拟使用 join,使用情况：一个 RDD 比较大，一个 RDD比较小。</p>
<p>join 算子=广播变量+filter、广播变量+map、广播变量+flatMap</p>
<h2 id="5、使用-map-side-预聚合的-shuffle-操作"><a href="#5、使用-map-side-预聚合的-shuffle-操作" class="headerlink" title="5、使用 map-side 预聚合的 shuffle 操作"></a>5、使用 map-side 预聚合的 shuffle 操作</h2><p>即尽量使用有 combiner 的 shuffle 类算子。</p>
<h3 id="combiner-概念："><a href="#combiner-概念：" class="headerlink" title="combiner 概念："></a>combiner 概念：</h3><p>在 map 端，每一个 map task 计算完毕后进行的局部聚合。</p>
<h3 id="combiner-好处："><a href="#combiner-好处：" class="headerlink" title="combiner 好处："></a>combiner 好处：</h3><p>1) 降低 shuffle write 写磁盘的数据量。</p>
<p>2) 降低 shuffle read 拉取数据量的大小。</p>
<p>3) 降低 reduce 端聚合的次数。</p>
<h3 id="有-combiner-的-shuffle-类算子："><a href="#有-combiner-的-shuffle-类算子：" class="headerlink" title="有 combiner 的 shuffle 类算子："></a>有 combiner 的 shuffle 类算子：</h3><p>1) reduceByKey:</p>
<p>这个算子在 map 端是有 combiner 的，在一些场景中可以使用 reduceByKey 代替 groupByKey。</p>
<p>2) aggregateByKey</p>
<p>3) combineByKey</p>
<h2 id="6、尽量使用高性能的算子"><a href="#6、尽量使用高性能的算子" class="headerlink" title="6、尽量使用高性能的算子"></a>6、尽量使用高性能的算子</h2><p>使用 reduceByKey 替代 groupByKey</p>
<p>使用 mapPartition 替代 map</p>
<p>使用 foreachPartition 替代 foreach</p>
<p>filter 后使用 coalesce 减少分区数</p>
<p>使用使用repartitionAndSortWithinPartitions 替代repartition与sort类操作</p>
<p>使用 repartition 和 coalesce 算子操作分区。</p>
<h2 id="7、使用广播变量"><a href="#7、使用广播变量" class="headerlink" title="7、使用广播变量"></a>7、使用广播变量</h2><p>​        开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如 100M 以上的大集合），那么此时就应该使用 Spark 的广播(Broadcast）功能来提升性能，函数中使用到外部变量时，默认情况下，Spark 会将该变量复制多个副本，通过网络传输到 task 中，此时每个 task都有一个变量副本。如果变量本身比较大的话（比如 100M，甚至 1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor 中占用过多内存导致的频繁 GC，都会极大地影响性能。如果使用的外部变量比较大，建议使用 Spark 的广播功能，对该变量进行广播。广播后的变量，会保证每个 Executor 的内存中，只驻留一份变量副本，</p>
<p>​       而 Executor 中的 task 执行时共享该 Executor 中的那份变量副本。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对 Executor 内存的占用开销，降低 GC 的频率。</p>
<p>​       广播大变量发送方式：</p>
<p>Executor 一开始并没有广播变量，而是 task 运行需 要 用 到 广 播 变 量 ， 会 找 executor 的 blockManager 要 ，bloackManager 找 Driver 里面的 blockManagerMaster 要。使用广播变量可以大大降低集群中变量的副本数。不使用广播变量，变量的副本数和 task 数一致。使用广播变量变量的副本和 Executor 数一致。</p>
<h2 id="8、使用-Kryo-优化序列化性能"><a href="#8、使用-Kryo-优化序列化性能" class="headerlink" title="8、使用 Kryo 优化序列化性能"></a>8、使用 Kryo 优化序列化性能</h2><p>在 Spark 中，主要有三个地方涉及到了序列化：</p>
<p>1) 在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输。</p>
<p>2) 将自定义的类型作为 RDD 的泛型类型时（比如 JavaRDD<ttt>，TTT是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现 Serializable 接口。</ttt></p>
<p>3) 使用可序列化的持久化策略时（比如 MEMORY_ONLY_SER），Spark会将 RDD 中的每个 partition 都序列化成一个大的字节数组。</p>
<p>Kryo 序列化器介绍：<br>Spark 支持使用 Kryo 序列化机制。Kryo 序列化机制，比默认的 Java 序列化机制，速度要快，序列化后的数据要更小，大概是 Java 序列化机制的 1/10。所以 Kryo 序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。对于这三种出现序列化的地方，我们都可以通过使用 Kryo 序列化类库，来优化序列化和反序列化的性能。Spark 默认使用的是 Java 的序列化机制，也就是 ObjectOutputStream/ObjectInputStream API 来进行序列化和反序列化。但是 Spark 同时支持使用 Kryo 序列化库，Kryo 序列化类库的性能比 Java 序列化类库的性能要高很多。官方介绍，Kryo 序列化机制比 Java 序列化机制，性能高 10 倍左右。Spark 之所以默认没有使用Kryo 作为序列化类库，是因为 Kryo 要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说这种方式比较麻烦。</p>
<p>Spark 中使用 Kryo：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Sparkconf.set(&quot;spark.serializer&quot;,</span><br><span class="line">&quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">.registerKryoClasses(new Class[]&#123;SpeedSortKey.class&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="9、优化数据结构"><a href="#9、优化数据结构" class="headerlink" title="9、优化数据结构"></a>9、优化数据结构</h2><h3 id="java-中有三种类型比较消耗内存："><a href="#java-中有三种类型比较消耗内存：" class="headerlink" title="java 中有三种类型比较消耗内存："></a>java 中有三种类型比较消耗内存：</h3><p>1) 对象，每个 Java 对象都有对象头、引用等额外的信息，因此比较占用内存空间。</p>
<p>2) 字符串，每个字符串内部都有一个字符数组以及长度等额外信息。</p>
<p>3) 集合类型，比如 HashMap、LinkedList 等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如 Map.Entry。</p>
<p>因此 Spark 官方建议，在 Spark 编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型（比如 Int、Long）替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用，从而降低 GC 频率，提升性能。</p>
<h2 id="10、使用高性能的库-fastutil"><a href="#10、使用高性能的库-fastutil" class="headerlink" title="10、使用高性能的库 fastutil"></a>10、使用高性能的库 fastutil</h2><h3 id="fasteutil-介绍："><a href="#fasteutil-介绍：" class="headerlink" title="fasteutil 介绍："></a>fasteutil 介绍：</h3><ul>
<li><p>fastutil 是扩展了 Java 标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的 map、set、list 和 queue；</p>
</li>
<li><p>fastutil 能够提供更小的内存占用，更快的存取速度；</p>
</li>
</ul>
<p>我们使用 fastutil提供的集合类，来替代自己平时使用的 JDK 的原生的 Map、List、Set，好处在于，fastutil 集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者 key）获取元素的值和设置元素的值的时候，提供更快的存取速度。fastutil 的每一种集合类型，都实现了对应的 Java 中的标准接口（比如 fastutil 的 map，实现了 Java 的 Map 接口），因此可以直接放入已有系统的任何代码中。</p>
<ul>
<li>fastutil 最新版本要求 Java 7 以及以上版本。</li>
</ul>
<h3 id="使用："><a href="#使用：" class="headerlink" title="使用："></a>使用：</h3><p>见 RandomExtractCars.java 类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, Map&lt;String, IntList&gt;&gt; fastutilDateHourExtractMap = </span><br><span class="line">                                <span class="keyword">new</span> HashMap&lt;String, Map&lt;String, IntList&gt;&gt;();</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> (Map.Entry&lt;String, Map&lt;String, List&lt;Integer&gt;&gt;&gt; dateHourExtractEntry : dateHourExtractMap.entrySet()) &#123;</span><br><span class="line">			String date = dateHourExtractEntry.getKey();</span><br><span class="line">			Map&lt;String, List&lt;Integer&gt;&gt; hourExtractMap =</span><br><span class="line">                                       dateHourExtractEntry.getValue();</span><br><span class="line">            </span><br><span class="line">Map&lt;String, IntList&gt; fastutilHourExtractMap = <span class="keyword">new</span> HashMap&lt;String, IntList&gt;();</span><br><span class="line"></span><br><span class="line">     		<span class="keyword">for</span> (Map.Entry&lt;String, List&lt;Integer&gt;&gt; hourExtractEntry : hourExtractMap.entrySet()) &#123;</span><br><span class="line">				String hour = hourExtractEntry.getKey();</span><br><span class="line">				List&lt;Integer&gt; extractList = hourExtractEntry.getValue();</span><br><span class="line"></span><br><span class="line">				IntList fastutilExtractList = <span class="keyword">new</span> IntArrayList();</span><br><span class="line"></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; extractList.size(); i++) &#123;</span><br><span class="line">				fastutilExtractList.add(extractList.get(i));</span><br><span class="line">				&#125;</span><br><span class="line">				fastutilHourExtractMap.put(hour, fastutilExtractList);</span><br><span class="line">			&#125;</span><br><span class="line">		fastutilDateHourExtractMap.put(date, fastutilHourExtractMap);</span><br></pre></td></tr></table></figure>
<h1 id="4、数据本地化"><a href="#4、数据本地化" class="headerlink" title="4、数据本地化"></a>4、数据本地化</h1><h2 id="（1）数据本地化的级别："><a href="#（1）数据本地化的级别：" class="headerlink" title="（1）数据本地化的级别："></a>（1）数据本地化的级别：</h2><h3 id="1-PROCESS-LOCAL"><a href="#1-PROCESS-LOCAL" class="headerlink" title="1) PROCESS_LOCAL"></a>1) PROCESS_LOCAL</h3><p>task 要计算的数据在本进程（Executor）的内存中。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21btcmi0aj309d06tt9e.jpg" alt=""></p>
<h3 id="2-NODE-LOCAL"><a href="#2-NODE-LOCAL" class="headerlink" title="2) NODE_LOCAL"></a>2) NODE_LOCAL</h3><p>① task 所计算的数据在本节点所在的磁盘上。<br>② task 所计算的数据在本节点其他 Executor 进程的内存中。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21bugz8otj30bp0cdwfu.jpg" alt=""></p>
<h3 id="3-NO-PREF"><a href="#3-NO-PREF" class="headerlink" title="3) NO_PREF"></a>3) NO_PREF</h3><p>task 所计算的数据在关系型数据库中，如 mysql。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21bvbr619j309j07a3yr.jpg" alt=""></p>
<h3 id="4-RACK-LOCAL"><a href="#4-RACK-LOCAL" class="headerlink" title="4) RACK_LOCAL"></a>4) RACK_LOCAL</h3><p>task所计算的数据在同机架的不同节点的磁盘或者Executor进程的内存中</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21bw26vmxj30910bcmxv.jpg" alt=""></p>
<h3 id="5-ANY"><a href="#5-ANY" class="headerlink" title="5) ANY"></a>5) ANY</h3><p>跨机架。</p>
<h2 id="（2）Spark-数据本地化调优："><a href="#（2）Spark-数据本地化调优：" class="headerlink" title="（2）Spark 数据本地化调优："></a>（2）Spark 数据本地化调优：</h2><p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21bwjhtyfj30ek08owf7.jpg" alt=""></p>
<p>​          Spark 中任务调度时，TaskScheduler 在分发之前需要依据数据的位置来分发，最好将 task 分发到数据所在的节点上，如果 TaskScheduler 分发的 task在默认 3s 依然无法执行的话，TaskScheduler 会重新发送这个 task 到相同的 Executor 中去执行，会重试 5 次，如果依然无法执行，那么 TaskScheduler会降低一级数据本地化的级别再次发送 task。</p>
<p>​         如上图中，会先尝试 1,PROCESS_LOCAL 数据本地化级别，如果重试 5 次每次等待 3s,会默认这个 Executor 计算资源满了，那么会降低一级数据本地化级别到 2，NODE_LOCAL,如果还是重试 5 次每次等待 3s 还是失败，那么还是会降低一级数据本地化级别到 3，RACK_LOCAL。这样数据就会有网络传输，降低了执行效率。</p>
<h3 id="1-如何提高数据本地化的级别？"><a href="#1-如何提高数据本地化的级别？" class="headerlink" title="1)  如何提高数据本地化的级别？"></a>1)  如何提高数据本地化的级别？</h3><p>可以增加每次发送 task 的等待时间（默认都是 3s），将 3s 倍数调大，  结合 WEBUI 来调节：</p>
<p>• spark.locality.wait</p>
<p>• spark.locality.wait.process</p>
<p>• spark.locality.wait.node</p>
<p>• spark.locality.wait.rack</p>
<p>注意：等待时间不能调大很大，调整数据本地化的级别不要本末倒置，虽然每一个 task 的本地化级别是最高了，但整个 Application 的执行时间反而加长。</p>
<h3 id="2-如何查看数据本地化的级别？"><a href="#2-如何查看数据本地化的级别？" class="headerlink" title="2)  如何查看数据本地化的级别？"></a>2)  如何查看数据本地化的级别？</h3><p>通过日志或者 WEBUI</p>
<h1 id="5、内存调优"><a href="#5、内存调优" class="headerlink" title="5、内存调优"></a>5、内存调优</h1><p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21bxft53yj30d709iq33.jpg" alt=""></p>
<p>​          JVM堆内存分为一块较大的Eden和两块较小的Survivor，每次只使用Eden和其中一块 Survivor，当回收时将 Eden 和 Survivor 中还存活着的对象一次性复制到另外一块Survivor上，最后清理掉Eden和刚才用过的Survivor。<br>也就是说当 task 创建出来对象会首先往 Eden 和 survivor1 中存放，survivor2是空闲的，当Eden和survivor1区域放满以后就会触发minor gc小型垃圾回收，清理掉不再使用的对象。会将存活下来的对象放入 survivor2中。<br>如果存活下来的对象大小大于 survivor2 的大小，那么 JVM 就会将多余的对象直接放入到老年代中。<br>如果这个时候年轻代的内存不是很大的话，就会经常的进行 minor gc，频繁的 minor gc 会导致短时间内有些存活的对象（多次垃圾回收都没有回收掉，一直在用的又不能被释放,这种对象每经过一次 minor gc 都存活下来）<br>频繁的倒来倒去，会导致这些短生命周期的对象（不一定长期使用）每进行一次垃圾回收就会长一岁。年龄过大，默认 15 岁，垃圾回收还是没有回收回去就会跑到老年代里面去了。<br>这样会导致在老年代中存放大量的短生命周期的对象，老年代应该存放的是数量比较少并且会长期使用的对象，比如数据库连接池对象。这样的话，老年代就会满溢（full gc 因为本来老年代中的对象很少，很少进行 full gc 因此采取了不太复杂但是消耗性能和时间的垃圾回收算法）。不管 minor gc 还是 full gc 都会导致 JVM 的工作线程停止。</p>
<h2 id="总结-堆内存不足造成的影响："><a href="#总结-堆内存不足造成的影响：" class="headerlink" title="总结-堆内存不足造成的影响："></a>总结-堆内存不足造成的影响：</h2><p>1) 频繁的 minor gc。</p>
<p>2) 老年代中大量的短声明周期的对象会导致 full gc。</p>
<p>3) gc 多了就会影响 Spark 的性能和运行的速度。</p>
<p>Spark JVM 调优主要是降低 gc时间，可以修改 Executor 内存的比例参数。<br>RDD 缓存、task 定义运行的算子函数，可能会创建很多对象，这样会占用大量的堆内存。堆内存满了之后会频繁的 GC，如果 GC 还不能够满足内存的需要的话就会报 OOM。比如一个 task 在运行的时候会创建 N 个对象，这些对象首先要放入到 JVM 年轻代中。比如在存数据的时候我们使用了foreach 来将数据写入到内存，每条数据都会封装到一个对象中存入数据库中，那么有多少条数据就会在 JVM 中创建多少个对象。</p>
<h2 id="Spark-中如何内存调优？"><a href="#Spark-中如何内存调优？" class="headerlink" title="Spark 中如何内存调优？"></a>Spark 中如何内存调优？</h2><p>Spark Executor 堆内存中存放（以静态内存管理为例）：</p>
<p>RDD 的缓存数据和广播变量（spark.storage.memoryFraction 0.6），shuffle 聚合内存<br>（spark.shuffle.memoryFraction 0.2）,task 的运行（0.2）那么如何调优呢？</p>
<p>1) 提高 Executor 总体内存的大小</p>
<p>2) 降低储存内存比例或者降低聚合内存比例</p>
<h2 id="如何查看-gc？"><a href="#如何查看-gc？" class="headerlink" title="如何查看 gc？"></a>如何查看 gc？</h2><p>Spark WEBUI 中 job-&gt;stage-&gt;task</p>
<h1 id="6、Spark-Shuffle-调优"><a href="#6、Spark-Shuffle-调优" class="headerlink" title="6、Spark Shuffle 调优"></a>6、Spark Shuffle 调优</h1><ol>
<li>buffer 大小——32KB</li>
<li>shuffle read 拉取数据量的大小——48M</li>
<li>shuffle 聚合内存的比例——20%</li>
<li>拉取数据重试次数——5 次</li>
<li>重试间隔时间 60s</li>
<li>Spark Shuffle 的种类</li>
<li>HashShuffle 合并机制</li>
<li>SortShuffle bypass 机制 200 次</li>
</ol>
<h1 id="7、调节-Executor-的堆外内存"><a href="#7、调节-Executor-的堆外内存" class="headerlink" title="7、调节 Executor 的堆外内存"></a>7、调节 Executor 的堆外内存</h1><p>​        Spark 底层 shuffle 的传输方式是使用 netty 传输，netty 在进行网络传输的过程会申请堆外内存（netty 是零拷贝），所以使用了堆外内存。默认情况下，这个堆外内存上限默认是每一个 executor 的内存大小的 10%；真正处理大数据的时候，这里都会出现问题，导致 spark 作业反复崩溃，无法运行；此时就会去调节这个参数，到至少 1G（1024M），甚至说 2G、4G。<br>​     executor 在进行 shuffle write，优先从自己本地block manager中获取某份数据地址，如果本地 block manager 没有的话，那么会通过 TransferService，去远程连接其他节点上 executor 的 blockmanager 去获取，尝试建立远程的网络连接，并且去拉取数据。频繁创建对象让 JVM 堆内存满溢，进行垃圾回收。正好碰到那个 exeuctor 的 JVM 在垃圾回收。处于垃圾回过程中，所有的工作线程全部停止；相当于只要一旦进行垃圾回收，spark / executor 停止工作，无法提供响应，spark 默认的网络连接的超时时长是 60s；如果卡住 60s 都无法建立连接的话，那么这个 task 就失败了。task  失败了就会出现 shuffle file cannot find  的错误。</p>
<p>那么如何调节等待的时长呢？</p>
<p>在./spark-submit 提交任务的脚本里面添加：</p>
<p>–conf spark.core.connection.ack.wait.timeout=300</p>
<p>Executor 由于内存不足或者堆外内存不足了，挂掉了，对应的 Executor 上面的 block manager 也挂掉了，找不到对应的 shuffle map output 文件，Reducer 端不能够拉取数据。</p>
<p>我们可以调节堆外内存的大小，如何调节？</p>
<p>在./spark-submit 提交任务的脚本里面添加</p>
<p>yarn 下：<br>–conf spark.yarn.executor.memoryOverhead=2048 单位 M</p>
<p>standalone 下：<br>–conf spark.executor.memoryOverhead=2048 单位 M</p>
<h1 id="8、解决数据倾斜"><a href="#8、解决数据倾斜" class="headerlink" title="8、解决数据倾斜"></a>8、解决数据倾斜</h1><h2 id="1、使用-Hive-ETL-预处理数据"><a href="#1、使用-Hive-ETL-预处理数据" class="headerlink" title="1、使用 Hive ETL 预处理数据"></a>1、使用 Hive ETL 预处理数据</h2><h3 id="方案适用场景："><a href="#方案适用场景：" class="headerlink" title="方案适用场景："></a>方案适用场景：</h3><p>如果导致数据倾斜的是 Hive 表。如果该 Hive 表中的数据本身很不均匀（比如某个 key 对应了 100 万数据，其他 key 才对应了 10 条数据），而且业务场景需要频繁使用 Spark 对 Hive 表执行某个分析操作，那么比较适合使用这种技术方案。</p>
<h3 id="方案实现思路："><a href="#方案实现思路：" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>此时可以评估一下，是否可以通过 Hive 来进行数据预处理（即通过 HiveETL 预先对数据按照 key 进行聚合，或者是预先和其他表进行 join），然后在 Spark 作业中针对的数据源就不是原来的 Hive 表了，而是预处理后的 Hive 表。此时由于数据已经预先进行过聚合或 join 操作了，那么在Spark 作业中也就不需要使用原先的 shuffle 类算子执行这类操作了。</p>
<h3 id="方案实现原理："><a href="#方案实现原理：" class="headerlink" title="方案实现原理："></a>方案实现原理：</h3><p>这种方案从根源上解决了数据倾斜，因为彻底避免了在 Spark 中执行shuffle 类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以 Hive ETL 中进行 group by 或者 join 等 shuffle 操作时，还是会出现数据倾斜，导致 Hive ETL 的速度很慢。我们只是把数据倾斜的发生提前到了 Hive ETL 中，避免 Spark 程序发生数据倾斜而已。</p>
<h2 id="2、过滤少数导致倾斜的-key"><a href="#2、过滤少数导致倾斜的-key" class="headerlink" title="2、过滤少数导致倾斜的 key"></a>2、过滤少数导致倾斜的 key</h2><h3 id="方案适用场景：-1"><a href="#方案适用场景：-1" class="headerlink" title="方案适用场景："></a>方案适用场景：</h3><p>如果发现导致倾斜的 key 就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如 99%的 key 就对应 10 条数据，但是只有一个 key 对应了 100 万数据，从而导致了数据倾斜。</p>
<h3 id="方案实现思路：-1"><a href="#方案实现思路：-1" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>如果我们判断那少数几个数据量特别多的 key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个 key。比如，在Spark SQL 中可以使用 where 子句过滤掉这些 key 或者在 Spark Core中对 RDD 执行 filter 算子过滤掉这些 key。如果需要每次作业执行时，动态判定哪些 key 的数据量最多然后再进行过滤，那么可以使用 sample算子对 RDD 进行采样，然后计算出每个 key 的数量，取数据量最多的 key过滤掉即可。</p>
<h3 id="方案实现原理：-1"><a href="#方案实现原理：-1" class="headerlink" title="方案实现原理："></a>方案实现原理：</h3><p>将导致数据倾斜的 key 给过滤掉之后，这些 key 就不会参与计算了，自然不可能产生数据倾斜。</p>
<h2 id="3、提高-shuffle-操作的并行度"><a href="#3、提高-shuffle-操作的并行度" class="headerlink" title="3、提高 shuffle 操作的并行度"></a>3、提高 shuffle 操作的并行度</h2><h3 id="方案实现思路：-2"><a href="#方案实现思路：-2" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>在对 RDD 执行 shuffle 算子时，给 shuffle 算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个 shuffle 算子执行时 shuffleread task的数量。对于Spark SQL中的shuffle类语句，比如group by、join 等，需要设置一个参数，即 spark.sql.shuffle.partitions，该参数代表了 shuffle read task 的并行度，该值默认是 200，对于很多场景来说都有点过小。</p>
<h3 id="方案实现原理：-2"><a href="#方案实现原理：-2" class="headerlink" title="方案实现原理："></a>方案实现原理：</h3><p>增加 shuffle read task 的数量，可以让原本分配给一个 task 的多个 key分配给多个 task，从而让每个 task 处理比原来更少的数据。举例来说，如果原本有 5 个不同的 key，每个 key 对应 10 条数据，这 5 个 key 都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffleread task 以后，每个 task 就分配到一个 key，即每个 task 就处理 10 条数据，那么自然每个 task 的执行时间都会变短了。</p>
<h2 id="4、双重聚合"><a href="#4、双重聚合" class="headerlink" title="4、双重聚合"></a>4、双重聚合</h2><h3 id="方案适用场景：-2"><a href="#方案适用场景：-2" class="headerlink" title="方案适用场景："></a>方案适用场景：</h3><p>对 RDD 执行 reduceByKey 等聚合类 shuffle 算子或者在 Spark SQL 中使用 group by 语句进行分组聚合时，比较适用这种方案。</p>
<h3 id="方案实现思路：-3"><a href="#方案实现思路：-3" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个 key 都打上一个随机数，比如 10 以内的随机数，此时原先一样的 key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行 reduceByKey 等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个 key 的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p>
<h3 id="方案实现原理：-3"><a href="#方案实现原理：-3" class="headerlink" title="方案实现原理："></a>方案实现原理：</h3><p>将原本相同的 key 通过附加随机前缀的方式，变成多个不同的 key，就可以让原本被一个 task 处理的数据分散到多个 task 上去做局部聚合，进而解决单个 task 处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21c00ck9yj30ek078t9g.jpg" alt=""></p>
<p>如果一个 RDD 中有一个 key 导致数据倾斜，同时还有其他的 key，那么一般先对数据集进行抽样，然后找出倾斜的 key,再使用 filter 对原始的RDD 进行分离为两个 RDD，一个是由倾斜的 key 组成的 RDD1，一个是由其他的key 组成的 RDD2，那么对于 RDD1 可以使用加随机前缀进行多分区多 task 计算，对于另一个 RDD2 正常聚合计算，最后将结果再合并起来。</p>
<h2 id="5、将-reduce-join-转为-map-join"><a href="#5、将-reduce-join-转为-map-join" class="headerlink" title="5、将 reduce join 转为 map join"></a>5、将 reduce join 转为 map join</h2><p>BroadCast+filter(或者 map)</p>
<h3 id="方案适用场景：-3"><a href="#方案适用场景：-3" class="headerlink" title="方案适用场景："></a>方案适用场景：</h3><p>在对 RDD 使用 join 类操作，或在 Spark SQL 中使用 join 语句时，而且 join 操作中的一个 RDD 或表的数据量比较小（比如几百 M 或者一两 G），比较适用此方案。</p>
<h3 id="方案实现思路：-4"><a href="#方案实现思路：-4" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>不使用 join 算子进行连接操作，而使用 Broadcast 变量与 map 类算子实现 join 操作，进而完全规避掉 shuffle 类的操作，彻底避免数据倾斜的发生和出现。将较小 RDD 中的数据直接通过 collect 算子拉取到 Driver端的内存中来，然后对其创建一个 Broadcast 变量；接着对另外一个 RDD执行 map 类算子，在算子函数内，从 Broadcast 变量中获取较小 RDD的全量数据，与当前 RDD 的每一条数据按照连接 key 进行比对，如果连接 key 相同的话，那么就将两个 RDD 的数据用你需要的方式连接起来。</p>
<h3 id="方案实现原理：-4"><a href="#方案实现原理：-4" class="headerlink" title="方案实现原理："></a>方案实现原理：</h3><p>普通的 join 是会走 shuffle 过程的，而一旦 shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个 RDD 是比较小的，则可以采用广播小 RDD 全量数据+map 算子来实现与 join 同样的效果，也就是 map join，此时就不会发生 shuffle 操作，也就不会发生数据倾斜。</p>
<h2 id="6、采样倾斜-key-并分拆-join-操作"><a href="#6、采样倾斜-key-并分拆-join-操作" class="headerlink" title="6、采样倾斜 key 并分拆 join 操作"></a>6、采样倾斜 key 并分拆 join 操作</h2><h3 id="方案适用场景：-4"><a href="#方案适用场景：-4" class="headerlink" title="方案适用场景："></a>方案适用场景：</h3><p>两个 RDD/Hive 表进行 join 的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个 RDD/Hive 表中的 key 分布情况。如果出现数据倾斜，是因为其中某一个 RDD/Hive 表中的少数几个 key的数据量过大，而另一个 RDD/Hive 表中的所有 key 都分布比较均匀，那么采用这个解决方案是比较合适的。</p>
<h3 id="方案实现思路：-5"><a href="#方案实现思路：-5" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>对包含少数几个数据量过大的 key 的那个 RDD，通过 sample 算子采样出一份样本来，然后统计一下每个 key 的数量，计算出来数据量最大的是哪几个key。然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的 RDD，并给每个 key 都打上 n 以内的随机数作为前缀，而不会导致倾斜的大部分 key 形成另外一个 RDD。接着将需要 join 的另一个 RDD，也过滤出来那几个倾斜 key 对应的数据并形成一个单独的RDD，将每条数据膨胀成 n 条数据，这 n 条数据都按顺序附加一个 0~n的前缀，不会导致倾斜的大部分 key 也形成另外一个 RDD。再将附加了随机前缀的独立 RDD 与另一个膨胀 n 倍的独立 RDD 进行 join，此时就可以将原先相同的 key 打散成 n 份，分散到多个 task 中去进行 join 了。而另外两个普通的 RDD 就照常 join 即可。最后将两次 join 的结果使用<br>union 算子合并起来即可，就是最终的 join 结果 。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21c0ylpoxj30ek06ijsi.jpg" alt=""></p>
<h2 id="7、使用随机前缀和扩容-RDD-进行-join"><a href="#7、使用随机前缀和扩容-RDD-进行-join" class="headerlink" title="7、使用随机前缀和扩容 RDD 进行 join"></a>7、使用随机前缀和扩容 RDD 进行 join</h2><h3 id="方案适用场景：-5"><a href="#方案适用场景：-5" class="headerlink" title="方案适用场景："></a>方案适用场景：</h3><p>如果在进行 join 操作时，RDD 中有大量的 key 导致数据倾斜，那么进行分拆 key 也没什么意义，此时就只能使用最后一种方案来解决问题了。</p>
<h3 id="方案实现思路：-6"><a href="#方案实现思路：-6" class="headerlink" title="方案实现思路："></a>方案实现思路：</h3><p>该方案的实现思路基本和“解决方案六”类似，首先查看 RDD/Hive 表中的数据分布情况，找到那个造成数据倾斜的 RDD/Hive 表，比如有多个 key 都对应了超过 1 万条数据。然后将该 RDD 的每条数据都打上一个n 以内的随机前缀。同时对另外一个正常的 RDD 进行扩容，将每条数据都扩容成 n 条数据，扩容出来的每条数据都依次打上一个 0~n 的前缀。最后将两个处理后的 RDD 进行 join 即可。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g21c1yursmj30ek08fmyp.jpg" alt=""></p>
<h1 id="9、Spark-故障解决（troubleshooting）"><a href="#9、Spark-故障解决（troubleshooting）" class="headerlink" title="9、Spark 故障解决（troubleshooting）"></a>9、Spark 故障解决（troubleshooting）</h1><h2 id="1、shuffle-file-cannot-find：磁盘小文件找不到。"><a href="#1、shuffle-file-cannot-find：磁盘小文件找不到。" class="headerlink" title="1、shuffle file cannot find：磁盘小文件找不到。"></a>1、shuffle file cannot find：磁盘小文件找不到。</h2><p>1) connection timeout —-shuffle file cannot find<br>提高建立连接的超时时间，或者降低 gc，降低 gc 了那么 spark 不能堆外提供服务的时间就少了，那么超时的可能就会降低。</p>
<p>2) fetch data fail —- shuffle file cannot find<br>提高拉取数据的重试次数以及间隔时间。</p>
<p>3) OOM/executor lost —- shuffle file cannot find<br>提高堆外内存大小，提高堆内内存大小。</p>
<h2 id="2、reduce-OOM"><a href="#2、reduce-OOM" class="headerlink" title="2、reduce OOM"></a>2、reduce OOM</h2><p>BlockManager 拉取的数据量大，reduce task 处理的数据量小</p>
<p>解决方法：<br>1) 降低每次拉取的数据量<br>2) 提高 shuffle 聚合的内存比例<br>3) 提高 Executor 的内存比例</p>
<h2 id="3、序列化问题"><a href="#3、序列化问题" class="headerlink" title="3、序列化问题"></a>3、序列化问题</h2><h2 id="4、Null-值问题"><a href="#4、Null-值问题" class="headerlink" title="4、Null 值问题"></a>4、Null 值问题</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = rdd.map&#123;x=&gt;&#123;</span><br><span class="line">x+”~”;<span class="type">W</span></span><br><span class="line">&#125;&#125;</span><br><span class="line">rdd.foreach&#123;x=&gt;&#123;</span><br><span class="line"><span class="type">System</span>.out.println(x.getName())</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2019/02/23/Spark优化/">Spark调优</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">Sukie</a></p>
        <p><span>发布时间:</span>2019-02-23, 00:00:00</p>
        <p><span>最后更新:</span>2019-04-17, 11:38:28</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2019/02/23/Spark优化/" title="Spark调优">http://sungithup.github.io/2019/02/23/Spark优化/</a>
            <span class="copy-path" data-clipboard-text="原文: http://sungithup.github.io/2019/02/23/Spark优化/　　作者: Sukie" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target="_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2019/02/25/大型网站日志分析系统/">
                    日志分析系统
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2019/02/22/Spark学习（6）/">
                    Spark学习（六）
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1、资源调优"><span class="toc-text">1、资源调优</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1）-在部署-spark-集群中"><span class="toc-text">1）  在部署 spark 集群中</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2）-在提交-Application-时"><span class="toc-text">2）  在提交 Application 时</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、并行度调优"><span class="toc-text">2、并行度调优</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3、代码调优"><span class="toc-text">3、代码调优</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、避免创建重复的-RDD"><span class="toc-text">1、避免创建重复的 RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、复用同一个-RDD"><span class="toc-text">2、复用同一个 RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、对多次使用的-RDD-进行持久化"><span class="toc-text">3、对多次使用的 RDD 进行持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#选择最合适的持久化策略？"><span class="toc-text">选择最合适的持久化策略？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#持久化算子："><span class="toc-text">持久化算子：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#（1）cache"><span class="toc-text">（1）cache:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#（2）persist："><span class="toc-text">（2）persist：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#（3）checkpoint"><span class="toc-text">（3）checkpoint:</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、尽量避免使用-shuffle-类的算子"><span class="toc-text">4、尽量避免使用 shuffle 类的算子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5、使用-map-side-预聚合的-shuffle-操作"><span class="toc-text">5、使用 map-side 预聚合的 shuffle 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#combiner-概念："><span class="toc-text">combiner 概念：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#combiner-好处："><span class="toc-text">combiner 好处：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#有-combiner-的-shuffle-类算子："><span class="toc-text">有 combiner 的 shuffle 类算子：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6、尽量使用高性能的算子"><span class="toc-text">6、尽量使用高性能的算子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7、使用广播变量"><span class="toc-text">7、使用广播变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8、使用-Kryo-优化序列化性能"><span class="toc-text">8、使用 Kryo 优化序列化性能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9、优化数据结构"><span class="toc-text">9、优化数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#java-中有三种类型比较消耗内存："><span class="toc-text">java 中有三种类型比较消耗内存：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10、使用高性能的库-fastutil"><span class="toc-text">10、使用高性能的库 fastutil</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fasteutil-介绍："><span class="toc-text">fasteutil 介绍：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用："><span class="toc-text">使用：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4、数据本地化"><span class="toc-text">4、数据本地化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#（1）数据本地化的级别："><span class="toc-text">（1）数据本地化的级别：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-PROCESS-LOCAL"><span class="toc-text">1) PROCESS_LOCAL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-NODE-LOCAL"><span class="toc-text">2) NODE_LOCAL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-NO-PREF"><span class="toc-text">3) NO_PREF</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-RACK-LOCAL"><span class="toc-text">4) RACK_LOCAL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-ANY"><span class="toc-text">5) ANY</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#（2）Spark-数据本地化调优："><span class="toc-text">（2）Spark 数据本地化调优：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-如何提高数据本地化的级别？"><span class="toc-text">1)  如何提高数据本地化的级别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-如何查看数据本地化的级别？"><span class="toc-text">2)  如何查看数据本地化的级别？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5、内存调优"><span class="toc-text">5、内存调优</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#总结-堆内存不足造成的影响："><span class="toc-text">总结-堆内存不足造成的影响：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-中如何内存调优？"><span class="toc-text">Spark 中如何内存调优？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何查看-gc？"><span class="toc-text">如何查看 gc？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6、Spark-Shuffle-调优"><span class="toc-text">6、Spark Shuffle 调优</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7、调节-Executor-的堆外内存"><span class="toc-text">7、调节 Executor 的堆外内存</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8、解决数据倾斜"><span class="toc-text">8、解决数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、使用-Hive-ETL-预处理数据"><span class="toc-text">1、使用 Hive ETL 预处理数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案适用场景："><span class="toc-text">方案适用场景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路："><span class="toc-text">方案实现思路：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现原理："><span class="toc-text">方案实现原理：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、过滤少数导致倾斜的-key"><span class="toc-text">2、过滤少数导致倾斜的 key</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案适用场景：-1"><span class="toc-text">方案适用场景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路：-1"><span class="toc-text">方案实现思路：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现原理：-1"><span class="toc-text">方案实现原理：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、提高-shuffle-操作的并行度"><span class="toc-text">3、提高 shuffle 操作的并行度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路：-2"><span class="toc-text">方案实现思路：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现原理：-2"><span class="toc-text">方案实现原理：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、双重聚合"><span class="toc-text">4、双重聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案适用场景：-2"><span class="toc-text">方案适用场景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路：-3"><span class="toc-text">方案实现思路：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现原理：-3"><span class="toc-text">方案实现原理：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5、将-reduce-join-转为-map-join"><span class="toc-text">5、将 reduce join 转为 map join</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案适用场景：-3"><span class="toc-text">方案适用场景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路：-4"><span class="toc-text">方案实现思路：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现原理：-4"><span class="toc-text">方案实现原理：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6、采样倾斜-key-并分拆-join-操作"><span class="toc-text">6、采样倾斜 key 并分拆 join 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案适用场景：-4"><span class="toc-text">方案适用场景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路：-5"><span class="toc-text">方案实现思路：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7、使用随机前缀和扩容-RDD-进行-join"><span class="toc-text">7、使用随机前缀和扩容 RDD 进行 join</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方案适用场景：-5"><span class="toc-text">方案适用场景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方案实现思路：-6"><span class="toc-text">方案实现思路：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9、Spark-故障解决（troubleshooting）"><span class="toc-text">9、Spark 故障解决（troubleshooting）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、shuffle-file-cannot-find：磁盘小文件找不到。"><span class="toc-text">1、shuffle file cannot find：磁盘小文件找不到。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、reduce-OOM"><span class="toc-text">2、reduce OOM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、序列化问题"><span class="toc-text">3、序列化问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、Null-值问题"><span class="toc-text">4、Null 值问题</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"Spark调优　| Sukie山脉　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    	


  
     
     




    <div class="scroll" id="post-nav-button">
        
            <a href="/2019/02/25/大型网站日志分析系统/" title="上一篇: 日志分析系统">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2019/02/22/Spark学习（6）/" title="下一篇: Spark学习（六）">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/05/05/Oozie学习/">Flink学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/28/impala学习/">impala学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/21/机器学习算法/">机器学习算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/25/大型网站日志分析系统/">日志分析系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/23/Spark优化/">Spark调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/22/Spark学习（6）/">Spark学习（六）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/21/Spark学习（5）/">Spark学习（五）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/20/Shuffle调优/">SparkShuffle调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/19/Spark学习（4）/">Spark学习（四）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/18/Spark学习（3）/">Spark学习（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/17/Spark学习（2）/">Spark学习（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/Spark学习（1）/">Spark学习（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/String方法/">String 方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/数组方法/">数组方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/面试问题总结/">面试问题总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/Map方法/">Map方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/Set方法/">Set方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/16/List方法/">List方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/15/Scala学习/">Scala学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/14/Redis学习/">Redis学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/29/Storm学习/">Storm学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/28/Kafka学习/">Kafka学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/25/Elasticsearch学习/">Elasticsearch学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/18/Flume学习/">Flume学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/18/CDH操作学习/">CDH部署操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/17/HBase性能优化/">HBase性能优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/15/HBase学习/">HBase学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/13/Sqoop学习/">Sqoop学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/Hive优化/">Hive优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/Hive中常用的UDF函数总结/">Hive中常用的UDF函数总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/11/Hive学习/">Hive学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/08/MapReduce源码分析/">MapReduce源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/MapReduce案例分析/">MapReduce案例实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/05/MapReduce学习/">MapReduce学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/04/Zookeeper学习/">Zookeeper学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/04/Yarn学习/">YARN的入门学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/Hadoop2.X/">Hadoop2.X</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/HDFS学习/">HDFS学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/02/Nginx入门学习2/">Nginx入门学习（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/02/Nginx入门学习1/">Nginx入门学习（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/30/大数据思想/">大数据思想</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/29/常用Linux命令的学习3/">常用Linux命令的学习（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/28/常用Linux命令的学习2/">常用Linux命令的学习（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/27/常用Linux命令的学习1/">常用Linux命令的学习（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/26/Linux系统数据库MySQL安装/">Linux系统数据库MySQL安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/25/Linux系统CentOS 6安装/">Linux学习之CentOS 6系统安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/手动安装maven坐标依赖/">手动安装maven坐标依赖</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/19/hello-world/">Hello World</a></li></ul>




    <script>
        
    </script>


<!--gitment 评论-->

  <div class="comments" id="comments">
  
  <!--汉化-->
    <link rel="stylesheet" href="https://billts.site/extra_css/gitment.css">
  <script src="https://billts.site/js/gitment.js"></script>
  <!--原型-->
  <!--
  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js" type="text/javascript"></script>
  -->
  
      <div id="gitmentContainer" style="margin-bottom: -19px;"></div>
     
      <style>
        .gitment-container a {
          border: none;
        }
        .comments {
          margin: 60px 0 0;padding: 0 60px;
        }
      </style>
     
      <script type="text/javascript">
        var gitment = new Gitment({
        id: 'Sat Feb 23 2019 00:00:00 GMT+0800',
        title: 'Spark调优',
        owner: 'sungithup',
        repo: 'sungithup.github.io',
        oauth: {
        client_id: '80107df5bc27be1c1495',
        client_secret: 'c7949e6fc532f63f30f14fe1aff7f4b9c234860e',
        },
        })
        gitment.render('gitmentContainer')
      </script>
  </div>

<!--gitment 评论 end--></div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                
                2016-2019 Sukie
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style="display:none">
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style="display:none">
                        <span id="page-visit" title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        

        <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span> 
        <script>
        var now = new Date(); 
        function createtime() { 
        var grt= new Date("02/14/2016 12:49:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
        } 
        setInterval("createtime()",250);
        </script>

    </div>
</footer>
    </div>
    
    <script src="/js/GithubRepoWidget.js"></script>

<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
             github: ".github-widget a", 
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

    <script>
        var originTitle = document.title;
        var titleTime;
        document.addEventListener("visibilitychange", function() {
            if (document.hidden) {
                document.title = "(つェ⊂) 我藏好了哦~ " + originTitle;
                clearTimeout(titleTime);
            }
            else {
                document.title = "(*´∇｀*) 被你发现啦~ " + originTitle;
                titleTime = setTimeout(function() {
                    document.title = originTitle;
                }, 2000);
            }
        })
    </script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<script typr="text/javascript" src="/resources/love.js"></script>
<script typr="text/javascript" src="/resources/float.js"></script>
<script typr="text/javascript" src="/resources/typewriter.js"></script>
<script typr="text/javascript" color="1,104,183" opacity="1" zindex="-1" count50="" src="/resources/particle.js"></script>
  </div>
</body>
</html>