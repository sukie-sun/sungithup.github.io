<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="Sukie">


    
    


<meta name="description" content="Sukie的个人博客，主要涉及到编程（Java、Python、C、MySql、Linux，etc），仅供个人提升学习之用。">
<meta name="keywords" content="各种资源">
<meta property="og:type" content="website">
<meta property="og:title" content="Sukie山脉">
<meta property="og:url" content="http://sungithup.github.io/index.html">
<meta property="og:site_name" content="Sukie山脉">
<meta property="og:description" content="Sukie的个人博客，主要涉及到编程（Java、Python、C、MySql、Linux，etc），仅供个人提升学习之用。">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sukie山脉">
<meta name="twitter:description" content="Sukie的个人博客，主要涉及到编程（Java、Python、C、MySql、Linux，etc），仅供个人提升学习之用。">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Sukie山脉" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Sukie山脉</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>





    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?bc39ced90d9f89c71fda7b7d4ca8b638";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script>


</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Sukie</a></h1>
        </hgroup>

        
        <p class="header-subtitle">肆意玩耍，肆意高歌</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false">
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class="no-result">No results found <i class="fa fa-spinner fa-pulse"></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/essays/">推荐</a></li>
                        
                            <li><a href="/books/">书籍</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:sunyaru216@163.com" title="Email"></a>
                            
                                <a class="fa 新浪微博" href="http://weibo.com/sunrise200 " title="新浪微博"></a>
                            
                                <a class="fa GitHub" href="https://github.com/sungithup" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa 博客园" href="/cnblogs" title="博客园"></a>
                            
                                <a class="fa CSDN" href="/" title="CSDN"></a>
                            
                                <a class="fa 网易云音乐" href="https://music.163.com/#/song?id=18949687" title="网易云音乐"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Array/">Array</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CDH/">CDH</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CentOS-6/">CentOS 6</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/">HBase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JVM/">JVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux命令/">Linux命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux系统环境/">Linux系统环境</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/List/">List</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Map/">Map</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/">Nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/">Redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL语句/">SQL语句</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Set/">Set</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark-shell/">Spark shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkCore/">SparkCore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkShuffle/">SparkShuffle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkSql/">SparkSql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkStreaming/">SparkStreaming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark框架/">Spark框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sqoop/">Sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Storm，流式处理框架/">Storm，流式处理框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/String/">String</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Zookeeper/">Zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maven/">maven</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shuffle调优/">shuffle调优</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sparkcore/">sparkcore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark内存管理/">spark内存管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web/">web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/yarn/">yarn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/内存/">内存</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式搜索和分析引擎/">分布式搜索和分析引擎</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式离线计算框架/">分布式离线计算框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分而治之/">分而治之</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/参数解释/">参数解释</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大型网站日志分析系统/">大型网站日志分析系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工作流调度引擎/">工作流调度引擎</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/广播/">广播</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据倾斜/">数据倾斜</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/流式处理框架/">流式处理框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/消息队列系统/">消息队列系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/源码分析/">源码分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/离线分析/">离线分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/累加/">累加</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编程语言/">编程语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算引擎/">计算引擎</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算框架/">计算框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/资源/">资源</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/静态/">静态</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">正宗小白</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Sukie</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Sukie</a></h1>
            </hgroup>
            
            <p class="header-subtitle">肆意玩耍，肆意高歌</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/essays/">推荐</a></li>
                
                    <li><a href="/books/">书籍</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:sunyaru216@163.com" title="Email"></a>
                            
                                <a class="fa 新浪微博" target="_blank" href="http://weibo.com/sunrise200 " title="新浪微博"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/sungithup" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa 博客园" target="_blank" href="/cnblogs" title="博客园"></a>
                            
                                <a class="fa CSDN" target="_blank" href="/" title="CSDN"></a>
                            
                                <a class="fa 网易云音乐" target="_blank" href="https://music.163.com/#/song?id=18949687" title="网易云音乐"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我">
</nav>
      <div class="body-wrap">
  
    <article id="post-Oozie学习" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/05/05/Oozie学习/" class="article-date">
      <time datetime="2019-05-04T16:00:00.000Z" itemprop="datePublished">2019-05-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/05/Oozie学习/">Oozie学习</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">1.9k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">9分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              用于 Hadoop 平台的开源的工作流调度引擎，用来管理Hadoop作业，属于web应用程序
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/flink/">flink</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/web/">web</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/工作流调度引擎/">工作流调度引擎</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/05/05/Oozie学习/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-impala学习" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/04/28/impala学习/" class="article-date">
      <time datetime="2019-04-27T16:00:00.000Z" itemprop="datePublished">2019-04-28</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/28/impala学习/">impala学习</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">2.7k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">10分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              简略描述
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/impala/">impala</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/04/28/impala学习/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-机器学习算法" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/04/21/机器学习算法/" class="article-date">
      <time datetime="2019-04-21T07:30:15.656Z" itemprop="datePublished">2019-04-21</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>title: 推荐系统项目学习<br>date: 2019-1-18<br>update: 2019-1-18<br>tags:</p>
<pre><code>- Linux系统环境
    - HDFS
    - Base
</code></pre><p>categories: flume<br>grammar_cjkRuby: true<br>mathjax: true<br>overdue: true #这一行文章提醒<br>no_word_count: false<br>description: “线性回归”</p>
<p>[TOC]</p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><p>是人工智能的分支，主要学习常用算法</p>
<p>深度学习是机器学习的分支</p>
<h1 id="一、人工智能与Spark-MLLib"><a href="#一、人工智能与Spark-MLLib" class="headerlink" title="一、人工智能与Spark MLLib"></a>一、人工智能与Spark MLLib</h1><p>分类：强人工智能 ，弱人工智能（目前使用最多）</p>
<p>训练模型：使用概率论，需要大量的数据样本，不断的迭代计算</p>
<p>HDFS：海量数据的存储</p>
<p>迭代计算：<br>使用MR受限（MR只能把中间结果存储在磁盘上，不利于下次计算的重新读取，对迭代算法是性能瓶颈，使用时，耗时，耗磁盘IO）</p>
<p>使用Spark（Spark基于内存计算，适合迭代计算，同时提供基于海量数据的ML库）</p>
<p>Spark MLLib ： spark + machine + learning + lib（库）</p>
<p>基本数据类型：</p>
<p>向量（有大小和方向，相当于元组，数字化描述特征）</p>
<h1 id="二、-线性回归"><a href="#二、-线性回归" class="headerlink" title="二、==线性回归=="></a>二、==线性回归==</h1><h1 id="利用历史数据找出规律用于预测。"><a href="#利用历史数据找出规律用于预测。" class="headerlink" title="利用历史数据找出规律用于预测。"></a>利用历史数据找出规律用于预测。</h1><p><code>回归（regression）：</code>关注自变量和因变量之间的对应关系,</p>
<p>用于预测  （相当于M=ax+by+cx  ，M就是因变量（就是需要预测的值） ，x,y,z就是自变量（参与预测的变量），a,b,c（就是训练模型提供的））</p>
<p>使用最小二乘法算出：</p>
<p>（损失函数）总误差: <img src="https://ws1.sinaimg.cn/large/005zftzDgy1g27svzh2m9j309l01qjrc.jpg" alt=""></p>
<p>梯度下降法：不断调试，迭代计算，求出局部最小的误差（局部收敛）</p>
<p>模拟出来的图线，成为拟合函数</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g27sy8gqqjj30hz0ddn0f.jpg" alt=""></p>
<h3 id="LabeledPoint标注点"><a href="#LabeledPoint标注点" class="headerlink" title="LabeledPoint标注点"></a>LabeledPoint标注点</h3><p>训练模型：需要多维度的历史数据，以LabeledPoint数据结构</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vector</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DataTypeTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"DataTypeTest"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//稠密向量</span></span><br><span class="line">    <span class="keyword">val</span> dv: <span class="type">Vector</span> = <span class="type">Vectors</span>.dense(<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>)</span><br><span class="line">    <span class="comment">//稀疏向量                          个数， 索引 ， 值</span></span><br><span class="line">    <span class="keyword">val</span> sv1: <span class="type">Vector</span> = <span class="type">Vectors</span>.sparse(<span class="number">10</span>, <span class="type">Array</span>(<span class="number">0</span>, <span class="number">2</span>,<span class="number">5</span>), <span class="type">Array</span>(<span class="number">1.0</span>, <span class="number">3.0</span>,<span class="number">8.0</span>))</span><br><span class="line"><span class="comment">//    val sv2: Vector = Vectors.sparse(10, Seq((0, 1.0), (2, 3.0)))</span></span><br><span class="line"></span><br><span class="line">    println(dv)</span><br><span class="line">    println(sv1)</span><br><span class="line"><span class="comment">//    println(sv2)</span></span><br><span class="line"></span><br><span class="line">    println(sv1.toDense)</span><br><span class="line"><span class="comment">//   标注点LabeledPoint ：带有标签的本地向量</span></span><br><span class="line">    <span class="keyword">val</span> pos: <span class="type">LabeledPoint</span> = <span class="type">LabeledPoint</span>(<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>))</span><br><span class="line">                                  <span class="comment">//      y    向量</span></span><br><span class="line">    <span class="keyword">val</span> neg: <span class="type">LabeledPoint</span> =</span><br><span class="line">             <span class="type">LabeledPoint</span>(<span class="number">0.0</span>, <span class="type">Vectors</span>.sparse(<span class="number">3</span>, <span class="type">Array</span>(<span class="number">0</span>, <span class="number">2</span>), <span class="type">Array</span>(<span class="number">1.0</span>, <span class="number">3.0</span>)))</span><br><span class="line">    println(pos.label)  <span class="comment">//  标注点对应的y</span></span><br><span class="line">    println(neg.features.toDense)   <span class="comment">//标注点对应的维度向量，转成dense输出</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> labeledPointRDD = sc.parallelize(<span class="type">Array</span>(pos,neg));</span><br><span class="line">    <span class="comment">//存储标注点数据</span></span><br><span class="line">    <span class="type">MLUtils</span>.saveAsLibSVMFile(labeledPointRDD,<span class="string">"labeledPointRDD.txt"</span>)</span><br><span class="line">      <span class="comment">/* 1.0 1:1.0 2:0.0 3:3.0</span></span><br><span class="line"><span class="comment">         0.0 1:1.0 3:3.0    </span></span><br><span class="line"><span class="comment">      */</span>      </span><br><span class="line">    <span class="comment">//加载标注点数据----------------------------</span></span><br><span class="line">    <span class="keyword">val</span> examples: <span class="type">RDD</span>[<span class="type">LabeledPoint</span>] = </span><br><span class="line">              <span class="type">MLUtils</span>.loadLibSVMFile(sc, <span class="string">"sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    examples.foreach &#123; x =&gt;</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">val</span> label = x.label</span><br><span class="line">        <span class="keyword">val</span> features = x.features</span><br><span class="line">        println(<span class="string">"label:"</span> + label + <span class="string">"\tfeatures:"</span> + features.toDense)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g27y5sdf6cj31780ysaca.jpg" alt=""></p>
<h1 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h1><p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g27y5sl1v1j316l17jdin.jpg" alt=""></p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.&#123;<span class="type">LabeledPoint</span>, <span class="type">LinearRegressionModel</span>, <span class="type">LinearRegressionWithSGD</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">LinearRegression</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="comment">// 构建Spark对象</span></span><br><span class="line">        <span class="keyword">val</span> conf = </span><br><span class="line">        <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"LinearRegressionWithSGD"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="type">Logger</span>.getRootLogger.setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line">        <span class="comment">//    sc.setLogLevel("WARN")</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//读取样本数据</span></span><br><span class="line"><span class="comment">//-0.4307829,-1.63735562648104 -2.00621178480549 -1.86242597251066 -1.02470580167082 -0.522940888712441 -0.863171185425945 -1.04215728919298 -0.864466507337306        </span></span><br><span class="line">        <span class="keyword">val</span> data_path1 = <span class="string">"lpsa.data"</span></span><br><span class="line">        <span class="keyword">val</span> data: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(data_path1)</span><br><span class="line">        <span class="keyword">val</span> examples: <span class="type">RDD</span>[<span class="type">LabeledPoint</span>] = data.map &#123; line =&gt;</span><br><span class="line">            <span class="keyword">val</span> parts = line.split(',')</span><br><span class="line">            <span class="type">LabeledPoint</span>(parts(<span class="number">0</span>).toDouble, </span><br><span class="line">                         <span class="type">Vectors</span>.dense(parts(<span class="number">1</span>).split(' ').map(_.toDouble)))</span><br><span class="line">        &#125;.cache()</span><br><span class="line">        <span class="comment">//1 为随机种子 ， 将数据集按比例随机切分为0.8训练集（0） ， 0.2测试集（1）</span></span><br><span class="line">        <span class="keyword">val</span> train2TestData: <span class="type">Array</span>[<span class="type">RDD</span>[<span class="type">LabeledPoint</span>]] =</span><br><span class="line">                                       examples.randomSplit(<span class="type">Array</span>(<span class="number">0.8</span>, <span class="number">0.2</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//    val numExamples = examples.count(</span></span><br><span class="line">        <span class="comment">// 迭代次数</span></span><br><span class="line">        <span class="keyword">val</span> numIterations = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//在每次迭代的过程中 梯度下降算法的下降步长大小</span></span><br><span class="line">        <span class="keyword">val</span> stepSize = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//每一次下山后，是否计算所有样本的误差值   fraction：n. 分数；部分；小部分；稍微</span></span><br><span class="line">        <span class="keyword">val</span> miniBatchFraction = <span class="number">1.0</span></span><br><span class="line">        <span class="keyword">val</span> lrs = <span class="keyword">new</span> <span class="type">LinearRegressionWithSGD</span>()<span class="comment">//结合梯度的线性回归算法</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//设置需不需要有截距</span></span><br><span class="line">        lrs.setIntercept(<span class="literal">true</span>)</span><br><span class="line">        lrs.optimizer.setStepSize(stepSize)</span><br><span class="line">        lrs.optimizer.setNumIterations(numIterations)</span><br><span class="line">        lrs.optimizer.setMiniBatchFraction(miniBatchFraction)</span><br><span class="line">        <span class="comment">//开始不停的训练：针对训练集</span></span><br><span class="line">        <span class="keyword">val</span> model: <span class="type">LinearRegressionModel</span> = lrs.run(train2TestData(<span class="number">0</span>))</span><br><span class="line">       <span class="comment">//训练模型的权重：a ， b</span></span><br><span class="line">        println(model.weights)</span><br><span class="line">        <span class="comment">//训练模型的截距：     intercept截；截断；窃听  n. 拦截；[数] 截距；截获的情报</span></span><br><span class="line">        println(model.intercept)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对样本进行测试 ：使用测试集数据    使用测试集的特征值测试</span></span><br><span class="line">        <span class="keyword">val</span> prediction: <span class="type">RDD</span>[<span class="type">Double</span>] =      </span><br><span class="line">                                   model.predict(train2TestData(<span class="number">1</span>).map(_.features))</span><br><span class="line">        <span class="comment">//K：训练集的预测   V：测试集的预测</span></span><br><span class="line">        <span class="keyword">val</span> predictionAndLabel: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] =</span><br><span class="line">                                   prediction.zip(train2TestData(<span class="number">1</span>).map(_.label))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">val</span> print_predict: <span class="type">Array</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = predictionAndLabel.take(<span class="number">100</span>)</span><br><span class="line">        println(<span class="string">"prediction"</span> + <span class="string">"\t"</span> + <span class="string">"label"</span>)</span><br><span class="line">        <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to print_predict.length - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">// val tuple: (Double, Double) = print_predict(i)</span></span><br><span class="line">            println(print_predict(i)._1 + <span class="string">"\t"</span> + print_predict(i)._2)</span><br><span class="line">            <span class="comment">//用以对比预测值和实际值  ，可能存在误差，  因为会有一些噪声数据</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 计算测试误差</span></span><br><span class="line">        <span class="keyword">val</span> loss = predictionAndLabel.map &#123;</span><br><span class="line">            <span class="keyword">case</span> (p, v) =&gt;</span><br><span class="line">                <span class="keyword">val</span> err = p - v</span><br><span class="line">                <span class="type">Math</span>.abs(err)</span><br><span class="line">        &#125;.reduce(_ + _)</span><br><span class="line">        <span class="keyword">val</span> error = loss / train2TestData(<span class="number">1</span>).count</span><br><span class="line">        println(<span class="string">s"Test RMSE = "</span> + error)</span><br><span class="line">        <span class="comment">// 模型保存</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">ModelPath</span> = <span class="string">"model"</span></span><br><span class="line">        <span class="comment">//  model.save(sc, ModelPath)</span></span><br><span class="line"><span class="comment">// 使用模型预测        </span></span><br><span class="line"><span class="comment">// val sameModel: LinearRegressionModel =  LinearRegressionModel.load(sc, ModelPath)</span></span><br><span class="line"><span class="comment">// RDD[Double] rdd = sameModel.pridict(testData:RDD[Vector])</span></span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="三、-贝叶斯分类算法"><a href="#三、-贝叶斯分类算法" class="headerlink" title="三、==贝叶斯分类算法=="></a>三、==贝叶斯分类算法==</h1><h1 id="依据概率原则进行垃圾邮件分类"><a href="#依据概率原则进行垃圾邮件分类" class="headerlink" title="依据概率原则进行垃圾邮件分类"></a>依据概率原则进行垃圾邮件分类</h1><p>朴素贝叶斯算法：依据概率原则进行分类，应用先前事件的有关数据来估计未来事件发生的概率。</p>
<p>基于贝叶斯定理的条件概率：事件A和事件B为相互独立事件</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g2874tfslcj30dm03d74y.jpg" alt=""><br>$$<br>P(A|B) = P(A)*P(B|A)/P(B)<br>$$</p>
<p>案例应用：</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g287bnorbtj318q0uewfq.jpg" alt=""></p>
<p>垃圾邮件案例：</p>
<p>某邮件出现几个单词，判断它是垃圾邮件的概率</p>
<p>但是因为其中某一单词的出现，抵消了或否决了所有其他证据</p>
<h1 id="拉普拉斯估计"><a href="#拉普拉斯估计" class="headerlink" title="拉普拉斯估计"></a>拉普拉斯估计</h1><blockquote>
<p>拉普拉斯估计本质上是给频率表中的每个计数加上一个较小的数，这样就保证了每一类中每个特征发生<strong>概率非零</strong>。</p>
</blockquote>
<blockquote>
<p> 通常情况下，拉普拉斯估计中加上的数值设定为1，这样就保证每一个特征至少在数据中出现一次</p>
</blockquote>
<h3 id="二分类→正负例"><a href="#二分类→正负例" class="headerlink" title="二分类→正负例"></a>二分类→正负例</h3><p>二分类：只有两种情况</p>
<p>​           正：期望结果（如垃圾邮件）     负： 与之相对的结果（正常邮件）</p>
<p>方法一：基于ML （针对DataFrame）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.&#123;<span class="type">NaiveBayes</span>, <span class="type">NaiveBayesModel</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.feature.&#123;<span class="type">CountVectorizer</span>, <span class="type">CountVectorizerModel</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SQLContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Naive_bayes1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"word2vector"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</span><br><span class="line">        <span class="comment">//加载数据</span></span><br><span class="line">        <span class="comment">// ham,It took Mr owl 3 licks</span></span><br><span class="line">        <span class="comment">//spam,"complimentary 4 STAR Ibiza Holiday or £10,000 cash needs your URGENT </span></span><br><span class="line">        <span class="keyword">val</span> idData = sc.textFile(<span class="string">"sms_spam.txt"</span>).map(_.split(<span class="string">","</span>)).cache()</span><br><span class="line">        <span class="comment">//1.0为正常邮件 0.0为垃圾邮件</span></span><br><span class="line">        <span class="keyword">val</span> idDataRows: <span class="type">RDD</span>[<span class="type">Row</span>] = idData.map(x =&gt; </span><br><span class="line">                <span class="type">Row</span>((<span class="keyword">if</span> (x(<span class="number">0</span>) == <span class="string">"ham"</span>) <span class="number">1.0</span> <span class="keyword">else</span> <span class="number">0.0</span>), x(<span class="number">1</span>).split(<span class="string">" "</span>).map(_.trim)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> schema = <span class="type">StructType</span>(<span class="type">List</span>(</span><br><span class="line">            <span class="type">StructField</span>(<span class="string">"label"</span>, <span class="type">DoubleType</span>, nullable = <span class="literal">false</span>),</span><br><span class="line">            <span class="type">StructField</span>(<span class="string">"words"</span>, <span class="type">ArrayType</span>(<span class="type">StringType</span>, <span class="literal">true</span>), nullable = <span class="literal">false</span>)</span><br><span class="line">        ))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> df = sqlContext.createDataFrame(idDataRows, schema)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//构建词汇表/词袋 【i hate you love dont 】</span></span><br><span class="line">        <span class="keyword">val</span> countVectorizer: <span class="type">CountVectorizerModel</span> =      </span><br><span class="line">       <span class="keyword">new</span> <span class="type">CountVectorizer</span>().setInputCol(<span class="string">"words"</span>).setOutputCol(<span class="string">"features"</span>).fit(df)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//查看词汇表</span></span><br><span class="line">        countVectorizer.vocabulary.take(<span class="number">100</span>).foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//文本向量化 CountVector (1,2,1) IdfVector  WordVertor</span></span><br><span class="line">        <span class="keyword">val</span> cvDF: <span class="type">DataFrame</span> = countVectorizer.transform(df)</span><br><span class="line">        <span class="comment">//是否最多只显示20个字符，默认为true。</span></span><br><span class="line">        cvDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//正负例样本，显示前10个</span></span><br><span class="line">        <span class="keyword">val</span> example: <span class="type">DataFrame</span> = cvDF.drop(<span class="string">"words"</span>)</span><br><span class="line">        example.show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 切分数据集与训练集</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = </span><br><span class="line">                                 example.randomSplit(<span class="type">Array</span>(<span class="number">0.8</span>, <span class="number">0.2</span>), seed = <span class="number">1234</span>L)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 训练朴素贝叶斯模型</span></span><br><span class="line">        <span class="keyword">val</span> model: <span class="type">NaiveBayesModel</span> = </span><br><span class="line">                           <span class="keyword">new</span> <span class="type">NaiveBayes</span>() .fit(trainingData)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 预测  predict</span></span><br><span class="line">        <span class="keyword">val</span> predictions: <span class="type">DataFrame</span> = model.transform(testData)</span><br><span class="line"></span><br><span class="line">        predictions.show()</span><br><span class="line">        <span class="comment">//okmail: Dear Dave this is your final notice to collect your!</span></span><br><span class="line">        <span class="comment">//模型评估</span></span><br><span class="line">        <span class="comment">//将结果注册为临时表</span></span><br><span class="line">        predictions.registerTempTable(<span class="string">"result"</span>)</span><br><span class="line">        <span class="comment">//计算正确率</span></span><br><span class="line">        <span class="keyword">val</span> accuracy: <span class="type">DataFrame</span> = sqlContext.sql(</span><br><span class="line">    <span class="string">"select (1- (sum(abs(label-prediction)))/count(label)) as accuracy from result"</span>)</span><br><span class="line">        accuracy.show()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//保存模型</span></span><br><span class="line">        <span class="comment">//    model.save("sms_spam")</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第二种：基于Ml （RDD）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">NaiveBayes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 贝叶斯算法</span></span><br><span class="line"><span class="comment">2,0 0 3</span></span><br><span class="line"><span class="comment">2,0 0 4</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Naive_bayes2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="comment">//1 构建Spark对象</span></span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Naive_bayes"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">//读取样本数据1</span></span><br><span class="line">        <span class="keyword">val</span> data = sc.textFile(<span class="string">"sample_naive_bayes_data.txt"</span>)</span><br><span class="line">        <span class="keyword">val</span> parsedData = data.map &#123; line =&gt;</span><br><span class="line">            <span class="keyword">val</span> parts = line.split(',')</span><br><span class="line">            <span class="type">LabeledPoint</span>(parts(<span class="number">0</span>).toDouble, </span><br><span class="line">                         <span class="type">Vectors</span>.dense(parts(<span class="number">1</span>).split(' ').map(_.toDouble)))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//样本数据划分训练样本与测试样本</span></span><br><span class="line">        <span class="keyword">val</span> splits = parsedData.randomSplit(<span class="type">Array</span>(<span class="number">0.6</span>, <span class="number">0.4</span>), seed = <span class="number">11</span>L)</span><br><span class="line">        <span class="keyword">val</span> training = splits(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">val</span> test = splits(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//新建贝叶斯分类模型模型，并训练</span></span><br><span class="line">        <span class="keyword">val</span> model = <span class="type">NaiveBayes</span>.train(training, lambda = <span class="number">1.0</span>)</span><br><span class="line">        <span class="comment">//对测试样本进行测试</span></span><br><span class="line">        <span class="keyword">val</span> predictionAndLabel = test.map(p =&gt; (model.predict(p.features), p.label))</span><br><span class="line">        <span class="keyword">val</span> print_predict = predictionAndLabel.take(<span class="number">20</span>)</span><br><span class="line">        println(<span class="string">"prediction"</span> + <span class="string">"\t"</span> + <span class="string">"label"</span>)</span><br><span class="line">        <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to print_predict.length - <span class="number">1</span>) &#123;</span><br><span class="line">            println(print_predict(i)._1 + <span class="string">"\t"</span> + print_predict(i)._2)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> accuracy = </span><br><span class="line">        <span class="number">1.0</span> * predictionAndLabel.filter(x =&gt; x._1 == x._2).count() / test.count()</span><br><span class="line">        println(accuracy)</span><br><span class="line">        <span class="comment">//保存模型</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">ModelPath</span> = <span class="string">"naive_bayes_model"</span></span><br><span class="line">        <span class="comment">//    model.save(sc, ModelPath)</span></span><br><span class="line">        <span class="comment">//    val sameModel = NaiveBayesModel.load(sc, ModelPath)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="四、-Kmeans聚类算法"><a href="#四、-Kmeans聚类算法" class="headerlink" title="四、==Kmeans聚类算法=="></a>四、==Kmeans聚类算法==</h1><p><a href="http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html" target="_blank" rel="noopener">http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html</a><br><a href="http://shabal.in/visuals/kmeans/4.html" target="_blank" rel="noopener">http://shabal.in/visuals/kmeans/4.html</a></p>
<h1 id="根据聚类中心点将数据自动划分成类"><a href="#根据聚类中心点将数据自动划分成类" class="headerlink" title="根据聚类中心点将数据自动划分成类"></a>根据聚类中心点将数据自动划分成类</h1><p>K均值聚类</p>
<p>聚类：给事物打标签，寻找同一组内的个体之间的一些潜在的相似模式。力图找到数据的自然分组kmeans</p>
<h3 id="Kmeans算法的基本原理："><a href="#Kmeans算法的基本原理：" class="headerlink" title="Kmeans算法的基本原理："></a>Kmeans算法的基本原理：</h3><ul>
<li><p>聚类是一种<strong>无监督</strong>的机器学习任务，它会自动将数据划分成类cluster。因此聚类分组不需要提前被告知所划分的组应该是什么样的。因为我们甚至可能都不知道我们再寻找什么，所以聚类是用于知识发现而不是预测。</p>
</li>
<li><p>聚类原则是一个组内的记录彼此必须非常相似，而与该组之外的记录截然不同。所有聚类做的就是遍历所有数据然后找到这些相似性</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g296i8zzjcj30d309a75z.jpg" alt=""></p>
</li>
<li><p>使用距离来分配和更新类</p>
</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g296m4ue3bj30bk08igmr.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g297p9ueblj30bu081gmn.jpg" alt=""></p>
<p>选择适当的聚类数：</p>
<h3 id="聚类原则："><a href="#聚类原则：" class="headerlink" title="聚类原则："></a>聚类原则：</h3><p>类内部成员越相似越好；类与类之间的成员差异越大越好</p>
<p>肘部法：求拐点的值</p>
<h3 id="算法思想："><a href="#算法思想：" class="headerlink" title="算法思想："></a>算法思想：</h3><p>–以空间中K个点为中心进行聚类，对最靠近他们的对象归类，通过迭代的方法<br>，逐次更新各聚类中心的值，直到得到最好的聚类结果</p>
<h3 id="算法流程总结："><a href="#算法流程总结：" class="headerlink" title="算法流程总结："></a>算法流程总结：</h3><p>–1、适当选择c个类的初始中心<br>–2、在第K次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在的类<br>–3、利用均值等方法更新该类的中心值<br>–4、对于多有的c个聚类中心，如果利用2,3的迭代法更新后，值保持不变，则迭代结束，否则继续迭代</p>
<h3 id="Kmeans算法的缺陷"><a href="#Kmeans算法的缺陷" class="headerlink" title="Kmeans算法的缺陷"></a>Kmeans算法的缺陷</h3><p> 聚类中心的个数K 需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适<br> Kmeans需要人为地确定初始聚类中心，不同的初始聚类中心可能导致<br>完全不同的聚类结果。（可以使用Kmeans++算法来解决）</p>
<h1 id="Kmeans-算法"><a href="#Kmeans-算法" class="headerlink" title="Kmeans++算法"></a>Kmeans++算法</h1><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p> 从输入的数据点集合中随机选择一个点作为第一个聚类中心<br> 对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)<br> 选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大<br> 重复2和3直到k个聚类中心被选出来<br> 利用这k个初始的聚类中心来运行标准的k-means算法</p>
<h3 id="Kmeans算法的应用："><a href="#Kmeans算法的应用：" class="headerlink" title="Kmeans算法的应用："></a>Kmeans算法的应用：</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.clustering._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KMeans</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="comment">//1 构建Spark对象</span></span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"KMeans"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 读取样本数据1，格式为LIBSVM format     </span></span><br><span class="line">       <span class="comment">/*  0.0 0.0 0.0</span></span><br><span class="line"><span class="comment">           0.1 0.1 0.1  */</span></span><br><span class="line">        <span class="keyword">val</span> data = sc.textFile(<span class="string">"kmeans_data.txt"</span>)</span><br><span class="line">        <span class="keyword">val</span> parsedData: <span class="type">RDD</span>[linalg.<span class="type">Vector</span>] = </span><br><span class="line">                  data.map(s =&gt; <span class="type">Vectors</span>.dense(s.split(' ').map(_.toDouble))).cache()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> numClusters = <span class="number">4</span></span><br><span class="line">        <span class="keyword">val</span> numIterations = <span class="number">100</span></span><br><span class="line">        <span class="keyword">val</span> model: <span class="type">KMeansModel</span> = <span class="keyword">new</span> <span class="type">KMeans</span>().</span><br><span class="line">            setK(numClusters).</span><br><span class="line">            setMaxIterations(numIterations).</span><br><span class="line">            run(parsedData)</span><br><span class="line">        <span class="keyword">val</span> centers: <span class="type">Array</span>[linalg.<span class="type">Vector</span>] = model.clusterCenters</span><br><span class="line">        println(<span class="string">"centers"</span>)</span><br><span class="line">        <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to centers.length - <span class="number">1</span>) &#123;</span><br><span class="line">            println(centers(i)(<span class="number">0</span>) + <span class="string">"\t"</span> + centers(i)(<span class="number">1</span>) + <span class="string">"\t"</span> + centers(i)(<span class="number">2</span>))</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 误差计算</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">WSSSE</span> = model.computeCost(parsedData)</span><br><span class="line">        println(<span class="string">"Errors = "</span> + <span class="type">WSSSE</span>)</span><br><span class="line">        <span class="comment">//打印出属于哪个聚类中心的类 ，的索引</span></span><br><span class="line">        println(model.predict(<span class="type">Vectors</span>.dense(<span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>)))</span><br><span class="line">        <span class="comment">//保存模型</span></span><br><span class="line">        <span class="comment">//    val ModelPath = "KMeans_Model"</span></span><br><span class="line">        <span class="comment">//    model.save(sc, ModelPath)</span></span><br><span class="line">        <span class="comment">//    val sameModel = KMeansModel.load(sc, ModelPath)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="五、-关联规则"><a href="#五、-关联规则" class="headerlink" title="五、==关联规则=="></a>五、==关联规则==</h1><h1 id="指定商品之间关系模式（如啤酒尿布）"><a href="#指定商品之间关系模式（如啤酒尿布）" class="headerlink" title="指定商品之间关系模式（如啤酒尿布）"></a>指定商品之间关系模式（如啤酒尿布）</h1><p>一个典型的规则可以表述为： {花生酱，果酱} –&gt; {面包}</p>
<h3 id="支持度和置信度："><a href="#支持度和置信度：" class="headerlink" title="支持度和置信度："></a>支持度和置信度：</h3><p>一个项集或者规则度量法的支持度是指其在数据中出现的频率</p>
<p>置信度是指该规则的预测能力或者准确度的度量</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g298xxfo38j30f408ajtu.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g299p8axdfj31fd0rejry.jpg" alt=""></p>
<p>理解：</p>
<p>​       项集 的支持度：指该相集在数据集中的概率</p>
<p>​       关联规则:  </p>
<p>​                     就是 由项集 A ， 推出项集 B 发生的概率 ， 而这个概率就是置信度</p>
<p>​       置信度   ： 指由 {AB} 的支持度 /  {A }的支持度 </p>
<p>  Apriori算法是通过设置支持度阈值 ， 找出频繁项集  ，结合关联规则 ， 得出置信度。    </p>
<p>Spark中没有Apriori算法，它的关联规则算法是FPGrowth算法。</p>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g299p1nk7yj31au0o1gmi.jpg" alt=""></p>
<h1 id="Apriori算法-FPGrowth算法"><a href="#Apriori算法-FPGrowth算法" class="headerlink" title="Apriori算法/FPGrowth算法"></a>Apriori算法/FPGrowth算法</h1><p> Apriori原则指的是一个频繁项集的所有子集也必须是频繁的，如果{A,B}是频繁的，那么{A}和{B}都必须是频繁的<br> 根据定义，支持度表示一个项集出现在数据中的频率。因此，如果知道{A}不满足所期望的支持度阈值，那么就没有考虑{A,B}或者任何包含{A}的项集，这些项集绝对不可能是频繁的</p>
<p> Apriori算法利用这个逻辑在实际评估他们之前潜在的关联规则</p>
<ul>
<li><p>分为两个阶段：</p>
<ul>
<li><p>识别所有满足最小支持度阈值的项集</p>
</li>
<li><p>根据满足最小支持度阈值的这些项集来创建规则 </p>
</li>
</ul>
</li>
<li><p>例如，迭代1需要评估一组1项集，迭代2评估2项集，以此类推。在迭代中没有产生新的项集，算法将停止。之后，算法会根据产生的频繁项集，根据所有可能的子集产生关联规则。例如，{A，B}将产生候选规则{A}-&gt;{B}和{B}-&gt;{A}。这些规则将根据最小置信度阈值评估，任何不满足所期望的置信度的规则将被排除</p>
</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/005zftzDgy1g299p7k23jj31a20qdt9w.jpg" alt=""></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.fpm.<span class="type">FPGrowth</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AssociationRule</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * Spark购物篮关联规则算法</span></span><br><span class="line"><span class="comment">      a,b,c</span></span><br><span class="line"><span class="comment">      a,b,d</span></span><br><span class="line"><span class="comment">      a,c</span></span><br><span class="line"><span class="comment">      a,d</span></span><br><span class="line"><span class="comment">      **/</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> inputPath = <span class="string">"shopping_cart"</span></span><br><span class="line">        <span class="keyword">val</span> outputPath = <span class="string">"rs/shopping_cart"</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">            .setMaster(<span class="string">"local"</span>)</span><br><span class="line">            .setAppName(<span class="string">"AssociationRule"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="type">SparkContext</span>.getOrCreate(sparkConf)</span><br><span class="line">        <span class="keyword">val</span> transactions: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(inputPath)</span><br><span class="line">        <span class="comment">//求出商品组合：(List(a,b),1) (List(b,c),1) (List(a,b,c),1)...</span></span><br><span class="line">        <span class="keyword">val</span> patterns: <span class="type">RDD</span>[(<span class="type">List</span>[<span class="type">String</span>], <span class="type">Int</span>)] = </span><br><span class="line">                         transactions.flatMap(line =&gt; &#123;</span><br><span class="line">                         <span class="keyword">val</span> items = line.split(<span class="string">","</span>).toList</span><br><span class="line">                         <span class="comment">//combinations 对项集执行两两自由组合</span></span><br><span class="line">            (<span class="number">0</span> to items.size).flatMap(items.combinations).filter(xs =&gt;</span><br><span class="line">                          !xs.isEmpty)</span><br><span class="line">        &#125;).map((_, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//商品组合出现的频度计算</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * (List(b, c, e),1)</span></span><br><span class="line"><span class="comment">          * (List(b, d, e),1)</span></span><br><span class="line"><span class="comment">          * (List(c, d),2)</span></span><br><span class="line"><span class="comment">          * (List(c, e),2)</span></span><br><span class="line"><span class="comment">          * (List(b),9)</span></span><br><span class="line"><span class="comment">          * (List(a, b, d),1)</span></span><br><span class="line"><span class="comment">          * (List(b, d),5)</span></span><br><span class="line"><span class="comment">          * (List(a, b),3)</span></span><br><span class="line"><span class="comment">          * (List(d, e),2)</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        <span class="keyword">val</span> combined: <span class="type">RDD</span>[(<span class="type">List</span>[<span class="type">String</span>], <span class="type">Int</span>)] = patterns.reduceByKey(_ + _)</span><br><span class="line">        combined.collect().foreach(println)</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * 算出所有的关联规则</span></span><br><span class="line"><span class="comment">          * (List(b, c, e),(List(),1))</span></span><br><span class="line"><span class="comment">          * (List(c, e),(List(b, c, e),1))</span></span><br><span class="line"><span class="comment">          * (List(b, e),(List(b, c, e),1))</span></span><br><span class="line"><span class="comment">          * (List(b, c),(List(b, c, e),1))</span></span><br><span class="line"><span class="comment">          * (List(b, d, e),(List(),1))</span></span><br><span class="line"><span class="comment">          * (List(e),(List(c, e),2))</span></span><br><span class="line"><span class="comment">          * (List(c),(List(c, e),2))</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        <span class="keyword">val</span> subpatterns: <span class="type">RDD</span>[(<span class="type">List</span>[<span class="type">String</span>], (<span class="type">List</span>[<span class="type">String</span>], <span class="type">Int</span>))] =</span><br><span class="line">             combined.flatMap(pattern =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> result = </span><br><span class="line">            <span class="type">ListBuffer</span>.empty[<span class="type">Tuple2</span>[<span class="type">List</span>[<span class="type">String</span>], <span class="type">Tuple2</span>[<span class="type">List</span>[<span class="type">String</span>], <span class="type">Int</span>]]]</span><br><span class="line">            result += ((pattern._1, (<span class="type">Nil</span>, pattern._2)))</span><br><span class="line">            print(result)</span><br><span class="line">            <span class="keyword">val</span> sublist= <span class="keyword">for</span> &#123;</span><br><span class="line">                i &lt;- <span class="number">0</span> until pattern._1.size</span><br><span class="line">                xs = pattern._1.take(i) ++ pattern._1.drop(i + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> xs.size &gt; <span class="number">0</span></span><br><span class="line">            &#125; <span class="keyword">yield</span> (xs, (pattern._1, pattern._2))</span><br><span class="line">            result ++= sublist</span><br><span class="line">            println(<span class="string">" : "</span> + result.toList)</span><br><span class="line">            result.toList</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        subpatterns.collect().foreach(x =&gt; &#123;println(x + <span class="string">"-----------"</span>)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rules: <span class="type">RDD</span>[(<span class="type">List</span>[<span class="type">String</span>], <span class="type">Iterable</span>[(<span class="type">List</span>[<span class="type">String</span>], <span class="type">Int</span>)])] =</span><br><span class="line">                subpatterns.groupByKey()</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算每个规则的概率</span></span><br><span class="line">        <span class="keyword">val</span> assocRules: <span class="type">RDD</span>[<span class="type">List</span>[(<span class="type">List</span>[<span class="type">String</span>], <span class="type">List</span>[<span class="type">String</span>], <span class="type">Double</span>)]] =</span><br><span class="line">        rules.map(in =&gt; &#123;</span><br><span class="line"><span class="comment">//          val a: Iterable[(List[String], Int)] = in._2</span></span><br><span class="line">            <span class="keyword">val</span> fromCount = in._2.find(p =&gt; p._1 == <span class="type">Nil</span>).get</span><br><span class="line">            <span class="keyword">val</span> lstData = in._2.filter(p =&gt; p._1 != <span class="type">Nil</span>).toList</span><br><span class="line">            <span class="keyword">if</span> (lstData.isEmpty) <span class="type">Nil</span></span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">val</span> result = &#123;</span><br><span class="line">                    <span class="keyword">for</span> &#123;</span><br><span class="line">                        t2 &lt;- lstData</span><br><span class="line">                        confidence = t2._2.toDouble / fromCount._2.toDouble</span><br><span class="line">                        difference = t2._1 diff in._1</span><br><span class="line">                    &#125; <span class="keyword">yield</span> (((in._1, difference, confidence)))</span><br><span class="line">                &#125;</span><br><span class="line">                result</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">val</span> formatResult: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Double</span>)] = </span><br><span class="line">       assocRules.flatMap(f =&gt; &#123;</span><br><span class="line">            f.map(s =&gt; </span><br><span class="line">            (s._1.mkString(<span class="string">"["</span>, <span class="string">","</span>, <span class="string">"]"</span>), s._2.mkString(<span class="string">"["</span>, <span class="string">","</span>, <span class="string">"]"</span>), s._3))</span><br><span class="line">        &#125;).sortBy(tuple =&gt; tuple._3, <span class="literal">false</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">//保存结果</span></span><br><span class="line">        <span class="comment">//formatResult.saveAsTextFile(outputPath)</span></span><br><span class="line">        <span class="comment">//打印商品组合频度</span></span><br><span class="line">        combined.foreach(println)</span><br><span class="line">        <span class="comment">//打印商品关联规则和置信度</span></span><br><span class="line">        formatResult.foreach(println)</span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="六、-逻辑回归"><a href="#六、-逻辑回归" class="headerlink" title="六、==逻辑回归=="></a>六、==逻辑回归==</h1><p>官网：<a href="http://spark.apache.org/docs/latest/mllib-linear-methods.html#classification" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/mllib-linear-methods.html#classification</a></p>
<p>逻辑回归是一种<strong>线性</strong><code>有监督</code><strong>分类</strong>模型</p>
<p>主要用于做分类 ， 常见的是二分类（分成两个类）， 被命名为 正负例类。还有多分类（多于两个类型）</p>
<p>有监督：有Y值用来测试结果</p>
<p>无监督：无Y值用来参考</p>
<h1 id="预测是否生病"><a href="#预测是否生病" class="headerlink" title="预测是否生病"></a>预测是否生病</h1><p><code>逻辑回归</code>是一种用于分类的模型，就相当于y=f(x)，表明输入与输出（类别）的关系。</p>
<p>最常见问题有如医生治病时的望、闻、问、切，之后判定病人是否生病或生了什么病，其中的望闻问切就是输入，即特征数据，判断是否生病就相当于获取因变量y，即分类结果。</p>
<p>二分类：结合训练医疗模型，根据输入的特征数据，判断因变量Y的值（要么健康，要么生病）。</p>
<h2 id="逻辑回归和线性回归的差别："><a href="#逻辑回归和线性回归的差别：" class="headerlink" title="逻辑回归和线性回归的差别："></a>逻辑回归和线性回归的差别：</h2><table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center"><em>线性回归</em></th>
<th style="text-align:center"><em>逻辑回归</em></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">目的</td>
<td style="text-align:center">预测</td>
<td style="text-align:center">分类</td>
</tr>
<tr>
<td style="text-align:center"><img src="https://private.codecogs.com/gif.latex?%5Cdpi%7B100%7D%20y%5E%7B%28i%29%7D" alt="y^{(i)}"><span class="img-alt">y^{(i)}</span></td>
<td style="text-align:center">未知</td>
<td style="text-align:center">{0,1}</td>
</tr>
<tr>
<td style="text-align:center">函数</td>
<td style="text-align:center">拟合函数</td>
<td style="text-align:center">预测函数</td>
</tr>
<tr>
<td style="text-align:center">参数计算方式</td>
<td style="text-align:center">最小二乘</td>
<td style="text-align:center">最大似然估计</td>
</tr>
</tbody>
</table>
<h2 id="代码案例："><a href="#代码案例：" class="headerlink" title="代码案例："></a>代码案例：</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.&#123;<span class="type">LogisticRegressionWithLBFGS</span>, <span class="type">LogisticRegressionWithSGD</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.optimization.&#123;<span class="type">L1Updater</span>, <span class="type">SquaredL2Updater</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">LogisticRegression4</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"spark"</span>).setMaster(<span class="string">"local[3]"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">     <span class="comment">/*数据类型：</span></span><br><span class="line"><span class="comment">     1 1:56 2:1 3:0 4:3 5:4 6:3 </span></span><br><span class="line"><span class="comment">     0 1:18 2:0 3:0 4:4 5:3 6:3 </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">        <span class="keyword">val</span> inputData: <span class="type">RDD</span>[<span class="type">LabeledPoint</span>] = </span><br><span class="line">                                  <span class="type">MLUtils</span>.loadLibSVMFile(sc, <span class="string">"健康状况训练集.txt"</span>)</span><br><span class="line">        <span class="keyword">val</span> splits = inputData.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line">        <span class="keyword">val</span> (trainingData, testData) = (splits(<span class="number">0</span>), splits(<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">val</span> lr = <span class="keyword">new</span> <span class="type">LogisticRegressionWithLBFGS</span>()</span><br><span class="line">        lr.setIntercept(<span class="literal">true</span>）<span class="comment">//设置截距</span></span><br><span class="line">        <span class="comment">//    val model = lr.run(trainingData)</span></span><br><span class="line">        <span class="comment">//    val result = testData.map&#123;point=&gt;</span></span><br><span class="line">        <span class="comment">//               Math.abs(point.label-model.predict(point.features)) &#125;</span></span><br><span class="line">        <span class="comment">//    println("正确率="+(1.0-result.mean()))</span></span><br><span class="line">        <span class="comment">//    println(model.weights.toArray.mkString(" "))</span></span><br><span class="line">        <span class="comment">//    println(model.intercept)</span></span><br><span class="line"><span class="comment">//将模型设置为不返回 0 ， 1  结果，而返回结果为 计算的概率</span></span><br><span class="line">        <span class="keyword">val</span> model = lr.run(trainingData).clearThreshold()</span><br><span class="line">        <span class="keyword">val</span> errorRate = testData.map &#123; p =&gt;</span><br><span class="line">            <span class="keyword">val</span> score = model.predict(p.features)</span><br><span class="line">            <span class="comment">// 癌症病人宁愿错判断出得癌症也别错过一个得癌症的病人</span></span><br><span class="line">            <span class="keyword">val</span> result = score &gt; <span class="number">0.5</span> <span class="keyword">match</span> &#123;</span><br><span class="line">                <span class="keyword">case</span> <span class="literal">true</span> =&gt; <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">case</span> <span class="literal">false</span> =&gt; <span class="number">0</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//为了规避风险，可以调整固定阈值0.5</span></span><br><span class="line">            <span class="type">Math</span>.abs(result - p.label)</span><br><span class="line">        &#125;.mean()<span class="comment">//求均值</span></span><br><span class="line">        println(<span class="number">1</span> - errorRate)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>出现线性不可分的情况时，可以使用调维方法， 如将二维数据变成三维数据</p>
<h1 id="鲁棒性调优"><a href="#鲁棒性调优" class="headerlink" title="鲁棒性调优"></a>鲁棒性调优</h1><p>W在数值上越小越好，这样越能抵抗数据的扰动</p>
<h1 id="数值优化"><a href="#数值优化" class="headerlink" title="数值优化"></a>数值优化</h1><h2 id="最大值最小值法"><a href="#最大值最小值法" class="headerlink" title="最大值最小值法"></a>最大值最小值法</h2><ul>
<li>归一化的一种方法：最大值最小值法</li>
<li>缺点<ul>
<li>抗干扰能力 弱</li>
<li>受离群值得影响比较大</li>
<li>中间容易没有数据</li>
</ul>
</li>
</ul>
<h2 id="方差归一化"><a href="#方差归一化" class="headerlink" title="方差归一化"></a>方差归一化</h2><ul>
<li>归一化的一种方法：方差归一化</li>
<li>优点<ul>
<li>抗干扰能力强，和所有数据都有关, 求标准差需要所有值的介入，重要有离群值的话，会被抑<br> 制下来</li>
</ul>
</li>
<li>缺点<ul>
<li>最终未必会落到0到1之间</li>
</ul>
</li>
<li>牺牲归一化结果为代价提高稳定</li>
</ul>
<h2 id="均值归一化："><a href="#均值归一化：" class="headerlink" title="均值归一化："></a>均值归一化：</h2><p> 每个数量减去平均值</p>
<h1 id="七、-随机森林"><a href="#七、-随机森林" class="headerlink" title="七、==随机森林=="></a>七、==随机森林==</h1><h2 id="天气与车祸的关系"><a href="#天气与车祸的关系" class="headerlink" title="天气与车祸的关系"></a>天气与车祸的关系</h2><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><ul>
<li><p>决策树</p>
<ul>
<li>决策树是一个预测模型;他代表的是对象属性与对象值之间的一种映射关系</li>
<li>决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试<br>输出，每个叶节点代表一种类别。</li>
</ul>
</li>
<li><p>决策树 思想，实际上就是寻找最纯净的划分 方法。</p>
</li>
<li><p>决策树是一种 <strong>非线性</strong> <code>有监督</code> <strong>分类</strong> 模型<br> 线性分类模型比如说逻辑回归，可能会存在不可分问题，但是非线性分类就不存在</p>
</li>
<li><p>决策树是通过固定的条件来对类别进行判断：</p>
</li>
<li><p>决策树方法</p>
<ul>
<li>决策树的生成：数据不断分裂的递归过程，每一次分裂，尽可能让类别一样的数据在树的一边，当树的叶子节点的数据都是一类的时候，则停止分类。(if else 语句)</li>
</ul>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.tree.<span class="type">DecisionTree</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.tree.model.<span class="type">DecisionTreeModel</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ClassificationDecisionTree</span> </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">"analysItem"</span>)</span><br><span class="line">    conf.setMaster(<span class="string">"local[3]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        1 1:3 2:1 3:1 4:1 5:66 </span></span><br><span class="line"><span class="comment">        0 1:1 2:3 3:2 4:2 5:47 </span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="keyword">val</span> data = <span class="type">MLUtils</span>.loadLibSVMFile(sc, <span class="string">"汽车数据样本.txt"</span>)</span><br><span class="line">        <span class="comment">// Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">        <span class="keyword">val</span> splits = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line">        <span class="keyword">val</span> (trainingData, testData) = (splits(<span class="number">0</span>), splits(<span class="number">1</span>))</span><br><span class="line">        <span class="comment">//指明类别,二分类</span></span><br><span class="line">        <span class="keyword">val</span> numClasses = <span class="number">2</span></span><br><span class="line">        <span class="comment">//指定离散变量，未指明的都当作连续变量处理</span></span><br><span class="line">        <span class="comment">//1,2,3,4维度进来就变成了0,1,2,3</span></span><br><span class="line">        <span class="comment">//这里天气维度有3类,但是要指明4,这里是个坑,后面以此类推</span></span><br><span class="line">        <span class="keyword">val</span> categoricalFeaturesInfo = <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Int</span>](<span class="number">0</span> -&gt; <span class="number">4</span>, <span class="number">1</span> -&gt; <span class="number">4</span>, <span class="number">2</span> -&gt; <span class="number">3</span>, <span class="number">3</span> -&gt; <span class="number">3</span>)</span><br><span class="line">        <span class="comment">//设定评判标准</span></span><br><span class="line">        <span class="keyword">val</span> impurity = <span class="string">"entropy"</span></span><br><span class="line">        <span class="comment">//树的最大深度,太深运算量大也没有必要  剪枝</span></span><br><span class="line">        <span class="keyword">val</span> maxDepth = <span class="number">3</span></span><br><span class="line">        <span class="comment">//设置离散化程度,连续数据需要离散化,分成32个区间,默认其实就是32,分割的区间保证数量差不多  这个参数也可以进行剪枝</span></span><br><span class="line">        <span class="keyword">val</span> maxBins =<span class="number">10</span></span><br><span class="line">        <span class="comment">//生成模型</span></span><br><span class="line">        <span class="keyword">val</span> model: <span class="type">DecisionTreeModel</span> = </span><br><span class="line">        <span class="type">DecisionTree</span>.trainClassifier(trainingData, numClasses,</span><br><span class="line">                                     categoricalFeaturesInfo, impurity, </span><br><span class="line">                                     maxDepth, maxBins)</span><br><span class="line">        <span class="comment">//测试</span></span><br><span class="line">        <span class="keyword">val</span> labelAndPreds: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = testData.map &#123; point =&gt;</span><br><span class="line">            <span class="keyword">val</span> prediction = model.predict(point.features)</span><br><span class="line">            (point.label, prediction)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">val</span> testErr = labelAndPreds.filter(r =&gt; r._1 != r._2).count().toDouble / testData.count()</span><br><span class="line">        println(<span class="string">"Test Error = "</span> + testErr)</span><br><span class="line">        println(<span class="string">"Learned classification tree model:\n"</span> + model.toDebugString)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p> 随机森林是一种非线性有监督分类模型<br> 森林：由树组成<br> 随机：生成树的数据都是从数据集中随机选取的</p>
<p>生成方式</p>
<p>当数据集很大的时候，我们随机选取数据集的一部分，生成一棵树，重复上述过程，我们可以生成一堆形态各异的树，这些树放在一起就叫森林。</p>
<table>
<thead>
<tr>
<th style="text-align:center">逻辑回归</th>
<th style="text-align:center">随机森林</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">软分类</td>
<td style="text-align:center">硬分类</td>
</tr>
<tr>
<td style="text-align:center">线性模型</td>
<td style="text-align:center">非线性模型</td>
</tr>
<tr>
<td style="text-align:center">输出有概率意义</td>
<td style="text-align:center">输出无概率意义</td>
</tr>
<tr>
<td style="text-align:center">抗干扰能力强</td>
<td style="text-align:center">抗干扰能力弱</td>
</tr>
</tbody>
</table>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkContext</span>, <span class="type">SparkConf</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.tree.<span class="type">RandomForest</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ClassificationRandomForest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">"analysItem"</span>)</span><br><span class="line">    conf.setMaster(<span class="string">"local[3]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//读取数据</span></span><br><span class="line">        <span class="keyword">val</span> data = <span class="type">MLUtils</span>.loadLibSVMFile(sc, <span class="string">"汽车数据样本.txt"</span>)</span><br><span class="line">        <span class="comment">//将样本按7：3的比例分成</span></span><br><span class="line">        <span class="keyword">val</span> splits = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line">        <span class="keyword">val</span> (trainingData, testData) = (splits(<span class="number">0</span>), splits(<span class="number">1</span>))</span><br><span class="line">        <span class="comment">//分类数</span></span><br><span class="line">        <span class="keyword">val</span> numClasses = <span class="number">2</span></span><br><span class="line">        <span class="comment">// categoricalFeaturesInfo 为空，意味着所有的特征为连续型变量</span></span><br><span class="line">        <span class="keyword">val</span> categoricalFeaturesInfo = <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Int</span>](<span class="number">0</span> -&gt; <span class="number">4</span>, <span class="number">1</span> -&gt; <span class="number">4</span>, <span class="number">2</span> -&gt; <span class="number">3</span>, <span class="number">3</span> -&gt; <span class="number">3</span>)</span><br><span class="line">        <span class="comment">//树的个数</span></span><br><span class="line">        <span class="keyword">val</span> numTrees = <span class="number">3</span></span><br><span class="line">        <span class="comment">//特征子集采样策略，auto 表示算法自主选取</span></span><br><span class="line">        <span class="comment">//"auto"根据特征数量在4个中进行选择</span></span><br><span class="line">    <span class="comment">// 1,all 全部特征 2,sqrt 把特征数量开根号后随机选择的 3,log2 取对数个 4,onethird 三分之一</span></span><br><span class="line">        <span class="keyword">val</span> featureSubsetStrategy = <span class="string">"auto"</span></span><br><span class="line">        <span class="comment">//纯度计算</span></span><br><span class="line">        <span class="keyword">val</span> impurity = <span class="string">"entropy"</span></span><br><span class="line">        <span class="comment">//树的最大层次</span></span><br><span class="line">        <span class="keyword">val</span> maxDepth = <span class="number">3</span></span><br><span class="line">        <span class="comment">//特征最大装箱数,即连续数据离散化的区间</span></span><br><span class="line">        <span class="keyword">val</span> maxBins = <span class="number">32</span></span><br><span class="line">        <span class="comment">//训练随机森林分类器，trainClassifier 返回的是 RandomForestModel 对象</span></span><br><span class="line">        <span class="keyword">val</span> model = </span><br><span class="line">     <span class="type">RandomForest</span>.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,</span><br><span class="line">            numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)</span><br><span class="line">        <span class="comment">//打印模型</span></span><br><span class="line">        println(model.toDebugString)</span><br><span class="line">        <span class="comment">//保存模型</span></span><br><span class="line">        <span class="comment">//model.save(sc,"汽车保险")</span></span><br><span class="line">        <span class="comment">//在测试集上进行测试</span></span><br><span class="line">        <span class="keyword">val</span> count = testData.map &#123; point =&gt;</span><br><span class="line">            <span class="keyword">val</span> prediction = model.predict(point.features)</span><br><span class="line">            <span class="comment">//    Math.abs(prediction-point.label)</span></span><br><span class="line">            (prediction, point.label)</span><br><span class="line">        &#125;.filter(r =&gt; r._1 != r._2).count()</span><br><span class="line">        println(<span class="string">"Test Error = "</span> + count.toDouble / testData.count().toDouble)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-大型网站日志分析系统" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/25/大型网站日志分析系统/" class="article-date">
      <time datetime="2019-02-24T16:00:00.000Z" itemprop="datePublished">2019-02-25</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/25/大型网站日志分析系统/">日志分析系统</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">164字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">1分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              Nginx作负载均衡，接收网站日志数据，并通过Flume收集日志保存到HDFS中，使用MapReduce作数据的ETL工作，清洗后的数据存在HBase中 ， 再使用MapReduce 或 Sqoop+Hive 将目标数据存放在MySql中，提供给Web 使用 
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/MapReduce/">MapReduce</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大型网站日志分析系统/">大型网站日志分析系统</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/离线分析/">离线分析</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/25/大型网站日志分析系统/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-Spark优化" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/23/Spark优化/" class="article-date">
      <time datetime="2019-02-22T16:00:00.000Z" itemprop="datePublished">2019-02-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/23/Spark优化/">Spark调优</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">7.6k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">28分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              资源调优，并行度调优，代码调优，数据本地化级别，内存调优，sparkshuffle调优，调节excutor的堆外内存，解决数据倾斜，spark故障解决
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/内存/">内存</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据倾斜/">数据倾斜</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/资源/">资源</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/23/Spark优化/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-Spark学习（6）" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/22/Spark学习（6）/" class="article-date">
      <time datetime="2019-02-21T16:00:00.000Z" itemprop="datePublished">2019-02-22</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/22/Spark学习（6）/">Spark学习（六）</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">7k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">33分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              SparkStreaming 是流式处理框架，是 Spark API 的扩展，支持可扩展、高吞吐量、容错的实时数据流处理
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkStreaming/">SparkStreaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark框架/">Spark框架</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/流式处理框架/">流式处理框架</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/22/Spark学习（6）/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-Spark学习（5）" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/21/Spark学习（5）/" class="article-date">
      <time datetime="2019-02-20T16:00:00.000Z" itemprop="datePublished">2019-02-21</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/21/Spark学习（5）/">Spark学习（五）</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">8.8k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">44分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              SparkSql是基于 Spark 计算框架之上且兼容 Hive 语法的 SQL 执行引擎,DataFrame的六种创建方式 ,三种保存方式,Spark on Hive ,关于序列化,自定义函数UDF和UDAF ， 以及开窗函数 
          
      
    </div>
    
    <div class="article-info article-info-index">
      
        <div class="article-pop-out tagcloud">
          <a class="">置顶</a>
        </div>
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SQL语句/">SQL语句</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkSql/">SparkSql</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark框架/">Spark框架</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/21/Spark学习（5）/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-Shuffle调优" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/20/Shuffle调优/" class="article-date">
      <time datetime="2019-02-19T16:00:00.000Z" itemprop="datePublished">2019-02-20</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/20/Shuffle调优/">SparkShuffle调优</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">1.3k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">4分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              SparkShuffle调优的参数配置及含义
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkCore/">SparkCore</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/20/Shuffle调优/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-Spark学习（4）" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/19/Spark学习（4）/" class="article-date">
      <time datetime="2019-02-18T16:00:00.000Z" itemprop="datePublished">2019-02-19</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/19/Spark学习（4）/">Spark学习（四）</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">3k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">12分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              Spark：广播变量、累加器、SparkShuffle（hashShuffle，sortShuffle，shuffle寻址）、spark内存管理（统一 ， 静态 ）、shuffle调优
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkShuffle/">SparkShuffle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shuffle调优/">shuffle调优</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sparkcore/">sparkcore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark内存管理/">spark内存管理</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/广播/">广播</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/累加/">累加</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/19/Spark学习（4）/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
    <article id="post-Spark学习（3）" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/02/18/Spark学习（3）/" class="article-date">
      <time datetime="2019-02-17T16:00:00.000Z" itemprop="datePublished">2019-02-18</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/18/Spark学习（3）/">Spark学习（三）</a>
    </h1>
  

        
           <div style="margin-top:10px;"> 
     <span class="post-time"> 
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-keyboard-o"></i> 
                 <span class="post-meta-item-text"> 字数统计: </span> 
                 <span class="post-count">4.3k字</span> 
           </span>
     </span> 

     <span class="post-time">
           |   
           <span class="post-meta-item-icon"> 
                 <i class="fa fa-hourglass-half"></i> 
                 <span class="post-meta-item-text"> 阅读时长: </span> 
                 <span class="post-count">23分</span> 
           </span> 
     </span> 
</div>

           
      </header>     
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              Spark案例学习:统计网站 pv 和 uv,二次排序,分组取topN
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-shell/">Spark shell</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sparkcore/">sparkcore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/参数解释/">参数解释</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/计算框架/">计算框架</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2019/02/18/Spark学习（3）/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











<!--gitment 评论-->

<!--gitment 评论 end-->
  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                
                2016-2019 Sukie
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style="display:none">
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style="display:none">
                        <span id="page-visit" title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        

        <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span> 
        <script>
        var now = new Date(); 
        function createtime() { 
        var grt= new Date("02/14/2016 12:49:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
        } 
        setInterval("createtime()",250);
        </script>

    </div>
</footer>
    </div>
    
    <script src="/js/GithubRepoWidget.js"></script>

<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>


    

     




    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
             github: ".github-widget a", 
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

    <script>
        var originTitle = document.title;
        var titleTime;
        document.addEventListener("visibilitychange", function() {
            if (document.hidden) {
                document.title = "(つェ⊂) 我藏好了哦~ " + originTitle;
                clearTimeout(titleTime);
            }
            else {
                document.title = "(*´∇｀*) 被你发现啦~ " + originTitle;
                titleTime = setTimeout(function() {
                    document.title = originTitle;
                }, 2000);
            }
        })
    </script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<script typr="text/javascript" src="/resources/love.js"></script>
<script typr="text/javascript" src="/resources/float.js"></script>
<script typr="text/javascript" src="/resources/typewriter.js"></script>
<script typr="text/javascript" color="1,104,183" opacity="1" zindex="-1" count50="" src="/resources/particle.js"></script>
  </div>
</body>
</html>