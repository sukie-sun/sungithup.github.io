[{"title":"","date":"2019-01-23T15:33:18.759Z","path":"2019/01/23/Nginx入门学习（第一回合）/","text":"Nginx入门学习（第一回合）[^开发者]: 由俄罗斯的程序设计师Igor Sysoev所开发 [TOC] 一、产生背景1.巨大流量—海量的并发访问 2.单台服务器资源和能力有限 引发服务器宕机而无法提供服务 二、负载均衡(Load Balance)1、高并发（1）、高（大量的） （2）、并发就是可以使用多个线程或者多个进程，同时处理（就是并发）不同的操作 （3）、简而言之就是每秒内有多少个请求同时访问。 2、负载均衡（1）、将请求/数据【均匀】分摊到多个操作单元上执行 （2）、关键在于【均匀】,也是分布式系统架构设计中必须考虑的因素之一。 3、互联网分布式架构常见，分为客户端层、反向代理nginx层、站点层、服务层、数据层。只需要实现“将请求/数据 均匀分摊到多个操作单元上执行”，就能实现负载均衡。 三、对Nginx的基本了解1、什么是Nginx？1一款轻量级的Web 服务器/反向代理服务器【后面有介绍】及电子邮件（IMAP/POP3）代理服务器。 ​ 特点 12*是占有内存少，CPU、内存等资源消耗却非常低，*运行非常稳定并发能力强，nginx的并发能力确实在同类型的网页服务器中表现非常好。 2、Nginx VS Apache（1）、nginx相对于apache的优点：1234*轻量级，同样起web 服务，比apache 占用更少的内存及资源高并发，*nginx 处理请求是异步非阻塞（如前端ajax）的，而apache 则是阻塞型的，*在高并发下nginx能保持低资源低消耗高性能高度模块化的设计，编写模块相对简单*Nginx 配置简洁, Apache 复杂 （2）、apache 相对于nginx 的优点：12* Rewrite重写 ，比nginx 的rewrite 强大模块超多，*基本想到的都可以找到少bug ，nginx 的bug 相对较多。（出身好起步高） 四、安装Nginx这里以安装tengine为例 1、安装之前准备配置依赖 gcc openssl-devel pcre-devel zlib-devel 安装： yum install gcc openssl-devel pcre-devel zlib-devel -y 2、下载（目前最新版）：tengine-2.2.3.tar 3、 解压缩 tar -zvxf tengine-2.2.3.tar 4、安装Nginx 在Nginx解压的目录下运行： ./configure make &amp;&amp; make install 默认安装目录：/usr/local/nginx 5、配置Nginx为系统服务，以方便管理（1）、在/etc/rc.d/init.d/目录中建立文本文件nginx（2）、在文件中粘贴下面的内容：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \\# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0 nginx=&quot;/usr/local/nginx/sbin/nginx&quot;prog=$(basename $nginx) NGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot; [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`nginx -V 2&gt;&amp;1 | grep &quot;configure arguments:&quot; | sed &apos;s/[^*]*--user=\\([^ ]*\\).*/\\1/g&apos; -` options=`$nginx -V 2&gt;&amp;1 | grep &apos;configure arguments:&apos;` for opt in $options; do if [ `echo $opt | grep &apos;.*-temp-path&apos;` ]; then value=`echo $opt | cut -d &quot;=&quot; -f 2` if [ ! -d &quot;$value&quot; ]; then # echo &quot;creating&quot; $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $&quot;Starting $prog: &quot; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; configtest || return $? stop sleep 1 start&#125; reload() &#123; configtest || return $? echo -n $&quot;Reloading $prog: &quot; killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;&quot; exit 2esac （3）、修改nginx文件的执行权限 chmod +x nginx （4）、添加该文件到系统服务中去 chkconfig –add nginx 查看是否添加成功 chkconfig –list nginx 启动，停止，重新装载 service nginx start|stop 五、Nginx配置1、查看配置 cd /usr/local/nginx/conf vim nginx.conf 2、配置解析12345678910111213141516171819202122232425262728293031323334#进程数，建议设置和CPU个数一样或2倍worker_processes 2;#日志级别error_log logs/error.log warning;(默认error级别)# nginx 启动后的pid 存放位置#pid logs/nginx.pid;events &#123; #配置每个进程的连接数，总的连接数= worker_processes * worker_connections #默认1024 worker_connections 10240;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on;#连接超时时间，单位秒keepalive_timeout 65; server &#123; listen 80; server_name localhost #默认请求 location / &#123; root html; #定义服务器的默认网站根目录位置 index index.php index.html index.htm; #定义首页索引文件的名称 &#125; #定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; 3、负载均衡配置1）安装Tomcat，参考 Tomcat配置 2）多负载均执行一下操作： 多负载的情况下，打开指定虚拟机器 open node01 node01 为指定虚拟机器的别名，在hosts文件中配置的 启动Tomcat 在Tomcat解压的目录下 ./startup.sh 注意： 记得关闭虚拟机器的防火墙 service iptables stop 浏览器访问 虚拟机器IP地址：8080 默认负载均衡配置 123456789101112131415161718192021&gt; http &#123; &gt; upstream shsxt&#123; &gt; # 以下均为实际执行服务的服务器&gt; #只有当hosts文件中给ip地址配置了别名，这里server后面才能用别名，&gt; #否则跟IP地址&gt; server node01; &gt; server node02; &gt; server node03; &gt; &#125; &gt; &gt; server &#123; &gt; #指定访问端口为80 ，那么Tomcat服务器端的port也要改为80&gt; listen 80; &gt; server_name localhost;&gt; location / &#123;&gt; proxy_pass http://shsxt; &gt; # shsxt 是指定的代理服务器&gt; &#125;&gt; &#125; &gt; &#125;&gt; 查看使用 80端口的程序 netstat -anp |grep 80 配置文件编辑结束后，启动nginx服务 service nginx start （1）、轮询负载均衡（默认）1- 对应用程序服务器的请求以循环方式分发 （2）、加权负载均衡 通过使用服务器权重，还可以进一步影响nginx负载均衡算法， 谁的权重越大，分发到的请求就越多。 权重总数：10 在nginx.conf文件中修改： 12345upstream shsxt &#123; server srv1.example.com weight=3;//域名为在/etc/hosts文件中取的别名 server srv2.example.com; server srv3.example.com; &#125; 配置修改之后，重启 service nginx restart （3）、最少连接负载平衡 在连接负载最少的情况下，nginx会尽量避免将过多的请求分发给繁忙的应用程序服务器， 而是将新请求分发给不太繁忙的服务器，避免服务器过载。 在nginx.conf文件中修改： 123456upstream shsxt &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; （4）、会话持久性——ip-hash负载平衡机制特点：保证相同的客户端总是定向到相同的服务; (此方法可确保来自同一客户端的请求将始终定向到同一台服务器，除非此服务器不可用。) 在nginx.conf文件中修改： 123456upstream shsxt&#123; ip_hash; server （IP地址|别名）; server （IP地址|别名）; server （IP地址|别名）;&#125; (5)、Nginx的访问控制 Nginx还可以对IP的访问进行控制，allow代表允许，deny代表禁止. 12345678location / &#123;deny 192.168.2.180;allow 192.168.78.0/24;allow 10.1.1.0/16;allow 192.168.1.0/32;deny all;proxy_pass http://shsxt;&#125; 12345从上到下的顺序，匹配到了便跳出。如上的例子先禁止了1个，接下来允许了3个网段，其中包含了一个ipv6，最后未匹配的IP全部禁止访问","tags":[]},{"title":"","date":"2019-01-23T15:33:18.734Z","path":"2019/01/23/Nginx入门学习（第二回合）/","text":"Nginx入门学习（第二回合）2018年12月20日 周四 阴 一、虚拟主机1、什么是虚拟主机？（1）是指在网络服务器上分出一定的磁盘空间，租给用户以放置站点以及应用空间，并提供必要的存储和传输功能。 （2）是被虚拟化的逻辑主机，也可理解为就是把一台物理服务器划分成多个“虚拟“的服务器，各个虚拟主机之间完全独立，对外界呈现的状态也同单独物理主机表现完全相同。 2、虚拟主有啥特点？（1）多台虚拟主机共享一台真实主机资源，大幅度降低了硬件、网络维护、通信线路等的费用 （2）也大大简化了服务器管理的复杂性； 3、虚拟主机有哪些类别？（1）基于域名 1234567891011121314151617181920212223242526http &#123; upstream shsxt&#123; server node01; server node02; &#125; upstream bjsxt&#123; server node03; &#125; server &#123; listen 80; //访问sxt2.com的时候，会把请求导到bjsxt的服务器组里 server_name sxt2.com; location / &#123; proxy_pass http://bjsxt; &#125; &#125; server &#123; listen 80; //访问sxt1.com的时候，会把请求导到shsxt的服务器组里 server_name sxt1.com; location / &#123; proxy_pass http://shsxt; &#125; &#125; &#125; 注意： （1）基于域名的虚拟机主机 在模拟应用场景时，需要在windows系统的hosts文件里配置域名映射。 （C:\\Windows\\System32\\drivers\\etc\\hosts 给IP取别名） 如：192.168.198.130 sxt1.com （2）每台服务器的Tomcat的端口不与配置的listen一致，那么windows系统浏览器访问时，需要加上TOmcat的端口，（192.168.198.128：8080） ​ 如果一致，那么就可以不加Tomcat的端口因为Nginx服务器默认端口为80 （2）基于端口 12345678910111213141516171819202122232425http &#123; upstream shsxt&#123; server node01; server node02; &#125; upstream bjsxt&#123; server node03 &#125; server &#123; //当访问nginx的80端口时，将请求导给bjsxt组 listen 8080; server_name 192.168.198.128; location / &#123; proxy_pass http://bjsxt; &#125;&#125; server &#123; //当访问nginx的81端口时，将请求导给shsxt组 listen 81; server_name 192.168.198.128; //nginx服务器的IP location / &#123; proxy_pass http://shsxt; &#125; &#125; &#125; （3）基于IP ：（不常用） 二、正向代理和反向代理1、正向代理理解： 代理客户端，如通过VPN ，隐藏客户端，访问目标服务器（服务端可见） 举例： 国内不能直接访问谷歌，但是可以访问代理服务器，通过代理服务器可以访问谷歌。（就是翻墙） 但是，需要客户端必须设置正向代理服务器，并且要知道正向代理服务器的IP地址和端口 2、反向代理理解： 代理服务端，通过负载均衡服务器（如Nginx），隐藏服务端，分发客户端的不同请求（客户端可见）到内部网络上的服务器 举例： 如我们访问www.baidu.com的时候，它背后有很多台服务器，客户端并不知道具体是哪一台服务器给你提供的服务，只要知道反向代理服务器是谁就好了，反向代理服务器就会把我们的请求转发到真实服务器上。 Nginx就是性能很好的反向代理服务器，用来作负载均衡。 三、Nginx的session一致性问题1、背景：http协议是无状态的，多次访问如果是不同服务器响应请求，就会出现上次访问留下的session或cookie失效。这就引发了session共享的问题。 2、Session一致性解决方案（1）–session复制 tomcat 本身带有复制session的功能。 （2）-共享session 需要专门管理session的软件， memcached 缓存服务，可以和tomcat整合，帮助tomcat共享管理session。 3、安装memcachedmemcached （同redis一样）是基于内存的数据库 1、安装 yum –y install memcached 可以用telnet localhost 11211 启动： memcached -d -m 128m -p 11211 -l 192.168.235.113 -u root -P /tmp/ 2.web服务器连接memcached的jar包拷贝到tomcat的lib目录下 访问Tomcat服务器期间产生的session通过相关jar包，才能写入到memcached数据库中 memcached-session-manager-1.7.0.jar memcached-session-manager-tc7-1.8.1.jar 3.配置tomcat的conf目录下的context.xml 1234567&lt;Manager className=\"de.javakaffee.web.msm.MemcachedBackupSessionManager\" memcachedNodes=\"n1:192.168.198.128:11211\" sticky=\"true\" lockingMode=\"auto\" sessionBackupAsync=\"false\" requestUriIgnorePattern=\".*\\.(ico|png|gif|jpg|css|js)$\"sessionBackupTimeout=\"1000\" transcoderFactoryClass=\"de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory\" /&gt; 配置memcachedNodes属性， 配置memcached数据库的ip和端口，默认11211，多个的话用逗号隔开. 目的是为了让tomcat服务器从memcached缓存里面拿session或者是放session 将配置完成的context.xml发送到其他虚拟机器上 scp -r context.xml root@node01:pwd 或 scp -r context.xml node01:pwd 或 scp -r context.xml root@192.168.198.130:pwd 4.修改tomcat目录中webapps/ROOT下的 index.jsp，取sessionid看一看 12345678&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;html lang=\"en\"&gt;SessionID:&lt;%=session.getId()%&gt;&lt;/br&gt;SessionIP:&lt;%=request.getServerName()%&gt;&lt;/br&gt;&lt;h1&gt;tomcat1&lt;/h1&gt;&lt;/html&gt;","tags":[]},{"title":"","date":"2019-01-23T15:33:18.431Z","path":"2019/01/23/Linux系统CentOS 6安装/","text":"Linux系统CentOS 6一、安装 资源准备： CentOS-6.6-x86_64-minimal.iso（简易迷你版） ： CentOS-6.7-x86_64-bin-DVD1.iso（完整版）： 1、点击新建虚拟机 2、选择典型。（专业人士使用的话建议选择高级） 3. 选择稍后安装操作系统 4. 选择操作系统类型，选择linux,centos 64位 5. 选择虚拟机安装位置和名称。 6. 指定磁盘容量，默认20GB。 7. 选择自定义硬件 8. 点击CD/DVD,然后选择操作系统的ISO映像文件，选择完后，点击关闭。 9.点击完成。 二、配置虚拟机1. 启动虚拟机。注意：如果启动虚拟机时，发生以下问题，说明是你的电脑默认未开启虚拟化技术。 此时你应该把机器重启并进入bios界面（不同的机器进入bios界面的快捷键不同，一般为F1~F10键中的某个键，如果都不行，就得自己百度一下你的机器型号进入bios界面的快捷方式）。 ​ 当进入bios界面后，把虚拟机化选项（virtualization technology）打开,通过回车键，把disabled改成enabled,然后保存并重启机器。我这边是按F10，不同机器可能不一样，看右下角的提示信息。 2.Test Media, 如果不需要的话，点Skip 3、单击Next按钮继续 4. 选择安装期间显示的语言 5、选择键盘语言 6、选择存储介质的类别。如果是将CentOS 6安装到本地硬盘上，选择 Basic Storage Devices，如果安装到网络存储介质如SANs上，选择 Specialized Storage Devices 7.选择 yes,discard any data 8. 设定主机名称（hostname） 9. 设定时区，选择 Asia/Shanghai 10. 设定root帐户的密码尽量使用较复杂的密码安装（根据实际情况，密码简单时，会有提示，点击user anyway 就行） 11. 选择安装类型，这里我选择 “Use All Space” 12. 选择 “Write changes to disk”，将分区数据写入硬盘 13. 开始安装，此时只需等待即可 14. 安装完结后，点击Reboot按钮","tags":[]},{"title":"","date":"2019-01-23T15:33:18.407Z","path":"2019/01/23/Linux网络配置+常用命令学习(第一回合)/","text":"Linux网络配置+常用命令学习[TOC] 一、 Linux概述1.1. 简介Linux是一个自由的，免费的，源码开放的操作系统。也是开源软件中最著名的例子。其最主要的目的就是为了建立不受任何商品化软件版权制约的，全世界都能使用的类Unix兼容产品.而我们将服务器部署在Linux将会更加的稳定、安全、高效以及出色的性能这时windows无法比的。 1.2.Linux作者 林纳斯·本纳第克特·托瓦兹（Linus Benedict Torvalds, 1969年~ ），著名的电脑程序员、黑客。Linux内核的发明人及该计划的合作者。托瓦兹利用个人时间及器材创造出了这套当今全球最流行的操作系统（作业系统）内核之一。现受聘于开放源代码开发实验室（OSDL：Open Source Development Labs, Inc），全力开发Linux内核。 1.3.Linux 发行版发行版是基于 Linux 内核的一个操作系统。它带有用户可以使用的软件集合。更多的，它还包含系统管理包。目前有许多 Linux 发行版。因为我们不能数清目前所有的 Linux 发行版，所以我们来看一下一些有名的版本： Ubuntu、Fedora、Opensuse、Red hat Linux 和 Debian 等是几个非常受欢迎的 Linux 发行版。 C**entos** Ubuntu Rehat 1.4.Linux的特点开放性，多用户，多任务，丰富的网络功能，可靠的系统安全，良好的可移植性，具有标准兼容性 二、环境准备2.1. Vmware2.1.1 Vmware简介大多数服务器的容量（CPU,内存，磁盘等）利用率不足 30%，这不仅导致了资源浪费，也加大了服务器的数量。实现服务器虚拟化后，多个操作系统可以作为虚拟机在单台物理服务器上运行，并且每个操作系统都可以访问底层服务器的计算资源，从而解决效率低下问题。 Vmware虚拟机化技术由此诞生，它可以将一台服务器虚拟化出多台虚拟机，供多人同时使用，提高资源利用率。 2.1.2 Vmware workstation安装详细见vmware安装文档 2.2. linux安装详细见Linux安装文档 2.3.网络配置2.3.1 查看网关 2.3.2 配置静态IP(NAT模式)1.编辑配置文件,添加修改以下内容 vi /etc/sysconfig/network-scripts/ifcfg-eth0 按i 进入文本编辑模式，出现游标，左下角会出现INSERT,即可以编辑 应包含以下配置，除此之外的可以删除掉。 123456789101112131415DEVICE=eth0 #网卡设备名,请勿修改名字TYPE=Ethernet #网络类型，以太网BOOTPROTO=static #启用静态IP地址ONBOOT=yes #开启自动启用网络连接 IPADDR=192.168.78.100 #设置IP地址NETMASK=255.255.255.0 #设置子网掩码GATEWAY=192.168.78.2 #设置网关DNS1=114.114.114.114 #设置备DNS 按ESC退出编辑模式 :wq #保存退出 2.修改完后执行以下命令 service network restart #重启网络连接 ifconfig #查看IP地址 3.验证是否配置成功: 虚拟机能ping通虚拟网关 虚拟机与物理机（笔记本）相互可ping通 虚拟机与公网上的百度网址相互可ping通（此步ping通，才说明网络配置成功，Ctrl键+C停止） 命令：ping www.baidu.com 注意： a.保证VMware的虚拟网卡没有被禁用 b.网关IP不能被占用 2.4.XShell安装与使用2.4.1安装步骤除了安装路径需要修改，其他一直下一步。 2.4.2 连接虚拟机 打开xshell软件新建一个会话 填写所要连接的虚拟机IP，会话名称可改可不改，点击确定。 3.连接虚拟机。 4．输入root用户名，可以勾选”记住用户名” 5.填写密码，可以勾选“记住密码” 6.登录成功。 三、文件系统Linux文件系统中的文件是数据的集合，文件系统不仅包含着文件中的数据而且还有文件系统的结构，所有Linux 用户和程序看到的文件、目录、软连接及文件保护信息等都存储在其中。 Linux目录结构： bin 存放二进制可执行文件(ls,cat,mkdir等) boot 存放用于系统引导时使用的各种文件 dev 用于存放设备文件 etc 存放系统配置文件 home 存放所有用户文件的根目录 lib 存放跟文件系统中的程序运行所需要的共享库及内核模块 mnt 系统管理员安装临时文件系统的安装点 opt 额外安装的可选应用程序包所放置的位置 proc 虚拟文件系统，存放当前内存的映射 root 超级用户目录 sbin 存放二进制可执行文件，只有root才能访问 tmp 用于存放各种临时文件 usr 用于存放系统应用程序，比较重要的目录/usr/local 本地管理员软件安装目录 var 用于存放运行时需要改变数据的文件 3.1目录操作3.1.1**切换目录命令：cd + 目录的路径 查看当前目录的完整路径 ：pwd 命令 cd .. 返回到父目录 3.1.2**新建目录命令：mkdir+ 目录名字 查看当前目录下拥有的子目录和文件: ls 3.1.3 拷贝目录cp source dest -r 3.1.4删除目录rmdir directory 注意：rmdir只能删除空目录,若要删除非空目录则用rm命令 rm -rf dir 3.1.5移动/更改 目录​ 移动文件或目录：mv + 目录/文件名字 + 其他路径 ​ mv test / 将test目录移动到 根目录/ 下 ​ ​ 更改文件或目录的名字：mv + 旧目录名字 + 新目录名字。 ​ 3.2.文件操作3.2.1新建文件：（一切皆文件）touch web.log 创建一个空文件。 3.2.2 复制文​ cp web.log web_cp.log 复制文件，加个-r 参数，代表遍历复制，此时可用于复制一个目录。 3.2.3删除文件rm web_cp.log 此时需要手动输入y ，代表确认删除。可加 –f参数，直接删除，无需确认。当需要一个目录下所有东西时，加-r参数，代表遍历删除。 rm -f web.log 3.2.4**查看3.2.4.1**查看目录下的东西​ ls / ll 命令 ls -l 等价于 ll 查看目录下的所有东西（包括隐藏文件） 命令：ls –al 等价于 ll –a 3.2.4.2查看文件内容cat filename: 一次性显示整个文件的内容 注意：当文件较大时，文本在屏幕上迅速闪过（滚屏），用户往往看不清所显示的内容。 因此，一般用more等命令分屏显示. more filename 该命令一次显示一屏文本，满屏后停下来，并且在屏幕的底部出现一个提示信息，给出至今己显示的该文件的百分比。 按Space键，显示文本的下一屏内容。按Enter键，只显示文本的下一行内容。 按B键，显示上一屏内容。 按Q键，退出。 命令：more /etc/profile 显示的内容： ​ less命令 与 more命令 非常类似 less filename: ​ h 显示帮助界面 Q 退出less 命令 u 向后滚动半页 d 向前翻半页 空格键 滚动一页 b 向后翻一页 回车键 滚动一行 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 以及上下键，向上一行，向下一行 3.2.4.3从头打印**文件内容​ head -10 filename 打印文件1到10行 3.2.4.4从尾部打印文件内容 tail -10 filename 打印文件最后10行 注意：tail 还经常可以拿来查看文件的内容变化 加-f参数，tail –f filename 3.2.5查找文件或目录​ find pathname –name filename ​ 例子：find / -name profile ​ 该命令表示为，在/目录下查找 名字为profile的文件或目录，最后列出它的绝对路径 ​ ​ 最后发现，linux系统根目录/ 下 一共有两个名字为profile， ​ 其中/etc/profile是一个文件，/etc/lvm/profile为目录 还可以按正则表达式来查找，且pathname越精确，查找的范围越小，速度越快。 ​ find /etc -name pro* 注意：（命令执行时，其查找的目录必须是所在目录的父级目录） ​ 该命令表示为：在/etc目录下查找以pro开头的文件或目录。 四、文本编辑4.1.vi编辑模式 vi filename :打开或新建文件，并将光标置于第一行首 vi +n filename ：打开文件，并将光标置于第n行首 vi + filename ：打开文件，并将光标置于最后一行首 vi +/pattern filename：打开文件，并将光标置于第一个与 pattern匹配的串处 • q!：不保存文件并退出vi – 在VI的命令模式下输入“:set nu”，就有行号了。 – 在VI的命令模式下输入“:set nonu”，取消行号。 一般模式 • yy 复制光标所在行(常用) • nyy 复制光标所在行的向下n行，例如， 20yy则是复制20行(常用) （不同：在我的xshell中是 yyn实现复制所在行的向下n行） • p,P p为复制的数据粘贴在光标下一行， P则为粘贴在光标上一行(常用) G:光标移至第最后一行 nG：光标移动至第N行行首 n（shift）+：光标下移n行 （nB|nb:光标向上移动n行） n-：光标上移n行 H ：光标移至屏幕顶行 M ：光标移至屏幕中间行 L ：光标移至屏幕最后行 • dd：删除 行 x或X：删除一个字符，x删除光标后的，而X删除光标前的 • u 恢复前一个动作(常用) 删除第N行到第M行： :N,Md 4.2.vimVim是从 vi 发展出来的一个文本编辑器。代码补完、语法高亮、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用. 安装vim 软件 yum install vim 按y确认, 这中间一共要按两次确认 可以在书写命令时就加y,这样就不用逐一确认。 yum install vim -y 用vim 打开/etc/profile 文件，会发现编辑器对文本的内容进行了高亮，使整个文件的内容可读性大大加强 命令：vim /etc/profile 五、文件传输5.1.远程拷贝5.1.1将本地文件复制到远程机器 举例： 123456789101112&gt; 方式一：&gt; scp -rf /etc/profile root@192.168.198.128:/etc/&gt; &gt; 方式二:&gt; scp -r /etc/profile root@node01 /etc/ &gt; &gt; 方式三：&gt; scp -r /etc/profile node01:/etc/&gt; &gt; 方式四：&gt; scp -r /ec/profile node01:&apos;pwd&apos;&gt; scp ：远程传输文件命令 -r ：- 指的是后面跟的是参数 r 指的是遍历指定文件 f 指的是不用询问 /etc/profile : 是指定传输的文件 root： 远程机器的账户名 @ 远程机器的IP地址 ： /etc/ 远程机器上指定的目录 node01：远程机器的别名 ‘pwd’： 本地要远程传输文件所在的目录 scp local_file remote_username@remote_ip:remote_folder 第一次远程拷贝时，需要在箭头1初输入yes确认一下，验证一下远程主机。然后在箭头2处输入一下远程主机的密码。 5.1.2将本地目录复制到远程机器scp -r local_folder remote_username@remote_ip:remote_folder 在test目录下创建一个myfile文件，然后将test目录远程拷贝到192虚拟机的根目录下。 5.2.上传​ 需先安装好lrzsz : yum install lrzsz -y 安装好后，输入上传的命令rz,弹出一下界面： 选择一个windows系统里的文件上传至虚拟机的当前目录下,然后ll命令，查看结果 5.3.下载 下载命令为sz，sz命令只能下载文件，不能是目录，可先将目录压缩成一个包，再下载至windows系统。下载完之后，按ctrl+c结束。 5.4 Xftp的安装与使用​ 除了可以用rz sz命令进行本地windows系统和虚拟机之间的文件传输，还可以使用XFTP软件。 六、网络指令6.1.查看网络配置信息命令:ifconfig 箭头1指向的是本机IP，箭头2为广播地址，箭头3位子网掩码。 6.2.测试与目标主机的连通性命令：ping remote_ip（可以ping通Windows系统的IP） 输入ping 192.168.78.192代表测试本机和192主机的网络情况， 箭头1表示一共接收到了3个包，箭头2表示丢包率为0，表示两者之间的网络顺畅。 注意：linux系统的ping命令会一直发送数据包，进行测试，除非认为的按ctrl + c停止掉， ​ windows系统默认只会发4个包进行测试，以下为windows的dos命令。 6.3.显示各种网络相关信息​ 命令：netstat –a n p t -a (all)显示所有选项，默认不显示LISTEN相关-t (tcp)仅显示tcp相关选项-u (udp)仅显示udp相关选项-n 拒绝显示别名，能显示数字的全部转化成数字。-l 仅列出有在 Listen (监听) 的服務状态 -p 显示建立相关链接的程序名-r 显示路由信息，路由表-e 显示扩展信息，例如uid等-s 按各个协议进行统计-c 每隔一个固定时间，执行该netstat命令。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到 七、系统配置7.1 主机名配置 若要修改主机名字，可在/etc/sysconfig/network文件里修改. vim /etc/sysconfig/network ​ 机器重启才能生效 7.2 DNS配置 /etc/resolv.conf 为DNS服务器的地址文件 7.3 环境变量Linux系统的环境变量是在/etc/profile文件里配置。 首先考虑一个问题，为什么我们先前敲的yum, service,date,useradd等等，可以直接使用，系统怎么知道这些命令对应的程序是放在哪里的呢？ 这是由于无论是windows系统还是linux系统，都有一个叫做path的系统环境变量，当我们在敲命令时，系统会到path对应的目录下寻找，找到的话就会执行，找不到就会报没有这个命令。如下图： 我们可以查看一下，系统一共在哪些目录里寻找命令对应的程序。 命令：echo $PATH 可以看到path里有很多路径，路径之间有冒号隔开。当用户敲命令时，系统会从左往右依次寻找对应的程序，有的话则运行该程序，没有的就报错，command not found. 那如果我写了一个脚本（脚本后面会专门讲），我该怎样运行它呢？ 对test.sh添加可执行权限，chmod 700 test.sh 运行方法有三种： 一种是到脚本的目录下执行： 运行命令 ： ./test.sh ,代表执行当前目录里的脚本test.sh 一种是敲脚本的绝对路径：/usr/test/test.sh 以上两种运行方式都不是很简便，因为先前我们执行yum service命令等，都是直接敲对应的命令的。所以我们也可以参照这样子做，只要我们配一个环境变量就好。 编辑： vim /etc/profile 将test.sh所在目录添加到PATH里就OK，我这里test.sh是在/usr/test目录（通过pwd查看）下。 编辑完之后，执行source /etc/profile命令，重新加载环境变量，此时会发现PATH路径多了一个/usr/test。 ​ 最后验证一下，直接执行test.sh ​ 八、服务操作8.1 列出所有服务命令：chkconfig 查询操作系统在每一个执行等级中会执行哪些系统服务，其中包括各类常驻服务。 各数字代表的系统初始化级别含义： ​ 0：停机状态 1：单用户模式，root账户进行操作 2：多用户，不能使用net file system，一般很少用 3：完全多用户，一部分启动，一部分不启动，命令行界面 4：未使用、未定义的保留模式 5：图形化，3级别中启动的进程都启动，并且会启动一部分图形界面进程。 6：停止所有进程，卸载文件系统，重新启动(reboot) 这些级别中1、2、4很少用，相对而言0、3、5、6用的会较多。3级别和5级别除了桌面相关的进程外没有什么区别。为了减少资源占用，推荐都用3级别. 注意 ：linux默认级别为3，不要把/etc/inittab 中initdefault 设置为0 和 6 8.2 服务操作service 服务名 start/stop/status/restart 例子：对防火墙服务进行操作，防火墙的服务名为：iptables. ​ 查看防火墙服务运行状态。 关闭防火墙. 开启防火墙 8.3 关闭防火墙service iptables start/stop/status 注：学习期间直接把防火墙关掉就是，工作期间也是运维人员来负责防火墙的。 永久开启/关闭防火墙 chkconfig iptables on/off 8.4 服务初执行等级更改chkconfig –level 2345 name off|on ​ （服务名） 若不加级别，默认是2345级别 命令：chkconfig name on|off ​ （服务名） 九、linux进程操作9.1 查看所有进程命令： ps -aux ​ -a 列出所有 ​ -u 列出用户 ​ -x 详细列出，如cpu、内存等 e ​ -f 命令： ps - ef | grep ssh 查看所有进程里CMD是ssh 的进程信息。 其中箭头所指的是sshd服务进程的进程号（PID） 9.2 杀死进程Kill 用法 kill pid -9：强制杀死 ps 命令先查出对应程序的PID或PPID ，然后杀死掉进程。 十、 其他常用命令10.1 yumyum是一个在Fedora和RedHat以及CentOS中的Shell前端软件包管理器。基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装。 由于centos系统的yum默认是到国外网站下载，有时下载速度会很慢，故我们可以换一个yum的下载源，这里我们换一个国内的下载源 阿里云镜像。 第一步：备份你的原镜像文件，以免出错后可以恢复。 cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 第二步：下载新的CentOS-Base.rep到/etc/yum.repos.d/ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo 下载完之后，vim /etc/yum.repos.d/CentOS-Base.repo 查看一下文件内容。 第三步：运行yum makecache生成缓存 查看当前源 yum list | head -50 10.2 wgetwget 是一个从网络上自动下载文件的自由工具，支持通过 HTTP、HTTPS、FTP 三个最常见的 TCP/IP协议 下载，并可以使用 HTTP 代理 需先安装 yum install wget –y wget用法:wget [option] 网址 -O 指定下载保存的路径 wget 工具还可以用来做一些简单的爬虫，这里不是我们的学习重点，如果想做爬虫，可以用java或python语言来做。 10.3 tartar ​ -z gzip进行解压或压缩，带.gz需要加，压缩出来.gz也需要加 ​ -x 解压 ​ -c 压缩 ​ -f 目标文件，压缩文件新命名或解压文件名 ​ -v 解压缩过程信息打印 解压命令：tar -zvxf xxxx.tar.gz 例子：先用rz命令或wscp上传一个tar包，然后解压。 解压后： 压缩命令：tar -zcf 压缩包命名 压缩目标 例子：tar -zcf tomcat.tar.gz apache-tomcat-7.0.61 将 apache-tomcat-7.0.61 目录压缩成tomcat.tar.gz包。 十一、JDK部署11.1 官网下载http://www.oracle.com/technetwork/java/javase/downloads/index.html 11.2 上传并解压用xftp将jdk包上传到linux系统里，我这里上传到/usr/soft目录下。 然后解压: tar -zxf jdk-7u80-linux-x64.tar.gz 11.3配置环境变量配置全局JAVA_HOME，并在PATH路径里加入java_home/bin. 注意：新的path路径必须要包含旧的PATH路径，且每个路径之间以冒号隔开，而不是分号 vim /etc/profile JAVA_HOME= /usr/soft/jdk1.7.0_75 PATH=$PATH:$JAVA_HOME/bin 重新加载环境变量：source /etc/profile 11.4 验证java -version 如出现上图，则表示java环境变量配置成功。 十二、部署Tomcat12.1 官网下载下载tomcat http://tomcat.apache.org/ 12**.2 上传并解压**我这里上传至/usr/soft目录下，然后解压。 12.3 启动tomcat在tomcat的bin目录下有个startup.sh 脚本可以直接启动tomcat服务 关闭tomcat服务，可以用shutdown.sh命令。 或者ps -ef | grep tomcat 查看出tomcat进程号后，用kill命令。 12.4 jpsjps是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。 如上图所示，jps命令显示出了，系统当前运行在jvm上的进程情况。其中Bootstrap是tomcat的进程名字，1996是tomcat的PID 13.5验证先把防火墙关了（service iptables stop），然后访问虚拟机IP的8080端口","tags":[]},{"title":"","date":"2019-01-23T15:33:18.403Z","path":"2019/01/23/Linux 入门学习（第二回合）/","text":"Linux 入门学习（第二回合）2018年12月18日 周二 晴 今日学习要点： [TOC] Linux后半程一、Linux系统配置1.主机名配置： vim /etc/sysconfig/network 配置完成之后需要重启机器才能生效 reboot 2.DNS配置 查看DNS服务器的地址cat /etc/resolv.conf 修改DNS服务器地址方式一：vim /etc/sysconfig/network.scripts/ifconfig-eth0 ​ 在配置网关时，配置DNS1=114.114.114.114（不推荐，江苏南京的IP） 方式二：vim /etc/resolv.conf （用本地网关解析） ​ nameserver 192.168.198.0 ( 此为虚拟机中的网关地址) 3.环境变量 配置系统环境变量，使得某些命令在执行时，系统可以找到命令对应的执行程序，命令才能正常执行。 查看系统一共在哪些目录里寻找命令对应的程序 命令：echo $PATH 注意：路径之间有冒号隔开，系统会从左往右依次寻找对应的程序 ​ 一般命令会存放在 bin目录，或sbin目录 配置全局环境变量： vim /etc/profile 在文件中： PATH=$PATH:(命令所在目录) 退出文件编辑后： source /etc/profile (重新加载资源，有的可能需要重启机器，这不适用于实际状况) 配置局部环境变量：（推荐，限当前登录用户使用） 查看所有文件(root目录下) ls -a (发现隐藏文件 .bash.profile) vim ~/ bash_profile 在文件中： export PATH =$PATH:(命令所在目录) 4.拍快照（保存当时计算机所出状态的各种配置和资源，适度使用） 选中指定虚拟计算机——鼠标右击—–选中“快照” ——“拍摄快照‘—-在页面中找到”拍摄快照“，并添加名称和描述 也可以删除，找到页面中的删除按钮 二、服务操作1、查询操作系统在每一个执行等级中会执行哪些系统服务，其中包括各类常驻服务。 命令：chkconfig 12345678各数字代表的系统初始化级别： 0：停机状态 1：单用户模式，root账户进行操作 2：多用户，不能使用net file system，一般很少用 3：完全多用户，一部分启动，一部分不启动，命令行界面 4：未使用、未定义的保留模式 5：图形化，3级别中启动的进程都启动，并且会启动一部分图形界面进程。 6：停止所有进程，卸载文件系统，重新启动(reboot) 1、2、4很少用，0、3、5、6常用，3级别和5级别除了桌面相关的进程外没有什么区别，推荐都用3级别； linux默认级别为3； 不要把 /etc/inittab 中 initdefault 设置为0 和 6； 2、服务操作 service 服务名 start/stop/status/restart 举例：对防火墙服务进行操作 防火墙的服务名为：iptables 查看防火墙服务运行状态 service iptables status 关闭防火墙 service iptables stop 开启防火墙 service iptables start 永久开启/关闭防火墙 chkconfig iptables on/off 3、服务初执行等级更改 chkconfig –level 2345 name off|on​ （ 服务名） 举例：防火墙 chkconfig –level 2345 iptables off 若不加级别，默认是2345级别 命令：chkconfig name on|off​ （服务名） 三、linux进程操作1、查看所有进程 命令： ps -aux 12345 -a 列出所有-u 列出用户-x 详细列出，如cpu、内存等 -e select all processes 相当于-a -f does full-format listing 将所有格式详细列出来 查看所有进程里CMD是ssh 的进程信息（包括pid 进程号） 命令： ps - ef | grep ssh （| 管道符 ：前一个输出，变为后一个的输入） 举例： ps -ef | grep redis 2、杀死进程kill 命令：kill pid -9 强制杀死 用法：用ps 命令先查出对应程序的PID或PPID ，然后用kill杀死掉进程。 四、其他常用命令1、yum 基于RPM包管理 能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装 跟换yum下载源（默认是到国外网站下载） 第一步：备份你的原镜像文件，以免出错后可以恢复 cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 第二步：下载新的CentOS-Base.rep到/etc/yum.repos.d/ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo 下载完之后，查看一下文件内容 vim /etc/yum.repos.d/CentOS-Base.repo 第三步：生成缓存 运行yum makecache 查看当前源 yum list | head -50 2、 wget 一个从网络上自动下载文件的自由工具 支持通过 HTTP、HTTPS、FTP 三个最常见的 TCP/IP协议，可以使用 HTTP 代理 安装： yum install wget –y 用法： wget [option] 网址 -O 指定下载保存的路径 举例： wget www.baidu.com -O baidu.html 3、tar12345 -z gzip进行解压或压缩，带.gz需要加，压缩出来.gz也需要加-x 解压-c 压缩-f 目标文件，压缩文件新命名或解压文件名-v 解压缩过程信息打印 解压命令：tar -zvxf xxxx.tar.gz 压缩命令：tar -zcf 压缩包命名 压缩目标举例： tar -zcf tomcat.tar.gz apache-tomcat-7.0.61将 apache-tomcat-7.0.61 目录压缩成tomcat.tar.gz包 4、man作用：用于查看指定命令的具体解释 安装 yum install man -y (下载并安装man 并确认) 使用 man ps 五、JDK部署1、准备JDK安装包：（这是使用 .rpm 格式的安装包） 官网下载：http://www.oracle.com/technetwork/java/javase/downloads/index.html 云盘资源： jdk-8u191-linux-x64.rpm ： ​ 根据用户喜好放到虚拟机器的文件目录中 2、解压并安装，展示编译过程 rpm -ivh jdk-8u191-linux-x64.rpm 安装放到了 /usr 目录下，有/java目录 3、配置环境变量 vim ~/.bash_profile 在文件中： JAVA_HOME=(jdk文件所在的路径+jdk文件名) export PATH=$PATH:$JAVA_HOME/bin 注意： 新的path路径必须要包含旧的PATH路径，且每个路径之间以冒号隔开，而不是分号 配置完成，退出编辑框后 source ~/.hash_profile 4、测试： java -version 或 echo $JAVA_HOME echo 标准输出，打印 六、Tomcat部署1、官网下载http://tomcat.apache.org/ 云盘资源：apache-tomcat-7.0.61.tar 2、上传并解压 tar -zvxf apache-tomcat-7.0.61.tar 3、启动tomcat在tomcat的bin目录下有个startup.sh 脚本可以直接启动tomcat服务 ./startup.sh 4、关闭tomcat服务方式一：可以用shutdown.sh命令 方式二：ps -ef | grep tomcat 查看出tomcat进程号后，用kill命令 5、验证先把防火墙关了（service iptables stop），然后访问虚拟机IP的8080端口","tags":[]},{"title":"Flume学习","date":"2019-01-17T16:00:00.000Z","path":"2019/01/18/Flume学习/","text":"[TOC] 一、分类exec： Unix等操作系统执行命令行，如tail ，cat 。可监听文件 netcat 监听一个指定端口，并将接收到的数据的每一行转换为一个event事件 avro 序列化的一种，实现RPC（一种远程过程调用协议）。 监听AVRO端口来接收外部AVRO客户端事件流 capacity：默认该通道中最大的可以存储的event数量是1000 Trasaction Capacity：每次最大可以source中拿到或者送到sink中的event数量也是100 二、操作1、 netcat（监听端口，在本地控制台打印）（1） vim netcat_logger1234567891011121314151617181920212223# example.conf: A single-node Flume configuration# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 （2）命令操作 （在会话1端） 在node00节点的控制台输入启动命令： (方式一：指定配置文件的路径+文件名) flume-ng agent –conf-file /root/flume/netcat_logger –name a1 -Dflume.root.logger=INFO,console （方式二：配置文件在当前目录） flume-ng agent –conf ./ –conf-file netcat_logger –name a1 -Dflume.root.logger=INFO,console 特别注意： #####官网方式######### flume-ng agent –conf conf –conf-file netcat_logger –name a1 -Dflume.root.logger=INFO,console 解释：此命令适用于将配置文件放在flume解压安装目录的conf中（不常用） 控制台显示: 1​````` 19/01/18 12:27:31 INFO instrumentation.MonitoredCounterGroup: Component type: CHANNEL, name: c1 started19/01/18 12:27:31 INFO node.Application: Starting Sink k119/01/18 12:27:31 INFO node.Application: Starting Source r119/01/18 12:27:31 INFO source.NetcatSource: Source starting19/01/18 12:27:31 INFO source.NetcatSource: Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/127.0.0.1:44444]123456789101112131415161718* (在会话2端)&gt; 在node00节点的控制台输入命令：&gt;&gt; 1、在节点上安装telnet：&gt;&gt; yum install -y telnet&gt;&gt; yum -y install telnet-server&gt;&gt; 2、启动：&gt;&gt; telnet localhost 44444 &gt;&gt; `注意：`：&gt;&gt; a1.sources.r1.bind = localhost12345678910&gt;&gt; 前提是/etc/hosts中已经配置&gt;&gt; 如果此处配置localhost 那么启动时，localhost 或127.0.0.1都可以，node00就不行&gt;&gt; 如果此处配置node00那么启动时，node00或ip都可以，localhost就不行&gt;&gt; 3、在控制台输入任何内容;&gt;&gt; 都会在会话1端显示，且会话1端（ctrl+c）退出服务，会话2端也自动结束 yum list telnet* 查看telnet相关的安装包 直接yum –y install telnet 就OK yum -y install telnet-server 安装telnet服务 yum -y install telnet-client 安装telnet客户端(大部分系统默认安装) 1234### 2、avro（监听远程发送文件，在本地控制台打印）#### （1）vim avro_logger #test avro sources ##使用avro方式在某节点上将文件发送到本服务器上且通过logger方式显示 ##当前flume节点执行： #flume-ng agent –conf ./ –conf-file avro_loggers –name a1 -Dflume.root.logger=INFO,console ##其他flume节点执行： #flume-ng avro-client –conf ./ -H 192.168.198.128 -p 55555 -F ./logs a1.sources=r1a1.channels=c1a1.sinks=k1 a1.sources.r1.type = avroa1.sources.r1.bind=192.168.198.128a1.sources.r1.port=55555 a1.sinks.k1.type=logger a1.channels.c1.type = memorya1.channels.c1.capacity=1000a1.channels.c1.transactionCapacity = 100 a1.sources.r1.channels=c1a1.sinks.k1.channel=c1123456789101112131415161718实现功能：&gt; 使用avro方式在某节点上将文件发送到本服务器上且通过logger方式显示#### （2）命令操作##### `启动` （在会话1端）在node00上* ##当前flume节点执行（配置文件在当前目录）：* &gt; flume-ng agent --conf ./ --conf-file avro_logger --name a1 -Dflume.root.logger=INFO,console`显示：` 19/01/18 13:53:16 INFO instrumentation.MonitoredCounterGroup: Component type: CHANNEL, name: c1 started19/01/18 13:53:16 INFO node.Application: Starting Sink k119/01/18 13:53:16 INFO node.Application: Starting Source r119/01/18 13:53:16 INFO source.AvroSource: Starting Avro source r1: { bindAddress: 192.168.198.128, port: 55555 }…19/01/18 13:53:17 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: SOURCE, name: r1: Successfully registered new MBean.19/01/18 13:53:17 INFO instrumentation.MonitoredCounterGroup: Component type: SOURCE, name: r1 started19/01/18 13:53:17 INFO source.AvroSource: Avro source r1 started. 1234567891011121314##### 发送(在会话2端)在node00上发送文件到node00`启动`* ##可在本地和其他flume节点执行（配置文件在当前目录）：* &gt; flume-ng avro-client --conf ./ -H 192.168.198.128 -p 55555 -F ./flume.log(在会话1端) 19/01/18 14:12:57 INFO sink.LoggerSink: Event: { headers:{} body: 68 65 6C 6C 6F 20 62 69 67 64 61 74 61 hello bigdata }12345678910时刻监听传输文件的内容`注意`&gt; 该过程也可应用于不同节点之间### 3、exec（监听某一命令，在本地控制台打印）#### （1）vim exec_logger #单节点flume配置 example.conf: A single-node Flume configuration#给agent三大结构命名 Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1 #描述source的配置：类型、命令（监听/root/flume.log文件） Describe/configure the sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F /root/flume.log #描述sink的配置：类型 Describe the sinka1.sinks.k1.type = logger #在内存中使用一个channel缓存事件 Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 #将source和sink绑定到channel上 Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 1234567891011121314151617181920212223242526（xshell会话1：）&gt; 在node00上：`启动`&gt;&gt; 在exec_logger文件所在的目录下&gt;&gt; 命令：flume-ng agent --conf-file exec_logger --name a1 -Dflume.root.logger=INFO,console&gt;&gt; r1 启动&gt; （复制会话：会话2）&gt;&gt; 在node00上：&gt;&gt; 在root目录下&gt;&gt; 命令：echo hello bigdata &gt;&gt;flume.log&gt; 之后在会话2上&gt;&gt; `logger本地控制台打印：`&gt;&gt; 19/01/18 12:03:23 INFO sink.LoggerSink:Event:{ headers:{} body: 68 65 6C 6C 6F 20 62 69 67 64 61 74 61 hello bigdata }123456### 4、netcat–hdfs(监听数据，传到hdfs上)#### （1）vim netcat_hdfs a1 which ones we want to activate.a1.channels = c1a1.sources = r1a1.sinks = k1 a1.sources.r1.type = netcata1.sources.r1.bind = node00a1.sources.r1.port = 41414 a1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = hdfs://Sunrise/myflume/%y-%m-%da1.sinks.k1.hdfs.useLocalTimeStamp=true Define a memory channel called c1 on a1a1.channels.c1.type = memory #默认值，可省 #a1.channels.c1.capacity = 1000 #a1.channels.c1.transactionCapacity = 100 Define an Avro source called r1 on a1 and tell ita1.sources.r1.channels = c1a1.sinks.k1.channel = c112345678910111213141516#### (2)操作在node00的会话1上启动&gt; 在node00上：&gt;&gt; 在netcat_hdfs文件所在的目录下&gt;&gt; 命令：flume-ng agent --conf-file netcat_hdfs --name a1 -Dflume.root.logger=INFO,console显示： 19/01/18 14:34:44 INFO instrumentation.MonitoredCounterGroup: Component type: CHANNEL, name: c1 started19/01/18 14:34:44 INFO node.Application: Starting Sink k119/01/18 14:34:44 INFO node.Application: Starting Source r119/01/18 14:34:44 INFO source.NetcatSource: Source starting19/01/18 14:34:44 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: SINK, name: k1: Successfully registered new MBean.19/01/18 14:34:44 INFO instrumentation.MonitoredCounterGroup: Component type: SINK, name: k1 started19/01/18 14:34:44 INFO source.NetcatSource: Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/192.168.198.128:41414] 12345678910在node00的会话2上启动&gt; telnet node00 41414显示 Trying 192.168.198.128…Connected to node00.Escape character is ‘^]’. 1234输入任意内容在node00会话1端会显示 19/01/18 14:36:50 INFO hdfs.HDFSSequenceFile: writeFormat = Writable, UseRawLocalFileSystem = false19/01/18 14:36:51 INFO hdfs.BucketWriter: Creating hdfs://Sunrise/myflume/19-01-18/FlumeData.1547822210259.tmp19/01/18 14:37:29 INFO hdfs.BucketWriter: Closing hdfs://Sunrise/myflume/19-01-18/FlumeData.1547822210259.tmp19/01/18 14:37:29 INFO hdfs.BucketWriter: Renaming hdfs://Sunrise/myflume/19-01-18/FlumeData.1547822210259.tmp to hdfs://Sunrise/myflume/19-01-18/FlumeData.154782221025919/01/18 14:37:29 INFO hdfs.HDFSEventSink: Writer callback called. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758在HDF分布式系统上会显示，生成的文件![](https://ws1.sinaimg.cn/large/005zftzDgy1fzb4acaz5fj30u10blmzc.jpg)![](https://ws1.sinaimg.cn/large/005zftzDgy1fzb4bsv8d2j30wd08k74i.jpg)`注意：`这种情况会在hdfs上生成很多小文件，[在官网](http://flume.apache.org/releases/content/1.8.0/FlumeUserGuide.html)#### HDFS Sink[¶](http://flume.apache.org/releases/content/1.8.0/FlumeUserGuide.html#hdfs-sink)有很多关于文件生成过程中的配置| Name | Default | Description || ---------------------- | ------------ | ------------------------------------------------------------ || **channel** | – | || **type** | – | The component type name, needs to be `hdfs` || **hdfs.path** | – | HDFS directory path (eg hdfs://namenode/flume/webdata/) || hdfs.filePrefix | FlumeData | Name prefixed to files created by Flume in hdfs directory || hdfs.fileSuffix | – | Suffix to append to file (eg `.avro` - *NOTE: period is not automatically added*) || hdfs.inUsePrefix | – | Prefix that is used for temporal files that flume actively writes into || hdfs.inUseSuffix | `.tmp` | Suffix that is used for temporal files that flume actively writes into || hdfs.rollInterval | 30 | Number of seconds to wait before rolling current file (0 = never roll based on time interval) || hdfs.rollSize | 1024 | File size to trigger roll, in bytes (0: never roll based on file size) || hdfs.rollCount | 10 | Number of events written to file before it rolled (0 = never roll based on number of events) || hdfs.idleTimeout | 0 | Timeout after which inactive files get closed (0 = disable automatic closing of idle files) || hdfs.batchSize | 100 | number of events written to file before it is flushed to HDFS || hdfs.codeC | – | Compression codec. one of following : gzip, bzip2, lzo, lzop, snappy || hdfs.fileType | SequenceFile | File format: currently `SequenceFile`, `DataStream` or `CompressedStream` (1)DataStream will not compress output file and please don’t set codeC (2)CompressedStream requires set hdfs.codeC with an available codeC || hdfs.maxOpenFiles | 5000 | Allow only this number of open files. If this number is exceeded, the oldest file is closed. || hdfs.minBlockReplicas | – | Specify minimum number of replicas per HDFS block. If not specified, it comes from the default Hadoop config in the classpath. || hdfs.writeFormat | Writable | Format for sequence file records. One of `Text` or `Writable`. Set to `Text` before creating data files with Flume, otherwise those files cannot be read by either Apache Impala (incubating) or Apache Hive. || hdfs.callTimeout | 10000 | Number of milliseconds allowed for HDFS operations, such as open, write, flush, close. This number should be increased if many HDFS timeout operations are occurring. || hdfs.threadsPoolSize | 10 | Number of threads per HDFS sink for HDFS IO ops (open, write, etc.) || hdfs.rollTimerPoolSize | 1 | Number of threads per HDFS sink for scheduling timed file rolling || hdfs.kerberosPrincipal | – | Kerberos user principal for accessing secure HDFS || hdfs.kerberosKeytab | – | Kerberos keytab for accessing secure HDFS || hdfs.proxyUser | | || hdfs.round | false | Should the timestamp be rounded down (if true, affects all time based escape sequences except %t) || hdfs.roundValue | 1 | Rounded down to the highest multiple of this (in the unit configured using `hdfs.roundUnit`), less than current time. || hdfs.roundUnit | second | The unit of the round down value - `second`, `minute` or `hour`. || hdfs.timeZone | Local Time | Name of the timezone that should be used for resolving the directory path, e.g. America/Los_Angeles. || hdfs.useLocalTimeStamp | false | Use the local time (instead of the timestamp from the event header) while replacing the escape sequences. || hdfs.closeTries | 0 | Number of times the sink must try renaming a file, after initiating a close attempt. If set to 1, this sink will not re-try a failed rename (due to, for example, NameNode or DataNode failure), and may leave the file in an open state with a .tmp extension. If set to 0, the sink will try to rename the file until the file is eventually renamed (there is no limit on the number of times it would try). The file may still remain open if the close call fails but the data will be intact and in this case, the file will be closed only after a Flume restart. || hdfs.retryInterval | 180 | Time in seconds between consecutive attempts to close a file. Each close call costs multiple RPC round-trips to the Namenode, so setting this too low can cause a lot of load on the name node. If set to 0 or less, the sink will not attempt to close the file if the first attempt fails, and may leave the file open or with a ”.tmp” extension. || serializer | `TEXT` | Other possible options include `avro_event` or the fully-qualified class name of an implementation of the `EventSerializer.Builder` interface. |netcat-hdfs （配置方式二） a1 which ones we want to activate.a1.channels = c1a1.sources = r1a1.sinks = k1 a1.sources.r1.type = avroa1.sources.r1.bind=node01a1.sources.r1.port=55555 a1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = hdfs://shsxt/hdfsflume Define a memory channel called c1 on a1a1.channels.c1.type = memorya1.channels.c1.capacity=1000a1.channels.c1.transactionCapacity = 100 Define an Avro source called r1 on a1 and tell ita1.sources.r1.channels = c1a1.sinks.k1.channel = c1123456### 5、结合版（netcat-avro）#### （1）vim netcat2_logger（node00） example.conf: A single-node Flume configuration#flume-ng agent –conf ./ –conf-file netcat2_logger –name a1 -Dflume.root.logger=INFO,console #flume-ng –conf conf –conf-file /root/flume_test/netcat_hdfs -n a1 -Dflume.root.logger=INFO,console #telnet 192.168.235.15 44444 Name the components on this agent a1.sources = r1 a1.sinks = k1 a1.channels = c1 Describe/configure the source a1.sources.r1.type = netcat a1.sources.r1.bind = node00 a1.sources.r1.port = 44444 Describe the sink a1.sinks.k1.type = avro a1.sinks.k1.hostname = node01 a1.sinks.k1.port = 60000 Use a channel which buffers events in memory a1.channels.c1.type = memory a1.channels.c1.capacity = 1000 a1.channels.c1.transactionCapacity = 100 Bind the source and sink to the channel a1.sources.r1.channels = c1 a1.sinks.k1.channel = c1 #————————— #flume-ng agent –conf-file etect2_logger –name a1 -#Dflume.root.logger=INFO,console #flume-ng agent –conf conf –conf-file netcat_logger –name a1 -#Dflume.root.logger=INFO,console12（node01） #flume-ng agent –conf ./ –conf-file avro2 -n a1a1.sources = r1a1.sinks = k1a1.channels = c1 a1.sources.r1.type = avroa1.sources.r1.bind = node01a1.sources.r1.port = 60000 a1.sinks.k1.type = logger Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 1234567891011121314(2)操作&gt; 先启动后面的flume节点node01 ，在启动node00，最后启动node02在node01上`启动`&gt; flume-ng &gt;&gt; --conf conf --conf-file avro2 -n a1 -Dflume.root.logger=INFO,console显示 19/01/18 23:22:27 INFO node.Application: Starting Channel c119/01/18 23:22:28 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: CHANNEL, name: c1: Successfully registered new MBean.19/01/18 23:22:28 INFO instrumentation.MonitoredCounterGroup: Component type: CHANNEL, name: c1 started19/01/18 23:22:28 INFO node.Application: Starting Sink k119/01/18 23:22:28 INFO node.Application: Starting Source r119/01/18 23:22:28 INFO source.AvroSource: Starting Avro source r1: { bindAddress: node01, port: 60000 }…19/01/18 23:22:30 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: SOURCE, name: r1: Successfully registered new MBean.19/01/18 23:22:30 INFO instrumentation.MonitoredCounterGroup: Component type: SOURCE, name: r1 started19/01/18 23:22:30 INFO source.AvroSource: Avro source r1 started. 1234567891011121314151617181920212223242526在node00上`启动`&gt; flume-ng agent&gt;&gt; --conf ./ --conf-file netcat2_logger --name a1 -Dflume.root.logger=INFO,console在node02上`启动`&gt; telnet node00 44444然后输入数据文件最后在node01节点上显示文件信息 19/01/18 23:33:01 INFO sink.LoggerSink: Event: { headers:{} body: 68 65 6C 6C 6F 20 77 6F 72 6C 64 0D hello world. } ` flume-ng agent –conf-file flumeproject –name a1 -Dflume.root.logger=INFO,console","tags":[{"name":"Linux系统环境","slug":"Linux系统环境","permalink":"http://sungithup.github.io/tags/Linux系统环境/"},{"name":"HDFS","slug":"HDFS","permalink":"http://sungithup.github.io/tags/HDFS/"},{"name":"Base","slug":"Base","permalink":"http://sungithup.github.io/tags/Base/"}]},{"title":"大数据思想","date":"2019-01-04T16:00:00.000Z","path":"2019/01/05/大数据思想/","text":"[TOC] 1、大数据核心问题：==海量数据、工业技术落后、硬件损坏常态化（Ctrl+M）== 2、大数据思维分而治之 把一个复杂的问题按一定的“分解”方法分为等价的规模较小的若干部分，然后逐个解决，然后分别找出各部分的中间结果，最后将各个部分的中间结果组成整个问题的最终结果（Ctrl+Q） 3、业务场景仓储、数牌 业务一：找{重复行}(chongfuhang)++现有1TB的TXT文件 ;格式：数字+字符 ；网速：500M/s ；服务器内存大小：128M ；条件：仅有两行重复 ，内存不能放下全量数据（OM：out of memery）；++ ==方法== 答：共需要2次IO：2*30min=1h ==第一次IO==： 给每一行内容加上唯一标记（hashcode（内容），value（行号））。对每一行内容进行hash运算，得到唯一标识hashcode，作为key，将行号作为value。然而，对于内容完全重复的两行，其hashcode值一定相同。 `对每一行的hash值进行取模运算，并放置于归类分区的小文件中`。由于数据基数过大，就将每行的key值对取模，转化为小文件，如将hash值对100取模，则产生100个小文件分区，取模后相同的放在同一个分区中。 ==第二次IO==： 在每个分区中的小文件遍历，对每一行进行比较，因为重复行一定会在同一个分区中。这样工作量就会大大减小。 业务二：快{排序}(paixu)++现有1TB的TXT文件 ;格式：数字；网速：500M/s ；服务器内存大小：128M ；条件：实现快排序，内存不能放下全量数据（OM：out of memery）；++ 两次IO，2 * 30分钟 = 1小时 ==方法一：先全局有序后局部有序== 1.对全局按分区排序（由大到小）。​ 用if。。else方法对数据进行按范围分类，落到不同的分区中（0~1000、1001~2000、2001~3000··················） 2.对局部进行排序（由大到小）。​ 对每个分区进行排序。 ==方法二：先局部有序后全局有序== 先实现局部有序(小–&gt;大)。将文件划分为N个分区，在每个分区内部进行排序 使用归并实现全局有序。每个分区分别各自取出最小值，拿出来比较，最小值放在一旁，最小值所在的那个分区再拿出剩下数据中的最小值，再进行比较，比较出的最小值，排在上一次的最小值后，依次进行下去，这样就实现了全局有序。","tags":[{"name":"BigData","slug":"BigData","permalink":"http://sungithup.github.io/tags/BigData/"},{"name":"头脑风暴","slug":"头脑风暴","permalink":"http://sungithup.github.io/tags/头脑风暴/"},{"name":"分而治之","slug":"分而治之","permalink":"http://sungithup.github.io/tags/分而治之/"}]},{"title":"Hadoop2.X","date":"2019-01-04T11:05:47.000Z","path":"2019/01/04/Hadoop2.X/","text":"[TOC] 一、Hadoop 2.x产生背景1、Hadoop 1.0存在的问题（1）HDFS存在的问题 NameNode单点故障，难以应用于在线场景 NameNode（一个）压力过大，内存受限，影响系统扩展性 （2）MapReduce存在的问题 JobTracker访问压力大，影响系统扩展性 难以支持MapReduce以外的计算框架，比如Spark、Storm 2、Hadoop 2.0分支HDFS：分布式文件存储系统MapReduce：计算框架YARN：资源管理系统 3、特点 1）. 解决单点故障：HDFS HA（高可用） 通过主备NameNode解决，如果主NameNode发生故障，就切换到备NameNode上 | 2).解决内存受限问题：HDFS Federation（联邦制）、HA HA：两个NameNode (3.0就实现了一组多从：水平扩展，支持多个NameNode；每个NameNode分管一部分目录；所有NameNode共享所有DataNode资源) 3).仅架构上发生变化使用方式不变 二、HDFS HA结构及功能**HADN：DataNode（数据节点） 存放数据block块；遵循心跳机制向NN Active和NN Standby汇报block块信息，但只执行active的命令 主备NN：NameNode Active 和 NameNode Standby （主备名称节点） 主NN对外提供读写服务，备NN同步主NN元数据，以待切换，所有的DN同时向两个NN汇报数据块信息 元数据信息加载到主NN，并写入JN（至少写两台：过半原则）； 备NN可以从JN中同步元数据信息； 解决单点故障； –两种切换方式： 手动：通过命令实现主备切换 自动：基于Zookeeper实现（详情见搭建步骤） JN：JournalNode（至少3台） 存储主NN元数据信息，实现主备NN间数据共享； （遵循过半原则：至少有过半的数量参与投票） ZKFC：FailoverController（竞争锁） 谁拿到了这个所，谁就是active NN 心跳机制监控主备NN状态，一旦出现一台挂机，就会释放锁，另一个NN就会立即启动竞争锁，成为active NN ZK：Zookeeper（至少3台） （实现主备NN切换） **联邦 通过多个namenode/namespace把元数据的存储和管理分散到多个节点中，使到namenode/namespace可以通过增加机器来进行水平扩展 通过多个namespace来隔离不同类型的应用，把不同类型应用的HDFS元数据的存储和管理分派到不同的namenode中。 三、YARN(资源管理)???????详见Yarn学习.md 1、核心思想：SourceManager（资源管理）+ReplicationMaster（任务调度） 2.yarn的引入使得多个计算框架可以应用到一个集群中 四、Zookeeper工作原理详见Zookeeper学习.md 五、Hadoop2.X 集群搭建1、linux环境下搭建 NN DN JN ZKFC ZK SM RM node00 √ √ √ √ √ √ √ node01 √ √ √ √ √ √ node02 √ √ √ √ 0.在搭建环境之前的准备 三台虚拟机： 1234567关闭防火墙安装jdk编辑/etc/hosts/给各个节点服务器起别名时间服务器：ntpdate 安装：yum install ntpdate -y 生成：ntpdate cn.ntp.org.cn免密登录环境准备 在hadoop安装目录下hadoop-2.6.5/etc/hadoop/ 编辑hadoop-env.sh 1export JAVA_HOME=/usr/soft/jdk1.8.0_191 2.编辑core-site.xml 123456789101112131415&lt;configuration&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://Sunrise&lt;/value&gt;&lt;!--配置集群的名字--&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node00:2181,node01:2181,node02:2181&lt;/value&gt; &lt;!--配置zookeeper：三个节点--&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop&lt;/value&gt;&lt;!--配置hadoop基础配置存放的路径--&gt;&lt;/property&gt;&lt;/configuration&gt; 3.编辑hdfs-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;sxt&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.namenodes.Sunrise&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.Sunrise.nn1&lt;/name&gt; &lt;value&gt;node00:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.Sunrise.nn2&lt;/name&gt; &lt;value&gt;node01:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.Sunrise.nn1&lt;/name&gt; &lt;value&gt;node00:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.Sunrise.nn2&lt;/name&gt; &lt;value&gt;node01:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;!-- 指定namenode元数据存储在journalnode中的路径 --&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://node00:8485;node01:8485;node02:8485/sxt&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;!-- 指定HDFS客户端连接active namenode的java类 --&gt; &lt;name&gt;dfs.client.failover.proxy.provider.Sunrise&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;!-- 配置隔离机制为ssh 防止脑裂：保证activeNN仅有一台--&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;!-- 指定秘钥的位置 --&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_dsa&lt;/value&gt; &lt;!--免密登录是生成的文件，有的是id_rsa--&gt;&lt;/property&gt;&lt;property&gt; &lt;!-- 指定journalnode日志文件存储的路径 --&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/data&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;!-- 开启自动故障转移 --&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 配置hadoop中的slaves（主从架构：datanode） 123node00node01node02 5.准备zookeeper 三台zookeeper：node00，node01，node02 编辑zookeeper-3.4.13/conf/zoo.cfg 123456789tickTime=2000initLimit=10syncLimit=5dataDir=/usr/soft/zookeeper-3.4.13/datadataLogDir=/usr/soft/zookeeper-3.4.13/logsclientPort=2181server.1=node00:2888:3888server.2=node01:2888:3888server.3=node02:2888:3888 在dataDir目录中创建文件myid，三台节点的文件内容分别为1，2，3 6.配置环境变量 vim ~/.bash_profile 123456JAVA_HOME=/usr/soft/jdk1.8.0_191export PATH=$PATH:$JAVA_HOME/binHADOOP_HOME=/usr/soft/hadoop-2.6.5export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinZOOKEEPER_HOME=/usr/soft/zookeeper-3.4.13export PATH=$PATH:$ZOOKEEPER_HOME/bin source ~/.bash_profile 使其成为资源文件，发送到其他节点后，也需要此操作 7.将以上配置文件远程发送至其他节点服务器 scp -r filename nodename:pwd 8.命令操作： 123456789101112131415161. 启动三个zookeeper：./zkServer.sh start2. 启动三个JournalNode：./hadoop-daemon.sh start journalnode3. （生成fsimage文件）在其中一个namenode上格式化： hdfs namenode -format4. 把刚刚格式化之后的元数据拷贝到另外一个namenode上 a) 启动刚刚格式化的namenode : hadoop-daemon.sh start namenode b) （同步fsimage文件）在另一个（没有格式化的）namenode上执行： hdfs namenode -bootstrapStandby c) 启动没格式化的namenode： hadoop-daemon.sh start namenode5. （初始化竞争锁zookeeper）在其中一个namenode上初始化zkfc： hdfs zkfc -formatZK6. 停止上面节点：stop-dfs.sh7. 全面启动（三个节点）：start-dfs.sh8. 启动yarn资源管理器 yarn-daemon.sh start resourcemanager (yarn resourcemanager ) 2、使用（启动步骤） 1234(1)关闭防火墙：service iptables stop （3台）(2)启动zookeeper:zkServer.sh start （3台）(3)启动集群：start-dfs.sh |（start-all.sh : 同时启动hdfs和yarn)(4)启动yarn：yarn-daemon.sh start resourcemanager （可3台） （关闭步骤） 123(1)关闭yarn：yarn-daemon.sh stop resourcemanager （开几台关几台）(2)关闭集群：stop-dfs.sh |（stop-all.sh :同时关闭hdfs和yarn） （3台）(3)关闭zookeeper：zkServer.sh stop （3台） 12345678有可能会出错的地方1， 确认每台机器防火墙均关掉2， 确认每台机器的时间是一致的3， 确认配置文件无误，并且确认每台机器上面的配置文件一样4， 如果还有问题想重新格式化，那么先把所有节点的进程关掉5， 删除之前格式化的数据目录hadoop.tmp.dir属性对应的目录，所有节点同步都删掉，别单删掉之前的一个，删掉三台JN节点中dfs.journalnode.edits.dir属性所对应的目录6， 接上面的第6步又可以重新格式化已经启动了7， 最终Active Namenode停掉的时候，StandBy可以自动接管！","tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://sungithup.github.io/tags/hadoop/"}]},{"title":"手动安装maven坐标依赖","date":"2018-12-27T18:16:47.000Z","path":"2018/12/28/手动安装maven坐标依赖/","text":"手动安装maven坐标依赖一、事件原因：学习quartz框架时，在maven项目的pom.xml文件中添加quartz所需要的坐标依赖时，显示jar包不存在。 12345678910111213提示：\"Dependency 'xxxx‘ not found\"， 并且添加的如下两个坐标依赖均报红。 &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 工具 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; 分析： 1、maven项目所需要的jar包均存放在maven的F:\\m2\\repository(项目所需的jar包仓库)文件夹中 2、在F:\\apache-maven-3.5.4\\conf的settings.xml文件中有如下设置：（由于使用远程仓库太慢，阿里云给我们提供了一个镜像仓库，便于我们使用，且只包含central仓库中的jar） 1234567&lt;!--文件中原有的配置：远程仓库---&gt;&lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt; 1234567&lt;!--文件中自己手动配置：阿里镜像仓库---&gt;&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; 3.可是我们在https://mvnrepository.com/（maven仓库）中发现有我们要的jar包，而且就在Central仓库里，这里我们就很奇怪了，后来就选择还是手动安装jar包吧 （如果有小伙伴有别的解决方案，还请指点一二。） 1&lt;!--more--&gt; 二、解决方案1、首先，我们需要从maven Repository中下载我们需要的jar包（需要的两个jar包，下载原理相同） 2、注意我们的maven安装，需要配置环境变量，才能在dos窗口，指令安装jar包 因为我之前查资料时，有小伙伴说，java的环境变量配置也会影响，所以，我在这里也把java的环境变量配置也贴出来 JAVA_HOME F:\\Java\\jdk1.8.0_131（ 根据自己的jdk安装目录） CLASSPATH .;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar MAVEN_HOME F:\\apache-maven-3.5.4（ 根据自己maven安装目录） Path（注意配置的时候，一定要和配置home时的变量名一致，如MAVEN_HOME,我配置成了%MVN_HOME%\\bin;） %JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin;%SystemRoot%\\system32;%SystemRoot%;%SystemRoot%\\System32\\Wbem;%SYSTEMROOT%\\System32\\WindowsPowerShell\\v1.0\\;%MYSQL_HOME%\\bin;%MAVEN_HOME%\\bin; 配置这些环境变量，在dos窗口才能使java ，mvn 之类的指令可以用； 否则会出现如下显示。 ‘mvn’ 不是内部或外部命令，也不是可运行的程序 (这就是环境变量没有配成功的结果) 3.安装 C:\\Users\\Administrator&gt;mvn -v C:\\Users\\Administrator&gt;mvn install:install-file -Dfile=F:/apache-maven-3.5.4/m2/quartz-2.3.0.jar（jar包所在路径） -DgroupId=org.quartz-scheduler -DartifactId=quartz -Dversion=2.3.0 -Dpackaging=jar （根据下面所示的配置groupId、artifactId、version） 12345&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; 如图所示，安装成功。","tags":[{"name":"maven","slug":"maven","permalink":"http://sungithup.github.io/tags/maven/"}]},{"title":"常用Linux命令的学习（二）","date":"2018-12-27T16:00:00.000Z","path":"2018/12/28/常用Linux命令的学习（二）/","text":"​​ [TOC] 一、磁盘指令 查看硬盘信息 命令：df （默认大小以kb显示） df -k（以kb为单位） df -m（ 以mb为单位） df –h （易于阅读） 查看文件/目录的大小 命令：du filename|foldername （默认单位为kb）-k kb单位 -m mb单位 -a 所有文件和目录 -h 更易于阅读 ​ --max-depth=0 目录深度 二、网络指令 查看网络配置信息 命令:ifconfig 测试与目标主机的连通性 命令：ping remote_ip ctrl + c :结束ping进程 显示各种网络相关信息 命令：netstat 查看端口号（是否被占用） (1)、lsof -i:端口号 （需要先安装lsof） (2)、netstat -tunlp|grep 端口号 测试远程主机的网络端口 命令： telnet ip port （需要先安装telnet） 测试成功后，按ctrl + ] 键，然后弹出telnet&gt;时，再按q退出 http请求模拟 curl -X get www.baidu.com 模拟请求百度 三、系统管理指令 用户操作 12345678910 操作 命令创建用户 useradd|adduser username修改密码 passwd username删除用户 userdel –r username修改用户（已下线）： 修改用户名: usermod –l new_name oldname 锁定账户: usermod –L username 解除账户： usermod –U username查看当前登录用户 仅root 用户：whoami | cat /etc/shadow 普通用户：cat /etc/pqsswd 用户组操作 12345 操作 命令 创建用户组 groupadd groupname删除用户组 groupdel groupname修改用户组 groupmod –n new_name old_name查看用户组 groups （查看的是当前用户所在的用户组） 用户+用户组 12345 操作 命令 修改用户的主组 usermod –g groupname username给用户追加附加组 usermod –G groupname username查看用户组中用户数 cat /etc/group注意：创建用户时，系统默认会创建一个和用户名字一样的主组 系统权限 12345678910 操作 命令 查看/usr下所有权限 ll /usr 权限类别 r（读取：4） w（写入：2） x（执行：1） 三个为一组，无权限用 —代替 UGO模型 U（User） G(Group) O(其他)权限修改 修改所有者：chown username file|folder (递归)修改所有者和所属组： chown -r username：groupname file|folder 修改所属组：chgrp groupname file|folder 修改权限：chmod ugo+rwx file|folder 四、系统配置指令 1.修改主机名 123 编辑文件： 命令： vim /etc/sysconfig/network 文件内容： HOSTNAME=node00（重启生效)reboot 2.DNS配置 12编辑文件： 命令：vim /etc/resolv.conf文件内容： nameserver 192.168.198.0 3.sudo权限配置 1234567891011121314151617 操作 命令编辑权限配置文件： vim /etc/sudoers格式： 授权用户 主机=[(切换到哪些用户或用户组)] [是否需要密码验证] 路径/命令举例： test ALL=(root) /usr/bin/yum,/sbin/service解释： test用户就可以用yum和servie命令， 但是，使用时需要在前面加上sudo再敲命令。 第一次使用需要输入用户密码,且每个十五分钟需要一次密码验证修改： test ALL=(root) NOPASSWD: /usr/bin/yum,/sbin/service这样就不需要密码了将权限赋予某个组，%+组名%group ALL=(root) NOPASSWD: /usr/bin/yum,/sbin/service列出用户所有的sudo权限 sudo –l 4.系统时间 12345678操作 命令查看系统时间 date ---查看当前时间详情 cal ---查看当前月日历 cal 2018 ---查看2018年完整日历 cal 12 2018 ---查看指定年月的日历 更新系统时间（推荐） yum install ntpdate –y ---安装ntp服务 ntpdate cn.ntp.org.cn ---到域名为cn.ntp.org.cn的时间服务器上同步时间 5.关于hosts配置 相当于给IP地址其别名，可以通过别名访问 路径： Windows系统 C:/Windows/System32/drivers/etc/hosts 文件 Linux系统 /etc/hosts文件：vim +路径 统一 编辑格式 IP地址 别名：192.168.198.128 node00 6.关于hostname配置 相当于给对应的虚拟机器起别名 Linux系统： vi /etc/sysconfig/network 编辑内容： HOSTNAME=node01 五、重定向与管道符 输出重定向 输出重定向到一个文件或设备： &gt; 覆盖原来的文件 &gt;&gt; 追加原来的文件 举例： ls &gt; log — 在log文件中列出所有项，并覆盖原文件 echo “hello”&gt;&gt;log —将hello追加到log文件中 输入重定向 &lt; 输入重定向到一个程序 举例：cat &lt; log —将log文件作为cat命令的输入，查看log文件的内容 标准 输出 重定向 1 &gt; 或 &gt; 含义： 输出重定向时，只用正确的输出才会重定向到指的文件中 错误的则会直接打印到屏幕上 错误 输出 重定向 2 &gt; 含义： 错误的输出会重定向到指定文件里，正确的日志则直接打印到屏幕上。 结合 使用 2&gt;&amp;1 含义： 将无论是正确的输出还是错误的输出都重定向到指定文件 管道 **\\ ** 含义： 把前一个输出当做后一个输入 grep 通过正则搜索文本，并将匹配的行打印出来 netstat -anp \\ grep 22 把netstat –anp 命令的输出 当做是grep 命令的输入 命令 执行 控制 &amp;&amp; 前一个命令执行成功才会执行后一个命令 **\\ \\ ** 前一个命令执行失败才会执行后一个命令","tags":[{"name":"Linux系统环境","slug":"Linux系统环境","permalink":"http://sungithup.github.io/tags/Linux系统环境/"}]},{"title":"常用Linux命令的学习（一）","date":"2018-12-27T12:16:47.000Z","path":"2018/12/27/常用Linux命令的学习（一）/","text":"常用Linux命令的学习（一）[TOC] 一、命令指南（manual）：man 安装：yum install man –y （-y 表示获得允许，无需确认） 查看ls命令指南： man ls 二、目录命令切换目录：cd + 目录的路径 查看当前目录所在的完整路径：pwd 新建目录：mkdir +目录名字 查看当前目录所用有的子目录和文件：ls ，ll等价于 ls –l ​ 查看目录下的所有东西（包括隐藏文件）： ls –al 等价于 ll -a​拷贝目录或文件：cp –r install.log install2.log 删除目录或文件：rm -r install.log (rmdir只能删除空目录) 移动目录或文件：mv + 目录/文件名字 + 其他路径 ​ 将test目录移动到 根目录/ 下 : mv test / （如果移动到当前目录，用另外一个名称，则可以实现重命名的效果） 更改文件或目录的名字：mv + 旧目录名字 + 新目录名 ( -r 用于递归的拷贝，删除，移动目录) 三、文件命令1、一般文件操作新建文件：touch install.log​ (vim install.log 编辑文件，如果文件不存在，就会新建一个对应的文件，并进入文件的编辑模式，如果按 :wq 会保存文件并退出，如果按 :q 则不保存退出)​查看文件内容：cat +（文件名）（一次性显示整个文件的内容，文件内容过多时用户体验不好） 一次命令显示一屏文本： 1234567 more +（文件名） 按键 效果 Space 显示下一屏文本内容B 显示上一屏文本内容Enter 显示下一行文本内容Q 退出查看 less+（文件名） 按键 效果 h 显示帮助界面 u 向后滚动半页 d 向前翻半页 e | Enter 向后翻一行文本 space 滚动一页 b 向后翻一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 上下键，向上一行，向下一行 从头打印文件内容：​ head -10 +（文件名） 打印文件1到10行 从尾部打印文件内容​ tail -10 +（文件名）打印文件最后10行 tail -f (文件名) 常用于查看文件内容的更新变化 查找文件或目录​ find +（路径名） –name +（文件名）​ 举例：find / -name profile​ 在/(根目录)目录下查找 名字为profile的文件或目录 ​ 也可利用正则：​ 举例： find /etc -name pro*​ 在/etc目录下查找以pro开头的文件或目录 路径越精确，查找的范围越小，速度越快 i 2、文件编辑vi（1） vi 进入编辑模式 —–&gt;按i 进入插入模式 ——-&gt; 按Esc 退出编辑模式 1234vi filename :打开或新建文件，并将光标置于第一行首 vi +n filename ：打开文件，并将光标置于第n行首 vi + filename ：打开文件，并将光标置于最后一行首 vi +/pattern filename：打开文件，并将光标置于第一个与 pattern匹配的字符串所在的行首 filename 为文件名 （2）在文件vi（文件编辑）模式下 命令行模式 123456789:w 保存:q 退出:wq 保存并退出:q! 强制退出:set nu |ctrl+g 显示文本行数:set nonu 去除显示的行数:s/p1/p2/g 将当前行中所有p1均用p2替代 :n1,n2s/p1/p2/g 将第n1至n2行中所有p1均用p2替代 :g/p1/s//p2/g 将文件中所有p1均用p2替换 一般模式 12345678910111213141516171819202122232425262728293031按键：yy 复制光标所在行(常用) nyy 复制光标所在行的向下n行，例如， 20yy则是复制20行(常用) p|P p为复制的数据粘贴在光标下一行， P则为粘贴在光标上一行(常用)G 光标移至第最后一行nG 光标移动至第N行行首n+ 光标下移n行 n- 光标上移n行 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 dd 删除所在行 x或X 删除一个字符，x删除光标后的，而X删除光标前的 u 撤销(常用)删除第N行到第M行：N,Md：,$-1d 删除当前光标到到数第一行数据按键： i: 在当前光标所在字符的前面，转为输入模式； a: 在当前光标所在字符的后面，转为输入模式； o: 在当前光标所在行的下方，新建一行，并转为输入模式； I：在当前光标所在行的行首，转换为输入模式 A：在当前光标所在行的行尾，转换为输入模式 O：在当前光标所在行的上方，新建一行，并转为输入模式；---逐字符移动：h: 左 l: 右j: 下 k: 上 vim 安装：yum install vim -y 用vim 打开/etc/profile 文件， 特点：编辑器对文本的内容进行了高亮，使整个文件的内容可读性大大加强 ，其他均与vi相同 3、文件上传下载 安装上传下载命令：yum install lrzsz -y 上传文件：（windows—&gt;linux） 命令 ：rz 弹出windows上传文件窗口 下载文件：(linux—&gt;windows) 注意：sz命令只能下载文件，不能下载目录，推荐将目录压缩成tar包或使用工具软件：Winscp【Xftp】 命令：sz （文件名） 弹出windows下载窗口,下载文件到指定文件目录 4、文件传输(1)、本地→远程 文件 ： scp local_file remote_username@remote_ip:remote_folder 目录 ： scp -r local_folder remote_username@remote_ip:remote_folder (2）、远程→本地 文件 ： scp remote_username@remote_ip:remote_file local_folder 目录 ： scp remote_username@remote_ip:remote_folder local_folder","tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://sungithup.github.io/tags/Linux命令/"}]},{"title":"Hello World","date":"2018-12-18T17:38:10.052Z","path":"2018/12/19/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]